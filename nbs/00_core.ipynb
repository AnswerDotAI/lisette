{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "798b1171",
   "metadata": {
    "input_tokens": 10
   },
   "source": [
    "# core\n",
    "\n",
    "> lisette core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe320a",
   "metadata": {
    "input_tokens": 7
   },
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82380377",
   "metadata": {
    "input_tokens": 123
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "import litellm, json\n",
    "from litellm import completion, stream_chunk_builder, get_model_info\n",
    "from litellm.types.utils import ModelResponseStream,ModelResponse\n",
    "from litellm.utils import function_to_dict\n",
    "from toolslm.funccall import mk_ns, call_func\n",
    "from toolslm.funccall import get_schema\n",
    "from typing import Optional\n",
    "from fastcore.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f20759",
   "metadata": {
    "input_tokens": 6
   },
   "source": [
    "## LiteLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c4ea2",
   "metadata": {
    "input_tokens": 21
   },
   "source": [
    "Litellm provides an easy wrapper for most big LLM providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a85dd",
   "metadata": {
    "input_tokens": 55
   },
   "outputs": [],
   "source": [
    "ms = [\"gemini/gemini-2.5-flash\", \"claude-sonnet-4-20250514\", \"openai/gpt-4.1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa8988a",
   "metadata": {
    "input_tokens": 21
   },
   "source": [
    "TODO: test mixed content/tool calls message (and mixed images too)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61cf441",
   "metadata": {
    "input_tokens": 295
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _repr_markdown_(self: litellm.ModelResponse):\n",
    "    message = self.choices[0].message\n",
    "    content = ''\n",
    "    if message.content: content += message.content\n",
    "    if message.tool_calls:\n",
    "        tool_calls = [f\"\\n\\n🔧 {tc.function.name}({tc.function.arguments})\\n\" for tc in message.tool_calls]\n",
    "        content += \"\\n\".join(tool_calls)\n",
    "    if not content: content = str(message)\n",
    "    details = [\n",
    "        f\"id: `{self.id}`\",\n",
    "        f\"model: `{self.model}`\",\n",
    "        f\"finish_reason: `{self.choices[0].finish_reason}`\"\n",
    "    ]\n",
    "    if hasattr(self, 'usage') and self.usage: details.append(f\"usage: `{self.usage}`\")\n",
    "    det_str = '\\n- '.join(details)\n",
    "    \n",
    "    return f\"\"\"{content}\n",
    "\n",
    "<details>\n",
    "\n",
    "- {det_str}\n",
    "\n",
    "</details>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920d0288",
   "metadata": {
    "input_tokens": 36
   },
   "outputs": [],
   "source": [
    "msg = [{'role':'user','content':'Hey there!', 'cache_control': {'type': 'ephemeral'}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c866d",
   "metadata": {
    "input_tokens": 33
   },
   "outputs": [],
   "source": [
    "for m in ms:\n",
    "    display(f'=== {m} ===')\n",
    "    display(completion(m,msg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad470e4",
   "metadata": {
    "input_tokens": 3
   },
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad6fc2c",
   "metadata": {
    "input_tokens": 82
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def stream_with_complete(gen, postproc=noop):\n",
    "    \"Extend streaming response chunks with the complete response\"\n",
    "    chunks = []\n",
    "    for chunk in gen:\n",
    "        chunks.append(chunk)\n",
    "        yield chunk\n",
    "    postproc(chunks)\n",
    "    return stream_chunk_builder(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc4b5f",
   "metadata": {
    "input_tokens": 12
   },
   "outputs": [],
   "source": [
    "from fastcore.xtras import SaveReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ce765",
   "metadata": {
    "input_tokens": 9
   },
   "outputs": [],
   "source": [
    "model = ms[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f16571",
   "metadata": {
    "input_tokens": 34
   },
   "outputs": [],
   "source": [
    "r = completion(messages=msg, model=model, stream=True)\n",
    "r2 = SaveReturn(stream_with_complete(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797136b",
   "metadata": {
    "input_tokens": 46,
    "output_tokens": 36
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Nice to meet you. How are you doing today?"
     ]
    }
   ],
   "source": [
    "for o in r2:\n",
    "    cts = o.choices[0].delta.content\n",
    "    if cts: print(cts, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897ec073",
   "metadata": {
    "input_tokens": 4,
    "output_tokens": 247
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! Nice to meet you. How are you doing today?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-7a42920c-6162-470c-b86a-844ffd1914d6`\n",
       "- model: `claude-sonnet-4-20250514`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=16, prompt_tokens=10, total_tokens=26, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-7a42920c-6162-470c-b86a-844ffd1914d6', created=1757396854, model='claude-sonnet-4-20250514', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Hello! Nice to meet you. How are you doing today?', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=16, prompt_tokens=10, total_tokens=26, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e11c0",
   "metadata": {
    "input_tokens": 3
   },
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4301402e",
   "metadata": {
    "input_tokens": 54
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def _lite_mk_func(f):\n",
    "    if isinstance(f, dict): return f\n",
    "    return {'type':'function', 'function':get_schema(f, pname='parameters')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b103600",
   "metadata": {
    "input_tokens": 85
   },
   "outputs": [],
   "source": [
    "def simple_add(\n",
    "    a: int,   # first operand\n",
    "    b: int=0  # second operand\n",
    ") -> int:\n",
    "    \"Add two numbers together\"\n",
    "    print(f\"TOOL CALLED {a=} + {b=}\")\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100fc27b",
   "metadata": {
    "input_tokens": 19,
    "output_tokens": 414
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'simple_add',\n",
       "  'description': 'Add two numbers together\\n\\nReturns:\\n- type: integer',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'a': {'type': 'integer', 'description': 'first operand'},\n",
       "    'b': {'type': 'integer', 'description': 'second operand', 'default': 0}},\n",
       "   'required': ['a']}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toolsc = _lite_mk_func(simple_add)\n",
    "toolsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32754b2",
   "metadata": {
    "input_tokens": 63
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_user(s, cache=False):\n",
    "    res = {\"role\": \"user\", \"content\": s}\n",
    "    if cache: res['cache_control'] = {'type': 'ephemeral'}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2af29a",
   "metadata": {
    "input_tokens": 115
   },
   "outputs": [],
   "source": [
    "tmsg = mk_user(\"What is 5478954793+547982745? How about 5479749754+9875438979? Always use tools for calculations, and describe what you'll do before using a tool. Where multiple tool calls are required, do them in a single response where possible.\")\n",
    "r = completion(model, [tmsg], tools=[toolsc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb1817",
   "metadata": {
    "input_tokens": 1,
    "output_tokens": 357
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'll help you calculate both of those additions using the simple_add tool. Let me perform both calculations for you:\n",
       "\n",
       "🔧 simple_add({\"a\": 5478954793, \"b\": 547982745})\n",
       "\n",
       "\n",
       "\n",
       "🔧 simple_add({\"a\": 5479749754, \"b\": 9875438979})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-d2b6869e-e336-46a9-9162-1f265c9d5104`\n",
       "- model: `claude-sonnet-4-20250514`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=159, prompt_tokens=475, total_tokens=634, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None), cache_creation_input_tokens=0, cache_read_input_tokens=0)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-d2b6869e-e336-46a9-9162-1f265c9d5104', created=1757396857, model='claude-sonnet-4-20250514', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=\"I'll help you calculate both of those additions using the simple_add tool. Let me perform both calculations for you:\", role='assistant', tool_calls=[ChatCompletionMessageToolCall(index=1, function=Function(arguments='{\"a\": 5478954793, \"b\": 547982745}', name='simple_add'), id='toolu_01ANyXaH1yQ8pTkWKh89pQsQ', type='function'), ChatCompletionMessageToolCall(index=2, function=Function(arguments='{\"a\": 5479749754, \"b\": 9875438979}', name='simple_add'), id='toolu_01AwCC8kjj42YFhSRLX3Uo6n', type='function')], function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=159, prompt_tokens=475, total_tokens=634, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None), cache_creation_input_tokens=0, cache_read_input_tokens=0))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d81d05",
   "metadata": {
    "input_tokens": 93
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def _lite_call_func(tc,ns,raise_on_err=True):\n",
    "    res = call_func(tc.function.name, json.loads(tc.function.arguments),ns=ns)\n",
    "    return {\"tool_call_id\": tc.id, \"role\": \"tool\", \"name\": tc.function.name, \"content\": str(res)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af607c",
   "metadata": {
    "input_tokens": 42,
    "output_tokens": 415
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOOL CALLED a=5478954793 + b=547982745\n",
      "TOOL CALLED a=5479749754 + b=9875438979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'tool_call_id': 'toolu_01ANyXaH1yQ8pTkWKh89pQsQ',\n",
       "  'role': 'tool',\n",
       "  'name': 'simple_add',\n",
       "  'content': '6026937538'},\n",
       " {'tool_call_id': 'toolu_01AwCC8kjj42YFhSRLX3Uo6n',\n",
       "  'role': 'tool',\n",
       "  'name': 'simple_add',\n",
       "  'content': '15355188733'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcs = [_lite_call_func(o, ns=globals()) for o in r.choices[0].message.tool_calls]\n",
    "tcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd9871b",
   "metadata": {
    "input_tokens": 211
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def delta_text(msg):\n",
    "    \"Extract printable content from streaming delta, return None if nothing to print\"\n",
    "    c = msg.choices[0]\n",
    "    if not c: return c\n",
    "    if not hasattr(c,'delta'): return None #f'{c}'\n",
    "    delta = c.delta\n",
    "    if delta.content: return delta.content\n",
    "    if delta.tool_calls:\n",
    "        res = ''.join(f\"🔧 {tc.function.name}\" for tc in delta.tool_calls if tc.id and tc.function.name)\n",
    "        if res: return f'\\n{res}'\n",
    "    if hasattr(delta,'reasoning_content'): return '🧠' if delta.reasoning_content else '\\n\\n'\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4790a51",
   "metadata": {
    "input_tokens": 67,
    "output_tokens": 73
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll help you calculate both of those addition problems using the simple_add tool"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". Let me perform both calculations for you:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 simple_add"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 simple_add"
     ]
    }
   ],
   "source": [
    "r = completion(messages=[tmsg], model=model, stream=True, tools=[toolsc])\n",
    "r2 = SaveReturn(stream_with_complete(r))\n",
    "for o in r2: print(delta_text(o) or '', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b21118c",
   "metadata": {
    "input_tokens": 4,
    "output_tokens": 343
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'll help you calculate both of those addition problems using the simple_add tool. Let me perform both calculations for you:\n",
       "\n",
       "🔧 simple_add({\"a\": 5478954793, \"b\": 547982745})\n",
       "\n",
       "\n",
       "\n",
       "🔧 simple_add({\"a\": 5479749754, \"b\": 9875438979})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-85cad387-08ec-46dc-99d7-8e6003743730`\n",
       "- model: `claude-sonnet-4-20250514`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=160, prompt_tokens=475, total_tokens=635, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-85cad387-08ec-46dc-99d7-8e6003743730', created=1757396858, model='claude-sonnet-4-20250514', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=\"I'll help you calculate both of those addition problems using the simple_add tool. Let me perform both calculations for you:\", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 5478954793, \"b\": 547982745}', name='simple_add'), id='toolu_01FjsG2q1ttX6EjGPU6Bn86u', type='function'), ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 5479749754, \"b\": 9875438979}', name='simple_add'), id='toolu_01JJSHD2y7DyHJc1P7hTT2oE', type='function')], function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=160, prompt_tokens=475, total_tokens=635, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f355ecbe",
   "metadata": {
    "input_tokens": 115,
    "output_tokens": 420
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠🧠"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠🧠🧠🧠"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠🧠"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠🧠🧠🧠"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠🧠"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠🧠🧠"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I'll find the derivative of f(x) = x³ + 2x² - 5x + 1 using the power rule"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "**Step-by-step solution:**\n",
      "\n",
      "Using the power rule:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " if f(x) = xⁿ, then f'(x) = nx"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ⁿ⁻¹\n",
      "\n",
      "Taking the derivative of each term:\n",
      "\n",
      "1) d/dx(x³) = "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3x²\n",
      "\n",
      "2) d/dx(2x²) = 2 × 2x¹ = 4x\n",
      "\n",
      "3)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " d/dx(-5x) = -5 × 1x⁰ = -5\n",
      "\n",
      "4) d/dx(1) ="
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 (derivative of a constant is zero)\n",
      "\n",
      "**Therefore"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":**\n",
      "f'(x) = 3x² + 4x - 5\n",
      "\n",
      "The derivative of x³ + 2x² - "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5x + 1 is **3x² + 4x -"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5**."
     ]
    }
   ],
   "source": [
    "msg = mk_user(\"Solve this complex math problem: What is the derivative of x^3 + 2x^2 - 5x + 1?\")\n",
    "r = completion(messages=[msg], model=model, stream=True, reasoning_effort=\"low\")\n",
    "r2 = SaveReturn(stream_with_complete(r))\n",
    "for o in r2: print(delta_text(o) or '', end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff5f1a",
   "metadata": {
    "input_tokens": 4,
    "output_tokens": 616
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'll find the derivative of f(x) = x³ + 2x² - 5x + 1 using the power rule.\n",
       "\n",
       "**Step-by-step solution:**\n",
       "\n",
       "Using the power rule: if f(x) = xⁿ, then f'(x) = nxⁿ⁻¹\n",
       "\n",
       "Taking the derivative of each term:\n",
       "\n",
       "1) d/dx(x³) = 3x²\n",
       "\n",
       "2) d/dx(2x²) = 2 × 2x¹ = 4x\n",
       "\n",
       "3) d/dx(-5x) = -5 × 1x⁰ = -5\n",
       "\n",
       "4) d/dx(1) = 0 (derivative of a constant is zero)\n",
       "\n",
       "**Therefore:**\n",
       "f'(x) = 3x² + 4x - 5\n",
       "\n",
       "The derivative of x³ + 2x² - 5x + 1 is **3x² + 4x - 5**.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-7f7397d8-b6c3-4916-87b8-2245024988cf`\n",
       "- model: `claude-sonnet-4-20250514`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=412, prompt_tokens=66, total_tokens=478, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=158, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-7f7397d8-b6c3-4916-87b8-2245024988cf', created=1757396861, model='claude-sonnet-4-20250514', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"I'll find the derivative of f(x) = x³ + 2x² - 5x + 1 using the power rule.\\n\\n**Step-by-step solution:**\\n\\nUsing the power rule: if f(x) = xⁿ, then f'(x) = nxⁿ⁻¹\\n\\nTaking the derivative of each term:\\n\\n1) d/dx(x³) = 3x²\\n\\n2) d/dx(2x²) = 2 × 2x¹ = 4x\\n\\n3) d/dx(-5x) = -5 × 1x⁰ = -5\\n\\n4) d/dx(1) = 0 (derivative of a constant is zero)\\n\\n**Therefore:**\\nf'(x) = 3x² + 4x - 5\\n\\nThe derivative of x³ + 2x² - 5x + 1 is **3x² + 4x - 5**.\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None, thinking_blocks=[{'type': 'thinking', 'thinking': \"I need to find the derivative of the function f(x) = x³ + 2x² - 5x + 1.\\n\\nI'll use the power rule for derivatives, which states that if f(x) = x^n, then f'(x) = nx^(n-1).\\n\\nLet me take the derivative of each term:\\n\\n1) For x³: The derivative is 3x²\\n2) For 2x²: The derivative is 2 × 2x¹ = 4x\\n3) For -5x: The derivative is -5 × 1x⁰ = -5\\n4) For the constant 1: The derivative is 0\\n\\nSo the derivative is: 3x² + 4x - 5\", 'signature': 'EtAECkYIBxgCKkCKGPBtKUUQO50PYR4uL7uDwEZ+hal+LZ2cumwbDTTAm7wvWUsjKf3JU9vUVHJ5Flz/ITlHGrHSIapjx/4yET2REgxKkKbnnluzYJ51rrsaDBF8Izs8Vx8htO0nRiIwf6i4JKR19w3T+gvhywNVmcK9DvNUXpoXqdo8rM+VFzzV9rNjQ7MxwZoKhAnjPmfCKrcDWpNBIQsTaVQKwkI6uiKSYhCH4VQNQqEjFm7bqPAV+zChc0S1q6GyyX4Mqe+KsJHAYrCi0DRXzFUH58I1SFi7ufQUtAhSDyyuanE8b29f4vNVi/BGVG6yx78DzirG0KafG/UjDKha/Bd+mYc9CGZVQTBUgnQyJLjujXZhgLRN0KK6wev7fGE/1ftiGiLNLwtcs+npJX9DI/y/sgSvaJKD0FYIIfGOtI8dhaYFX/mJhX4y6ng/04f+T3u6VC6K8JmwUs6SUgq29TCEh9zPVvbldEGguksCjPDPO94v3MFJmBKprVMidXbegi7rjulooWNfcdn2+ffcAkqPy1DL/8SdEf7ESdWT6UbYmkKOFN26FjkQy/7v18GIChGI6rzx+WXndOmAt9RMEjDdlY2jieVFyF79R88RLD9BmadY5NLa1ga1rioo+jn/khsDp3ZEkNntMlMvC9hFQ/a35VXenQbMc6EhG/p0btnLtZ7AdH7+elS1gcNJNkztzKlWQMKz3YU0X9sB9q2qLv2N8bgIHE/OjBGxVW2Oal3GjYbqNFHJM2BaE8xdr+PW4DDre8Wmv/aVLRS37GmyZhgB'}], reasoning_content=\"I need to find the derivative of the function f(x) = x³ + 2x² - 5x + 1.\\n\\nI'll use the power rule for derivatives, which states that if f(x) = x^n, then f'(x) = nx^(n-1).\\n\\nLet me take the derivative of each term:\\n\\n1) For x³: The derivative is 3x²\\n2) For 2x²: The derivative is 2 × 2x¹ = 4x\\n3) For -5x: The derivative is -5 × 1x⁰ = -5\\n4) For the constant 1: The derivative is 0\\n\\nSo the derivative is: 3x² + 4x - 5\"))], usage=Usage(completion_tokens=412, prompt_tokens=66, total_tokens=478, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=158, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd33761",
   "metadata": {
    "input_tokens": 97,
    "output_tokens": 631
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Otters are carnivorous mammals in the weasel family, found on every continent except Australia and Antarctica. There are 13-14 species ranging from small-clawed otters to giant otters, with sizes from 0.6 to 1.8 meters in length.\n",
       "\n",
       "They have elongated bodies, long tails, webbed feet for swimming, and dense waterproof fur. Otters have the densest fur of any animal—as many as a million hairs per square inch. Their lung capacity is 2.5 times greater than similar-sized land mammals, allowing sea otters to stay underwater for over 5 minutes and river otters up to 8 minutes.\n",
       "\n",
       "All otters are expert hunters that eat fish, crustaceans, and other critters. Sea otters famously use tools, floating on their backs and smashing mollusks on rocks placed on their chests. They are notably playful animals, engaging in sliding and water games.\n",
       "\n",
       "Baby otters stay with their mothers for up to a year, and otters can live up to 16 years. Unfortunately, many species remain at risk from pollution, habitat loss, and historical hunting for their fur.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-ff33e062-ce19-4e53-a0bb-1677026bbf9b`\n",
       "- model: `claude-sonnet-4-20250514`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=532, prompt_tokens=13316, total_tokens=13848, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None), server_tool_use=ServerToolUse(web_search_requests=1), cache_creation_input_tokens=0, cache_read_input_tokens=0)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-ff33e062-ce19-4e53-a0bb-1677026bbf9b', created=1757396878, model='claude-sonnet-4-20250514', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Otters are carnivorous mammals in the weasel family, found on every continent except Australia and Antarctica. There are 13-14 species ranging from small-clawed otters to giant otters, with sizes from 0.6 to 1.8 meters in length.\\n\\nThey have elongated bodies, long tails, webbed feet for swimming, and dense waterproof fur. Otters have the densest fur of any animal—as many as a million hairs per square inch. Their lung capacity is 2.5 times greater than similar-sized land mammals, allowing sea otters to stay underwater for over 5 minutes and river otters up to 8 minutes.\\n\\nAll otters are expert hunters that eat fish, crustaceans, and other critters. Sea otters famously use tools, floating on their backs and smashing mollusks on rocks placed on their chests. They are notably playful animals, engaging in sliding and water games.\\n\\nBaby otters stay with their mothers for up to a year, and otters can live up to 16 years. Unfortunately, many species remain at risk from pollution, habitat loss, and historical hunting for their fur.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': [[{'type': 'web_search_result_location', 'cited_text': 'The charismatic otter, a member of the weasel family, is found on every continent except Australia and Antarctica. ', 'url': 'https://www.nationalgeographic.com/animals/mammals/facts/otters-1', 'title': 'Otters, facts and information | National Geographic', 'encrypted_index': 'Eo8BCioIBxgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDGSBf88S47DAweIwGhoMNZkbIflRzVJKEINOIjD/KVAIb0wABKB3JbDuVzoI+duKRiEWJxUFPg34RfUtoocpXjbS0n/A4z5bSsGJGX0qE4dOrL4dvQN149N3Db7KxKbXF3kYBA=='}], [{'type': 'web_search_result_location', 'cited_text': 'There are 13 species in total, ranging from the small-clawed otter to the giant otter.', 'url': 'https://www.nationalgeographic.com/animals/mammals/facts/otters-1', 'title': 'Otters, facts and information | National Geographic', 'encrypted_index': 'Eo8BCioIBxgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDNrEMk5B9TKDbPE0jhoM0Zy5xWdGh+z/6Oz+IjD3gjaiuo0QFTJXTLeDfTsbE1gttYqFBGHxApJrpH+cVb9kwOIa+EWTO/DIy0YNtmQqEy55pK4wcFyXJoWEovA5Jhn3v04YBA=='}, {'type': 'web_search_result_location', 'cited_text': 'The 13 species range in adult size from 0.6 to 1.8 m (2.0 to 5.9 ft) in length and 1 to 45 kg (2.2 to 99.2 lb) in weight. ', 'url': 'https://en.wikipedia.org/wiki/Otter', 'title': 'Otter - Wikipedia', 'encrypted_index': 'EpABCioIBxgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDAmrwuTBxKz7EFWcJhoMSbbN4A5ysUyvBLKXIjAvx+JrasM7dqZ8kWZPjZCsKCLf+qQI9TXFp7mSOfK127mYKAFm2D2K0Hp5p8WUFd4qFGCfxYINaVyI2qcjBsvzGPLYfBicGAQ='}], [{'type': 'web_search_result_location', 'cited_text': 'Most are small, with short ears and noses, elongated bodies, long tails, and soft, dense fur. ', 'url': 'https://www.nationalgeographic.com/animals/mammals/facts/otters-1', 'title': 'Otters, facts and information | National Geographic', 'encrypted_index': 'Eo8BCioIBxgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDDAkmzixnimGMqrZvhoMbuhImqNwqglzeB8CIjBahHMBBVeP/PEY/YkN6DnLzQC/mxmj/ggsTJKvffpEHMrDtxXfwObT+Ypm9beDkhgqE0ZhSSjFMl5ikWLCs7JVmygux6kYBA=='}, {'type': 'web_search_result_location', 'cited_text': 'Otters are distinguished by their long, slim bodies, powerful webbed feet for swimming, and their dense fur, which keeps them warm and buoyant in wate...', 'url': 'https://en.wikipedia.org/wiki/Otter', 'title': 'Otter - Wikipedia', 'encrypted_index': 'Eo8BCioIBxgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDJh3Nxjly46XZokdDhoMuw5XuCExXaO0YVuTIjCWKVX3jguMSe7N3tj9+mEkeotcG4Q+j8ghPW0HEsi6723kzJde9MFChNHFCRW+BI0qEzBCc/rwOGCuV2ugLM4hUuFIRnQYBA=='}], [{'type': 'web_search_result_location', 'cited_text': 'Otters have the densest fur of any animal—as many as a million hairs per square inch in places. ', 'url': 'https://www.nationalgeographic.com/animals/mammals/facts/otters-1', 'title': 'Otters, facts and information | National Geographic', 'encrypted_index': 'Eo8BCioIBxgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDGGdWMou37O2ilc0jBoMwGoA2v5EQPZjnRJzIjBTVcDfu34CxuJxYuIvbCi4GwvIMB6kNkekyDopG2OxnDaICPYbwAbCogVyzaLOqeEqE899zwN/bXYaJmaZSj1Bi7tKh1YYBA=='}], [{'type': 'web_search_result_location', 'cited_text': 'An otter’s lung capacity is 2.5 times greater than that of similar-sized land mammals. Sea otters have been known to stay submerged for more than 5 mi...', 'url': 'https://www.doi.gov/blog/12-facts-about-otters-sea-otter-awareness-week', 'title': '12 Facts About Otters for Sea Otter Awareness Week | U.S. Department of the Interior', 'encrypted_index': 'EpMBCioIBxgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDEGjII2a6v0jSI+jmhoMm0WTDx4awTt2XOuyIjDh3QT0trTdPPeM+ftng1482Ift/lpfd78E9XBvP/UXrwLlt2/Cmtkx5wVwWgp9rZYqF8WcFFaQVEqJa00lZHUa87AWy6MzRudSGAQ='}], [{'type': 'web_search_result_location', 'cited_text': 'All otters are expert hunters that eat fish, crustaceans, and other critters. ', 'url': 'https://www.nationalgeographic.com/animals/mammals/facts/otters-1', 'title': 'Otters, facts and information | National Geographic', 'encrypted_index': 'EpABCioIBxgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDLcFoGMeY1LFU+SGLhoMIt5bJsnkn3MdcZ59IjDKsbztwinUGemlapnJVTLxjEKtYQ8rd1/GsGcqQIbLDJCp3bTax9HACnx+VZApKzQqFC4ku/6GNvO1F28em6UzIcxHQ2gyGAQ='}, {'type': 'web_search_result_location', 'cited_text': 'Otters are carnivores that eat mainly fish and invertebrates. ', 'url': 'https://www.pbs.org/wnet/nature/blog/otter-fact-sheet/', 'title': 'Otter Fact Sheet | Blog | Nature | PBS', 'encrypted_index': 'EpABCioIBxgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDBhNASRBBwWjrWxC1hoM3pDJ36Zf7HLOj3EFIjBBfZQ3XzqApcs9fTHwa9Qf3k5gPUZnrBKMCwQwhNEOO1nmahbUCHtjGacwp+G4uA4qFEeo5kjuyOtGPG6/WMw36o+SDy6uGAQ='}], [{'type': 'web_search_result_location', 'cited_text': 'A sea otter will float on its back, place a rock on its chest, then smash the mollusk down on it until it breaks open. ', 'url': 'https://www.nationalgeographic.com/animals/mammals/facts/otters-1', 'title': 'Otters, facts and information | National Geographic', 'encrypted_index': 'EpABCioIBxgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDOrJ2yjt1+WNhSuyyRoMMQ/focqIwClQqYIcIjAxJA71C6aGvXw/i/954W+LiYe8Ut505YEDbRb9NowIULW0SC1PyYrgl/lrW8uG41sqFC5PMYy3jyDs9QRLfEsPs5GgU/nzGAQ='}], [{'type': 'web_search_result_location', 'cited_text': 'River otters are especially playful, gamboling on land and splashing into rivers and streams. ', 'url': 'https://www.nationalgeographic.com/animals/mammals/facts/otters-1', 'title': 'Otters, facts and information | National Geographic', 'encrypted_index': 'EpABCioIBxgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDJ24K8KoySsOp0RB8BoMdx778nXbW83VkEhaIjBrrSzLemZkGnEBZbhBbz6NuK4ThRBzQ1D1vThGQ+oOV0xBNY3aLVvOlfBg//VK7ssqFJy/hilVPkfyDE8CYJX+FYa5965+GAQ='}, {'type': 'web_search_result_location', 'cited_text': 'They are playful animals, engaging in activities like sliding into water on natural slides and playing with stones. ', 'url': 'https://en.wikipedia.org/wiki/Otter', 'title': 'Otter - Wikipedia', 'encrypted_index': 'Eo8BCioIBxgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDDkgu9ZIHOp8DmtR6RoM2dU4y3mNd3I022QdIjAN5g8aIEXuYXMYXnpcDcjGt+NkBJdWDzkcZXzzwEHbV2RfbZ/GBlpOv4ngKamjWbIqE5txwQL8GN3B5GMVvS/jpKEcNdYYBA=='}], [{'type': 'web_search_result_location', 'cited_text': 'Baby otters, called pups or kittens, stay with their mothers until they’re up to a year old, or until she has another litter. ', 'url': 'https://www.nationalgeographic.com/animals/mammals/facts/otters-1', 'title': 'Otters, facts and information | National Geographic', 'encrypted_index': 'EpABCioIBxgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDMPKmB4b3je8vg7IxhoMLv9CnSC9YSiaxVX6IjAPMaTaxpm9uh0w2l7GGWKljaGy2XSpfpr0/83+Zt9pEacOloY9NsyU1i+TXohi6TgqFK6chGL3pgUvY23mz3NjaJMc59bVGAQ='}, {'type': 'web_search_result_location', 'cited_text': 'The pup lives with its family for approximately one year. ', 'url': 'https://en.wikipedia.org/wiki/Otter', 'title': 'Otter - Wikipedia', 'encrypted_index': 'EpABCioIBxgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDMpc9vgHWEkR7qQPKBoMNOpn/vh65jLyECF6IjBylHjGM6WAqjET1yTedQiv18CmwH9PcM00Qtsijr5TtMr22Afo1qdINJe0SVgJu6cqFI3bVuDMHWzpCsBcQ1pQpygQTZs9GAQ='}], [{'type': 'web_search_result_location', 'cited_text': 'Otters live up to 16 years; they are by nature playful, and frolic in the water with their pups. ', 'url': 'https://en.wikipedia.org/wiki/Otter', 'title': 'Otter - Wikipedia', 'encrypted_index': 'EpABCioIBxgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDHPWkoQveSjKfQ9R6xoMn7c3st6tGncBqwCSIjAow5bAhh1TjiEKG0f2wR7RZ88BoZmEjlBAqEScpa+bS9rYREE/FWe7ywQpeUCLYdYqFLmAS2+iQb1sHMdZHD/CVTbZGqmUGAQ='}], [{'type': 'web_search_result_location', 'cited_text': 'Otters and their mustelid relatives were once hunted extensively for their fur, many to the point of near extinction. Despite regulations designed to ...', 'url': 'https://www.nationalgeographic.com/animals/mammals/facts/otters-1', 'title': 'Otters, facts and information | National Geographic', 'encrypted_index': 'EpMBCioIBxgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDJ0L8G38DdPTqqBAHhoMkVBIfts2dm3HPRKRIjAgcSbpdy2q9VD9oDtpj0/bCHjO1mhrVjj90HBClf7uFup0ndxPHRp/DC8+3JtFN+4qF9Tk88Lj4ho6ZzD8OM24x4Y0tn9kFwmAGAQ='}]], 'thinking_blocks': None}))], usage=Usage(completion_tokens=532, prompt_tokens=13316, total_tokens=13848, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None), server_tool_use=ServerToolUse(web_search_requests=1), cache_creation_input_tokens=0, cache_read_input_tokens=0))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tool = { \"type\": \"web_search_20250305\", \"name\": \"web_search\", \"max_uses\": 3}\n",
    "smsg = mk_user(\"Search the web and tell me very briefly about otters\")\n",
    "r = completion(ms[1], [smsg], tools=[search_tool])\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaeeee1",
   "metadata": {
    "input_tokens": 25
   },
   "source": [
    "When not using streaming, all citations are placed in a separate key in the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84f8c8",
   "metadata": {
    "input_tokens": 24,
    "output_tokens": 459
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'web_search_result_location',\n",
       "  'cited_text': 'The charismatic otter, a member of the weasel family, is found on every continent except Australia and Antarctica. ',\n",
       "  'url': 'https://www.nationalgeographic.com/animals/mammals/facts/otters-1',\n",
       "  'title': 'Otters, facts and information | National Geographic',\n",
       "  'encrypted_index': 'Eo8BCioIBxgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDGSBf88S47DAweIwGhoMNZkbIflRzVJKEINOIjD/KVAIb0wABKB3JbDuVzoI+duKRiEWJxUFPg34RfUtoocpXjbS0n/A4z5bSsGJGX0qE4dOrL4dvQN149N3Db7KxKbXF3kYBA=='}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.choices[0].message.provider_specific_fields['citations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3ce342",
   "metadata": {
    "input_tokens": 31
   },
   "outputs": [],
   "source": [
    "r = list(completion(ms[1], [smsg], tools=[search_tool], stream=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc341e7e",
   "metadata": {
    "input_tokens": 150
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def cite_footnotes(stream_list):\n",
    "    \"Add markdown footnote citations to stream deltas\"\n",
    "    for msg in stream_list:\n",
    "        delta = nested_idx(msg, 'choices', 0, 'delta')\n",
    "        if not delta: continue\n",
    "        citation = nested_idx(delta, 'provider_specific_fields', 'citation')\n",
    "        if citation:\n",
    "            title = citation['title'].replace('\"', '\\\\\"')\n",
    "            delta.content = f'[*]({citation[\"url\"]} \"{title}\") '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2150365",
   "metadata": {
    "input_tokens": 16,
    "output_tokens": 1329
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Otters are [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") carnivorous mammals in the weasel family, found on every continent except Australia and Antarctica. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") There are 13-14 species in total, ranging from the small-clawed otter to the giant otter.\n",
       "\n",
       "[*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") Most are small, with short ears and noses, elongated bodies, long tails, and soft, dense fur. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") Otters have the densest fur of any animal—as many as a million hairs per square inch in places. [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") They have long, slim bodies with relatively short limbs and powerful webbed feet used for swimming.\n",
       "\n",
       "[*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") All otters are expert hunters that eat fish, crustaceans, and other critters. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") Sea otters use an ingenious method to open shellfish—floating on their backs, placing a rock on their chest, then smashing mollusks against it. [*](https://www.doi.gov/blog/12-facts-about-otters-sea-otter-awareness-week \"12 Facts About Otters for Sea Otter Awareness Week | U.S. Department of the Interior\") An otter's lung capacity is 2.5 times greater than similar-sized land mammals, with sea otters staying submerged for more than 5 minutes and river otters for up to 8 minutes.\n",
       "\n",
       "[*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") They are playful animals, engaging in activities like sliding into water on natural slides and playing with stones. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") When sea otters nap, they entangle themselves in kelp so they don't float away, and sometimes intertwine their feet with another sea otter to stay together.\n",
       "\n",
       "[*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") Otters were once hunted extensively for their fur, many to the point of near extinction, and despite regulations, many species remain at risk from pollution and habitat loss.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-47e5ae35-2e10-4663-9416-c52f991acb21`\n",
       "- model: `claude-sonnet-4-20250514`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=584, prompt_tokens=13316, total_tokens=13900, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-47e5ae35-2e10-4663-9416-c52f991acb21', created=1757396880, model='claude-sonnet-4-20250514', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Otters are [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") carnivorous mammals in the weasel family, found on every continent except Australia and Antarctica. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") There are 13-14 species in total, ranging from the small-clawed otter to the giant otter.\\n\\n[*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") Most are small, with short ears and noses, elongated bodies, long tails, and soft, dense fur. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") Otters have the densest fur of any animal—as many as a million hairs per square inch in places. [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") They have long, slim bodies with relatively short limbs and powerful webbed feet used for swimming.\\n\\n[*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") All otters are expert hunters that eat fish, crustaceans, and other critters. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") Sea otters use an ingenious method to open shellfish—floating on their backs, placing a rock on their chest, then smashing mollusks against it. [*](https://www.doi.gov/blog/12-facts-about-otters-sea-otter-awareness-week \"12 Facts About Otters for Sea Otter Awareness Week | U.S. Department of the Interior\") An otter\\'s lung capacity is 2.5 times greater than similar-sized land mammals, with sea otters staying submerged for more than 5 minutes and river otters for up to 8 minutes.\\n\\n[*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") They are playful animals, engaging in activities like sliding into water on natural slides and playing with stones. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") When sea otters nap, they entangle themselves in kelp so they don\\'t float away, and sometimes intertwine their feet with another sea otter to stay together.\\n\\n[*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") Otters were once hunted extensively for their fur, many to the point of near extinction, and despite regulations, many species remain at risk from pollution and habitat loss.', role='assistant', tool_calls=[], function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=584, prompt_tokens=13316, total_tokens=13900, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cite_footnotes(r)\n",
    "stream_chunk_builder(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29018310",
   "metadata": {
    "input_tokens": 3
   },
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9223dc",
   "metadata": {
    "input_tokens": 63
   },
   "source": [
    "Litellm is pretty bare bones. It doesnt keep track of conversation history or anything.\n",
    "\n",
    "So lets make a claudette style wrapper so we can do streaming, toolcalling, and toolloops without problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd81a7c",
   "metadata": {
    "input_tokens": 63
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "# TODO: dont like this var name...\n",
    "# TODO: make enum so type hints are nice\n",
    "effort = AttrDict({o[0]:o for o in ('low','medium','high')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266f3d5d",
   "metadata": {
    "input_tokens": 1000
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class Chat:\n",
    "    def __init__(self, model:str, sp='', temp=0, tools:list=None, hist:list=None, ns:Optional[dict]=None, cache=False):\n",
    "        \"LiteLLM chat client.\"\n",
    "        self.model = model\n",
    "        hist,tools = listify(hist),listify(tools)\n",
    "        if ns is None and tools: ns = mk_ns(tools)\n",
    "        elif ns is None: ns = globals()\n",
    "        self.tool_schemas = [_lite_mk_func(t) for t in tools] if tools else None\n",
    "        store_attr()\n",
    "    \n",
    "    def _prepare_msgs(self, msg=None, prefill=None):\n",
    "        \"Prepare the messages list for the API call\"\n",
    "        msgs = [{\"role\": \"system\", \"content\": self.sp}] if self.sp else []\n",
    "        self.hist += [mk_user(msg, cache=self.cache)] if isinstance(msg, str) \\\n",
    "            else [msg] if isinstance(msg, dict) \\\n",
    "            else [] if msg is None \\\n",
    "            else msg\n",
    "        if prefill and get_model_info(self.model)[\"supports_assistant_prefill\"]: \n",
    "            self.hist.append({\"role\":\"assistant\",\"content\":prefill})\n",
    "        return msgs + [m if isinstance(m, dict) else m.model_dump() for m in self.hist]\n",
    "\n",
    "    def _call(self, msg=None, prefill=None, temp=None, think=None, stream=False, max_tool_rounds=1, tool_round=0, final_prompt=None, tool_choice=None, **kwargs):\n",
    "        \"Internal method that always yields responses\"\n",
    "        msgs = self._prepare_msgs(msg, prefill)\n",
    "        res = completion(model=self.model, messages=msgs, stream=stream, \n",
    "                         tools=self.tool_schemas, reasoning_effort = effort.get(think),\n",
    "                         # temperature is not supported when reasoning\n",
    "                         temperature=None if think else (temp if temp is not None else self.temp), **kwargs)\n",
    "        if stream: res = yield from stream_with_complete(res, postproc=cite_footnotes)\n",
    "        m = res.choices[0].message\n",
    "        self.hist.append(m)\n",
    "        yield res\n",
    "\n",
    "        if tcs := m.tool_calls:\n",
    "            tool_results = [_lite_call_func(tc, ns=self.ns) for tc in tcs]\n",
    "            if tool_round>=max_tool_rounds-1:\n",
    "                tool_results += ([{\"role\": \"user\", \"content\": final_prompt}] if final_prompt else [])\n",
    "                tool_choice='none'\n",
    "            yield from self._call(\n",
    "                tool_results, stream, max_tool_rounds, tool_round+1,\n",
    "                final_prompt, tool_choice=tool_choice, **kwargs)\n",
    "    \n",
    "    def __call__(self, msg=None, prefill=None, temp=None, think=None, stream=False, max_tool_rounds=1,\n",
    "                 final_prompt=None, return_all=False, **kwargs):\n",
    "        \"Main call method - handles streaming vs non-streaming\"\n",
    "        result_gen = self._call(msg, prefill, temp, think, stream, max_tool_rounds, 0, final_prompt, **kwargs)     \n",
    "        if stream: return result_gen              # streaming\n",
    "        elif return_all: return list(result_gen)  # toolloop behavior\n",
    "        else: return last(result_gen)             # normal chat behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563e7178",
   "metadata": {
    "input_tokens": 6
   },
   "source": [
    "## Add prefill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3723e8",
   "metadata": {
    "input_tokens": 58
   },
   "source": [
    "Litellm supports `prefill` for models that have this feature. Note, it does not add your prefill to the response, so you'll have to do that yourself in post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc61f060",
   "metadata": {
    "input_tokens": 33,
    "output_tokens": 259
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "-ns! Nice to meet you. How are you doing today?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-2519bf61-03e9-4487-adee-63560158af1e`\n",
       "- model: `claude-sonnet-4-20250514`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=17, prompt_tokens=18, total_tokens=35, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None), cache_creation_input_tokens=0, cache_read_input_tokens=0)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-2519bf61-03e9-4487-adee-63560158af1e', created=1757396919, model='claude-sonnet-4-20250514', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='-ns! Nice to meet you. How are you doing today?', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=17, prompt_tokens=18, total_tokens=35, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None), cache_creation_input_tokens=0, cache_read_input_tokens=0))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(ms[1])\n",
    "chat(\"Hey my name is Rens\", prefill=\"Howdy Re\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbf319a",
   "metadata": {
    "input_tokens": 6
   },
   "source": [
    "### Test history tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ccd1e",
   "metadata": {
    "input_tokens": 25,
    "output_tokens": 294
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hi Rens! Nice to meet you. How can I help you today? 😊\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-CDlVYCRj8tekPIc0YXDdq0312VGFt`\n",
       "- model: `gpt-4.1-2025-04-14`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=17, prompt_tokens=13, total_tokens=30, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-CDlVYCRj8tekPIc0YXDdq0312VGFt', created=1757396920, model='gpt-4.1-2025-04-14', object='chat.completion', system_fingerprint='fp_3502f4eb73', choices=[Choices(finish_reason='stop', index=0, message=Message(content='Hi Rens! Nice to meet you. How can I help you today? 😊', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=17, prompt_tokens=13, total_tokens=30, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(m)\n",
    "res = chat(\"Hey my name is Rens\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5978da56",
   "metadata": {
    "input_tokens": 9,
    "output_tokens": 271
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your name is Rens!\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-CDlVZiSvndtoiiivjaMR7EaT0FoCp`\n",
       "- model: `gpt-4.1-2025-04-14`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=6, prompt_tokens=41, total_tokens=47, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-CDlVZiSvndtoiiivjaMR7EaT0FoCp', created=1757396921, model='gpt-4.1-2025-04-14', object='chat.completion', system_fingerprint='fp_daf5fcc80a', choices=[Choices(finish_reason='stop', index=0, message=Message(content='Your name is Rens!', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=6, prompt_tokens=41, total_tokens=47, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"Whats my name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb77c7",
   "metadata": {
    "input_tokens": 12
   },
   "source": [
    "See now we keep track of history!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46716033",
   "metadata": {
    "input_tokens": 4
   },
   "source": [
    "### Testing streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe74496",
   "metadata": {
    "input_tokens": 100
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "chat2 = Chat(m)\n",
    "stream_gen = chat2(\"Count to 5\", stream=True)\n",
    "for chunk in stream_gen:\n",
    "    sleep(0.1)  # for effect\n",
    "    if isinstance(chunk, ModelResponse): display(chunk)\n",
    "    else: print(delta_text(chunk) or '',end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8c3666",
   "metadata": {
    "input_tokens": 6
   },
   "source": [
    "## Test tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf17377a",
   "metadata": {
    "input_tokens": 9
   },
   "source": [
    "Ok now lets test tool use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4cf429",
   "metadata": {
    "input_tokens": 63
   },
   "outputs": [],
   "source": [
    "for m in ms:\n",
    "    display(f'=== {m} ===')\n",
    "    chat = Chat(m, tools=[simple_add])\n",
    "    res = chat(\"What's 5 + 3?\")\n",
    "    display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9a499",
   "metadata": {
    "input_tokens": 99
   },
   "outputs": [],
   "source": [
    "chat = Chat(ms[1], tools=[search_tool])\n",
    "res = chat(\"Search the web and tell me very briefly about otters\", stream=True)\n",
    "for o in res:\n",
    "    if isinstance(o, ModelResponse): sleep(0.01); display(o)\n",
    "    else: print(delta_text(o) or '',end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cce2d9",
   "metadata": {
    "input_tokens": 7
   },
   "source": [
    "## Test multi tool calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662f7aa3",
   "metadata": {
    "input_tokens": 73
   },
   "outputs": [],
   "source": [
    "chat = Chat(model, tools=[simple_add])\n",
    "res = chat(\"What's ((5 + 3)+7)+11? Work step by step\", return_all=True, max_tool_rounds=5)\n",
    "for r in res: display(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9de676",
   "metadata": {
    "input_tokens": 87
   },
   "outputs": [],
   "source": [
    "@patch(as_prop=True)\n",
    "def cost(self: Chat):\n",
    "    \"Total cost of all responses in conversation history\"\n",
    "    return sum(getattr(r, '_hidden_params', {}).get('response_cost')  or 0\n",
    "               for r in self.h if hasattr(r, 'choices'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f66101",
   "metadata": {
    "input_tokens": 30
   },
   "source": [
    "Some models support parallel tool calling. I.e. sending multiple tool call requests in one conversation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec77539",
   "metadata": {
    "input_tokens": 136
   },
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"Multiply two numbers\"\n",
    "    print(f\"MULTIPLY: {a} * {b}\")\n",
    "    return a * b\n",
    "\n",
    "chat = Chat(ms[-1], tools=[simple_add, multiply])\n",
    "res = chat(\"Calculate (5 + 3) * (7 + 2)\", max_tool_rounds=5, return_all=True)\n",
    "for r in res: display(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba4958f",
   "metadata": {
    "input_tokens": 13
   },
   "source": [
    "See it did the additions in one go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b17e71",
   "metadata": {
    "input_tokens": 13
   },
   "source": [
    "Hit max_tool_rounds limit with final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7298c0",
   "metadata": {
    "input_tokens": 183
   },
   "outputs": [],
   "source": [
    "def divide(a: int, b: int) -> float:\n",
    "    \"Divide two numbers\"\n",
    "    display(f\"DIVIDE: {a} / {b}\")\n",
    "    return a / b\n",
    "\n",
    "chat = Chat(m, tools=[simple_add, multiply, divide])\n",
    "res = chat(\"Calculate ((10 + 5) * 3) / (2 + 1) step by step\", \n",
    "           max_tool_rounds=2, return_all=True,\n",
    "           final_prompt=\"Please summarize what you've calculated so far\")\n",
    "print(f\"Got {len(res)} responses\")\n",
    "for r in res: display(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9764dc",
   "metadata": {
    "input_tokens": 3
   },
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e677e0c",
   "metadata": {
    "input_tokens": 21
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78ee53b",
   "metadata": {
    "input_tokens": 9
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d383f1d",
   "metadata": {
    "input_tokens": 28
   },
   "outputs": [],
   "source": [
    "fn = Path('samples/puppy.jpg')\n",
    "Image(filename=fn, width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d71207",
   "metadata": {
    "input_tokens": 96
   },
   "outputs": [],
   "source": [
    "def _mk_img(data:bytes)->tuple:\n",
    "    \"Convert image bytes to a base64 encoded image\"\n",
    "    img = base64.b64encode(data).decode(\"utf-8\")\n",
    "    mtype = mimetypes.types_map[\".\"+imghdr.what(None, h=data)]\n",
    "    return img, mtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979360f0",
   "metadata": {
    "input_tokens": 24
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import mimetypes\n",
    "from fastcore import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac27e13",
   "metadata": {
    "input_tokens": 70
   },
   "outputs": [],
   "source": [
    "imgbytes = fn.read_bytes()\n",
    "img,mtype = _mk_img(imgbytes)\n",
    "imgd = { \"image_url\": {\"url\": f'data:{mtype};base64,{img}', \"format\":mtype} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108e17ca",
   "metadata": {
    "input_tokens": 85
   },
   "outputs": [],
   "source": [
    "response = completion( model=model, \n",
    "    messages=[\n",
    "        { \"role\": \"user\",\n",
    "        \"content\": [{ \"type\": \"text\", \"text\": \"What’s in this image?\" },\n",
    "        { \"type\": \"image_url\", **imgd }] }\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae33d10f",
   "metadata": {
    "input_tokens": 1
   },
   "outputs": [],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "learning",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
