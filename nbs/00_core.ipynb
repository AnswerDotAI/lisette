{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "798b1171",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> Lisette Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd7861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from cachy import enable_cachy,disable_cachy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e5b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "enable_cachy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82380377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import asyncio, base64, json, litellm, mimetypes, random, string, ast\n",
    "from typing import Optional,Callable\n",
    "from html import escape\n",
    "from litellm import (acompletion, completion, stream_chunk_builder, Message,\n",
    "                     ModelResponse, ModelResponseStream, get_model_info, register_model, Usage)\n",
    "from litellm.utils import function_to_dict, StreamingChoices, Delta, ChatCompletionMessageToolCall, Function, Choices\n",
    "from toolslm.funccall import mk_ns, call_func, call_func_async, get_schema\n",
    "from fastcore.utils import *\n",
    "from fastcore.meta import delegates\n",
    "from fastcore import imghdr\n",
    "from dataclasses import dataclass\n",
    "from litellm.exceptions import ContextWindowExceededError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import *\n",
    "from IPython.display import Markdown, Image, Audio, Video\n",
    "import httpx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f20759",
   "metadata": {},
   "source": [
    "# LiteLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a774f",
   "metadata": {},
   "source": [
    "## Deterministic outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dfd53d",
   "metadata": {},
   "source": [
    "LiteLLM `ModelResponse(Stream)` objects have `id` and `created_at` fields that are generated dynamically. Even when we use [`cachy`](https://github.com/answerdotai/cachy) to cache the LLM response these dynamic fields create diffs which makes code review more challenging. The patches below ensure that `id` and `created_at` fields are fixed and won't generate diffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c28e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def patch_litellm(seed=0):\n",
    "    \"Patch litellm.ModelResponseBase such that `id` and `created` are fixed.\"\n",
    "    from litellm.types.utils import ModelResponseBase, ChatCompletionMessageToolCall\n",
    "    from uuid import UUID\n",
    "    from base64 import b64encode\n",
    "    if seed is not None: random.seed(seed) # ensures random ids like tool call ids are deterministic\n",
    "    \n",
    "    @patch\n",
    "    def __init__(self: ModelResponseBase, id=None, created=None, *args, **kwargs): \n",
    "        self._orig___init__(id='chatcmpl-xxx', created=1000000000, *args, **kwargs)\n",
    "\n",
    "    @patch\n",
    "    def __setattr__(self: ModelResponseBase, name, value):\n",
    "        if name == 'id': value = 'chatcmpl-xxx'\n",
    "        elif name == 'created': value = 1000000000\n",
    "        self._orig___setattr__(name, value)\n",
    "\n",
    "    def _unqid():\n",
    "        res = b64encode(UUID(int=random.getrandbits(128), version=4).bytes)\n",
    "        return '_' + res.decode().rstrip('=').translate(str.maketrans('+/', '__'))  # both to underscore for srvtoolu_ pattern\n",
    "\n",
    "    # @patch\n",
    "    # def __init__(self: ChatCompletionMessageToolCall, function=None, id=None, type=\"function\", **kwargs):\n",
    "    #     # we keep the tool call prefix if it exists, this is needed for example to handle srvtoolu_ correctly.\n",
    "    #     id = id.split('_')[0]+_unqid() if id and '_' in id else id\n",
    "    #     self._orig___init__(function=function, id=id, type=type, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e05085",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_litellm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfbbaf6",
   "metadata": {},
   "source": [
    "## Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c4ea2",
   "metadata": {},
   "source": [
    "LiteLLM provides an convenient unified interface for most big LLM providers. Because it's so useful to be able to switch LLM providers with just one argument. We want to make it even easier to by adding some more convenience functions and classes. \n",
    "\n",
    "This is very similar to our other wrapper libraries for popular AI providers: [claudette](https://claudette.answer.ai/) (Anthropic), [gaspard](https://github.com/AnswerDotAI/gaspard) (Gemini), [cosette](https://answerdotai.github.io/cosette/) (OpenAI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61cf441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _repr_markdown_(self: litellm.ModelResponse):\n",
    "    message = self.choices[0].message\n",
    "    content = ''\n",
    "    if mc:=message.content: content += mc[0]['text'] if isinstance(mc,list) else mc\n",
    "    if message.tool_calls:\n",
    "        tool_calls = [f\"\\n\\nðŸ”§ {nested_idx(tc,'function','name')}({nested_idx(tc,'function','arguments')})\\n\" for tc in message.tool_calls]\n",
    "        content += \"\\n\".join(tool_calls)\n",
    "    for img in getattr(message, 'images', []): content += f\"\\n\\n![generated image]({nested_idx(img, 'image_url', 'url')})\"\n",
    "    if not content: content = str(message)\n",
    "    details = [\n",
    "        f\"id: `{self.id}`\",\n",
    "        f\"model: `{self.model}`\",\n",
    "        f\"finish_reason: `{self.choices[0].finish_reason}`\"\n",
    "    ]\n",
    "    if hasattr(self, 'usage') and self.usage: details.append(f\"usage: `{self.usage}`\")\n",
    "    det_str = '\\n- '.join(details)\n",
    "    \n",
    "    return f\"\"\"{content}\n",
    "\n",
    "<details>\n",
    "\n",
    "- {det_str}\n",
    "\n",
    "</details>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dcaa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "register_model({\"claude-sonnet-4-6\": dict(get_model_info(\"claude-sonnet-4-5\"))})\n",
    "\n",
    "sonn45 = \"claude-sonnet-4-5\"\n",
    "sonn46 = \"claude-sonnet-4-6\"\n",
    "opus45 = \"claude-opus-4-5\"\n",
    "opus46 = \"claude-opus-4-6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80b76a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Opus requires beta header for very expensive >200k tokens, so disable\n",
    "info = dict(get_model_info(\"claude-opus-4-6\"))\n",
    "info['max_input_tokens'] = 200_000\n",
    "register_model({\"claude-opus-4-6\": info})\n",
    "get_model_info.cache_clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf2d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# litellm._turn_on_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a6f62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**gemini/gemini-3-pro-preview:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**gemini/gemini-3-pro-preview:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Hi! How are you doing today?**\n",
       "\n",
       "I'm ready to help with whatever you needâ€”whether it's writing, answering questions, brainstorming ideas, or just chatting. What's on your mind?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-pro-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=152, prompt_tokens=4, total_tokens=156, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=107, rejected_prediction_tokens=None, text_tokens=45, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=4, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-pro-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"**Hi! How are you doing today?**\\n\\nI'm ready to help with whatever you needâ€”whether it's writing, answering questions, brainstorming ideas, or just chatting. What's on your mind?\", role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['Es4DCssDAb4+9vsBPaSKRXTdBoapKBt6tqzvEuHFbufcDKry7bUM319AvhO81Uk3Pzms4b2CDiSJuxZy8sGtNLKiMSV3+PfeP3sfghiwme5sSviio8KfEh6QAKdm2pJPoCEGC8eMA/eqW/Yk92+Juw7l+wZ/e8V5+YXddvKgTujPbMx9+2hBfmgmbmEo//XBdJm3jiZpMiQPPlwlNgIxvjgDWZeuQ+uykEso0ydxmXXgfsEE5LqKcvVKMp3Ce5KG3UgOrgqCmqfCMGWeLtsCP16zAv4K2UqqaOftxFQOtbYAjDGqtpCfwjiFtPDEY/+rV6Opf0QRxyzif3MfE7l6IsUsFxUzOas/z/AaaIMI/aBc9HD7CVrZAZWDmN0sPYzusA26/VOefmANi8UBmJnhrTq/m2r4hzZpy+DgXffvVVD7wXjMGzaylopV+vPuLaQqsnFneoacKUFpJHyWUPqfY+ruAgwxRDWRVXk+OM1VqZYGz8FlsRFiNjn7oUeBNb+sZ1mXZXQJrP2nh1cdazOFti+UTHs2U/9nhUphAgeUGVNCtDEuiFgRj8VhooSRI2XFb8ZDCAepz9uJ4C+zEjV02EgjmnUUNtXFgfQdktQnsLIp']}))], usage=Usage(completion_tokens=152, prompt_tokens=4, total_tokens=156, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=107, rejected_prediction_tokens=None, text_tokens=45, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=4, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**gemini/gemini-3-flash-preview:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**gemini/gemini-3-flash-preview:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I help you today?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=9, prompt_tokens=4, total_tokens=13, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=9, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=4, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Hello! How can I help you today?', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7lX1PrtTl2GxEUSsk1dy+8xDGtNDaviYl/X6s26CyxUdgLbhrAj8lqsXLVM8p']}))], usage=Usage(completion_tokens=9, prompt_tokens=4, total_tokens=13, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=9, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=4, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**claude-opus-4-6:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**claude-opus-4-6:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hey there! ðŸ‘‹ How's it going? What can I help you with today?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=23, prompt_tokens=10, total_tokens=33, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=23, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Hey there! ðŸ‘‹ How's it going? What can I help you with today?\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=23, prompt_tokens=10, total_tokens=33, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=23, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**openai/gpt-4.1:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**openai/gpt-4.1:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I help you today? ðŸ˜Š\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gpt-4.1-2025-04-14`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=10, prompt_tokens=10, total_tokens=20, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gpt-4.1-2025-04-14', object='chat.completion', system_fingerprint='fp_2240633f8e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='Hello! How can I help you today? ðŸ˜Š', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=10, prompt_tokens=10, total_tokens=20, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ms = [\"gemini/gemini-3-pro-preview\", \"gemini/gemini-3-flash-preview\", \"claude-opus-4-6\", \"openai/gpt-4.1\"]\n",
    "msg = [{'role':'user','content':'Hey there!', 'cache_control': {'type': 'ephemeral'}}]\n",
    "for m in ms:\n",
    "    display(Markdown(f'**{m}:**'))\n",
    "    display(completion(m,msg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4841816e",
   "metadata": {},
   "source": [
    "Generated images are also displayed (not shown here to conserve filesize):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a027b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completion(model='gemini/gemini-2.5-flash-image', messages=[{'role':'user','content':'Draw a simple sketch of a cat'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715fff5a",
   "metadata": {},
   "source": [
    "## Messages formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5671bcb0",
   "metadata": {},
   "source": [
    "Let's start with making it easier to pass messages into litellm's `completion` function (including images, and pdf files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c8b8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _bytes2content(data):\n",
    "    \"Convert bytes to litellm content dict (image, pdf, audio, video)\"\n",
    "    mtype = detect_mime(data)\n",
    "    if not mtype: raise ValueError(f'Data must be a supported file type, got {data[:10]}')\n",
    "    encoded = base64.b64encode(data).decode(\"utf-8\")    \n",
    "    if mtype.startswith('image/'): return {'type': 'image_url', 'image_url': f'data:{mtype};base64,{encoded}'}\n",
    "    return {'type': 'file', 'file': {'file_data': f'data:{mtype};base64,{encoded}'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6ee78",
   "metadata": {},
   "source": [
    "If `msg` has `tool_calls`, `cache_control` is added to the last tool call (required since LiteLLM strips it from empty content blocks), otherwise to the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef65f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _add_cache_control(msg,          # LiteLLM formatted msg\n",
    "                       ttl=None):    # Cache TTL: '5m' (default) or '1h'\n",
    "    \"cache `msg` with default time-to-live (ttl) of 5minutes ('5m'), but can be set to '1h'.\"\n",
    "    cc = {\"type\": \"ephemeral\"} | ({\"ttl\": ttl} if ttl else {})\n",
    "    if tcs := msg.get('tool_calls'):\n",
    "        tcs[-1]['cache_control'] = cc\n",
    "        return msg\n",
    "    if not (content := msg.get(\"content\")): return msg\n",
    "    if isinstance(content, str): msg[\"content\"] = [{\"type\": \"text\", \"text\": content}]\n",
    "    if msg[\"content\"] and msg[\"content\"][-1].get(\"text\"):\n",
    "        msg[\"content\"][-1][\"cache_control\"] = cc\n",
    "    return msg\n",
    "\n",
    "def _has_cache(msg):\n",
    "    \"Check if msg has cache_control set\"\n",
    "    if tcs := msg.get('tool_calls'): return 'cache_control' in tcs[-1]\n",
    "    content = msg.get(\"content\")\n",
    "    return content and isinstance(content, list) and 'cache_control' in content[-1]\n",
    "\n",
    "def remove_cache_ckpts(msg):\n",
    "    \"remove cache checkpoints and return msg.\"\n",
    "    if not _has_cache(msg): return msg\n",
    "    if tcs := msg.get('tool_calls'):\n",
    "        tc = tcs[-1]\n",
    "        if isinstance(tc, dict): tc.pop('cache_control', None)\n",
    "        elif isinstance(tc, ChatCompletionMessageToolCall): delattr(tc, 'cache_control')\n",
    "    elif msg.get('content'): msg[\"content\"][-1].pop('cache_control', None)\n",
    "    return msg\n",
    "\n",
    "def _mk_content(o):\n",
    "    if isinstance(o, str): return {'type':'text','text':o.strip() or '.'}\n",
    "    elif isinstance(o,bytes): return _bytes2content(o)\n",
    "    return o\n",
    "\n",
    "def contents(r):\n",
    "    \"Get message object from response `r`.\"\n",
    "    if not r.choices: return ''\n",
    "    return r.choices[0].message\n",
    "\n",
    "def stop_reason(r):\n",
    "    if not r.choices: return 'unk'\n",
    "    return r.choices[0].finish_reason"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad8eddd",
   "metadata": {},
   "source": [
    "Test with regular content message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ea44f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_content = {'role': 'user', 'content': [{'type': 'text', 'text': 'hello'}]}\n",
    "_add_cache_control(msg_content)\n",
    "test_eq(msg_content['content'][-1].get('cache_control'), {'type': 'ephemeral'})\n",
    "test_eq(_has_cache(msg_content), True)\n",
    "remove_cache_ckpts(msg_content)\n",
    "test_eq(_has_cache(msg_content), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4685f8f",
   "metadata": {},
   "source": [
    "Test with assistant message with tool_calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd1da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcs = [\n",
    "    {'id': 'tc1', 'type': 'function', 'function': {'name': 'test', 'arguments': '{}'}},\n",
    "    {'id': 'tc2', 'type': 'function', 'function': {'name': 'test', 'arguments': '{}'}}\n",
    "]\n",
    "msg_tool = {'role': 'assistant', 'content': '', 'tool_calls': tcs}\n",
    "_add_cache_control(msg_tool)\n",
    "test_eq(msg_tool['tool_calls'][-1].get('cache_control'), {'type': 'ephemeral'})\n",
    "test_eq('cache_control' not in msg_tool.get('content', [{}])[-1] if msg_tool.get('content') else True, True)  # no cache in content\n",
    "test_eq(_has_cache(msg_tool), True)\n",
    "remove_cache_ckpts(msg_tool)\n",
    "test_eq(_has_cache(msg_tool), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a67317",
   "metadata": {},
   "source": [
    "Test with `ChatCompletionMessageToolCall` tool call object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd5cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcs =[\n",
    "    ChatCompletionMessageToolCall(id='tc1', type='function', function=Function(name='test', arguments='{}')), \n",
    "    ChatCompletionMessageToolCall(id='tc2', type='function', function=Function(name='test', arguments='{}'))\n",
    "]\n",
    "msg_tc_obj = {'role': 'assistant', 'content': '', 'tool_calls': tcs}\n",
    "_add_cache_control(msg_tc_obj)\n",
    "test_eq(getattr(msg_tc_obj['tool_calls'][-1], 'cache_control', None), {'type': 'ephemeral'})\n",
    "test_eq(_has_cache(msg_tc_obj), True)\n",
    "remove_cache_ckpts(msg_tc_obj)\n",
    "test_eq(_has_cache(msg_tc_obj), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb67a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_msg(\n",
    "    content,      # Content: str, bytes (image), list of mixed content, or dict w 'role' and 'content' fields\n",
    "    role=\"user\",  # Message role if content isn't already a dict/Message\n",
    "    cache=False,  # Enable Anthropic caching\n",
    "    ttl=None      # Cache TTL: '5m' (default) or '1h'\n",
    "):\n",
    "    \"Create a LiteLLM compatible message.\"\n",
    "    if content is None: return None\n",
    "    if isinstance(content, dict) or isinstance(content, Message): return content\n",
    "    if isinstance(content, ModelResponse): return contents(content)\n",
    "    if isinstance(content, list) and len(content) == 1 and isinstance(content[0], str): c = content[0]\n",
    "    elif isinstance(content, list): c = [_mk_content(o) for o in content]\n",
    "    else: c = content\n",
    "    msg = {\"role\": role, \"content\": c}\n",
    "    return _add_cache_control(msg, ttl=ttl) if cache else msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da39f96f",
   "metadata": {},
   "source": [
    "Now we can use mk_msg to create different types of messages.\n",
    "\n",
    "Simple text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6217f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user', 'content': 'hey'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = mk_msg(\"hey\")\n",
    "msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a922030e",
   "metadata": {},
   "source": [
    "Which can be passed to litellm's `completion` function like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1295ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ms[1] # use 2.5-pro, 3-pro is very slow even to run tests as of making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a28656f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hey there! How can I help you today?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=10, prompt_tokens=2, total_tokens=12, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=10, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=2, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Hey there! How can I help you today?', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7/wjE9HWq6jd0Cw1NK9psKYqcjKQMaMwmICpnWNY8h89F9UMLyXHiABEi4VqJ']}))], usage=Usage(completion_tokens=10, prompt_tokens=2, total_tokens=12, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=10, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=2, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = completion(model, [msg])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68485b58",
   "metadata": {},
   "source": [
    "We'll add a little shortcut to make examples and testing easier here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d8df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(msgs, m=model, **kw):\n",
    "    msgs = [msgs] if isinstance(msgs,dict) else listify(msgs)\n",
    "    return completion(m, msgs, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0186ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hey there! How can I help you today?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=10, prompt_tokens=2, total_tokens=12, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=10, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=2, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Hey there! How can I help you today?', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7/wjE9HWq6jd0Cw1NK9psKYqcjKQMaMwmICpnWNY8h89F9UMLyXHiABEi4VqJ']}))], usage=Usage(completion_tokens=10, prompt_tokens=2, total_tokens=12, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=10, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=2, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552e1298",
   "metadata": {},
   "source": [
    "Lists w just one string element are flattened for conciseness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a0955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(mk_msg(\"hey\"), mk_msg([\"hey\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001e399e",
   "metadata": {},
   "source": [
    "(LiteLLM ignores these fields when sent to other providers)\n",
    "\n",
    "Text and images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923e6c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "Image(b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xe2\\x0cTICC_PROFILE\\x00\\x01\\x01\\x00\\x00\\x0cDUCCM\\x02@\\x00\\x00mntrRGB XYZ \\x07\\xd3\\x00\\x04\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00acspMSFT\\x00\\x00\\x00\\x00CANOZ009\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xf6\\xd6\\x00\\x01\\x00\\x00\\x00\\x00\\xd3-CANO\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0erTRC\\x00\\x00\\x01,\\x00\\x00\\x08\\x0cgTRC\\x00\\x00\\x01,\\x00\\x00\\x08\\x0cbTRC\\x00\\x00\\x01,\\x00\\x00\\x08\\x0crXYZ\\x00\\x00\\t8\\x00\\x00\\x00\\x14gXYZ\\x00\\x00\\tL\\x00\\x00\\x00\\x14bXYZ\\x00\\x00\\t`\\x00\\x00\\x00\\x14chad\\x00\\x00\\tt\\x00\\x00\\x00,cprt\\x00\\x00\\t\\xa0\\x00\\x00\\x00@dmnd\\x00\\x00\\t\\xe0\\x00\\x00\\x00|dmdd\\x00\\x00\\n\\\\\\x00\\x00\\x00\\x94wtpt\\x00\\x00\\n\\xf0\\x00\\x00\\x00\\x14tech\\x00\\x00\\x0b\\x04\\x00\\x00\\x00\\x0cdesc\\x00\\x00\\n\\\\\\x00\\x00\\x00\\x94ucmI\\x00\\x00\\x0b\\x10\\x00\\x00\\x014curv\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x04\\x00\\t\\x00\\x0e\\x00\\x13\\x00\\x18\\x00\\x1d\\x00\"\\x00\\'\\x00,\\x001\\x006\\x00;\\x00@\\x00E\\x00J\\x00O\\x00T\\x00Y\\x00^\\x00c\\x00h\\x00m\\x00r\\x00v\\x00{\\x00\\x80\\x00\\x85\\x00\\x8a\\x00\\x8f\\x00\\x94\\x00\\x99\\x00\\x9e\\x00\\xa3\\x00\\xa8\\x00\\xad\\x00\\xb2\\x00\\xb7\\x00\\xbc\\x00\\xc1\\x00\\xc6\\x00\\xcb\\x00\\xd0\\x00\\xd5\\x00\\xda\\x00\\xdf\\x00\\xe5\\x00\\xea\\x00\\xf0\\x00\\xf5\\x00\\xfb\\x01\\x01\\x01\\x06\\x01\\x0c\\x01\\x12\\x01\\x18\\x01\\x1e\\x01$\\x01+\\x011\\x017\\x01>\\x01D\\x01K\\x01R\\x01Y\\x01_\\x01f\\x01m\\x01u\\x01|\\x01\\x83\\x01\\x8a\\x01\\x92\\x01\\x99\\x01\\xa1\\x01\\xa9\\x01\\xb0\\x01\\xb8\\x01\\xc0\\x01\\xc8\\x01\\xd0\\x01\\xd8\\x01\\xe1\\x01\\xe9\\x01\\xf1\\x01\\xfa\\x02\\x02\\x02\\x0b\\x02\\x14\\x02\\x1d\\x02&\\x02/\\x028\\x02A\\x02J\\x02S\\x02]\\x02f\\x02p\\x02z\\x02\\x83\\x02\\x8d\\x02\\x97\\x02\\xa1\\x02\\xac\\x02\\xb6\\x02\\xc0\\x02\\xca\\x02\\xd5\\x02\\xe0\\x02\\xea\\x02\\xf5\\x03\\x00\\x03\\x0b\\x03\\x16\\x03!\\x03,\\x037\\x03C\\x03N\\x03Z\\x03f\\x03q\\x03}\\x03\\x89\\x03\\x95\\x03\\xa1\\x03\\xad\\x03\\xba\\x03\\xc6\\x03\\xd3\\x03\\xdf\\x03\\xec\\x03\\xf9\\x04\\x06\\x04\\x13\\x04 \\x04-\\x04:\\x04G\\x04U\\x04b\\x04p\\x04~\\x04\\x8c\\x04\\x9a\\x04\\xa8\\x04\\xb6\\x04\\xc4\\x04\\xd2\\x04\\xe1\\x04\\xef\\x04\\xfe\\x05\\r\\x05\\x1b\\x05*\\x059\\x05H\\x05X\\x05g\\x05v\\x05\\x86\\x05\\x95\\x05\\xa5\\x05\\xb5\\x05\\xc5\\x05\\xd5\\x05\\xe5\\x05\\xf5\\x06\\x05\\x06\\x16\\x06&\\x067\\x06H\\x06X\\x06i\\x06z\\x06\\x8b\\x06\\x9d\\x06\\xae\\x06\\xbf\\x06\\xd1\\x06\\xe3\\x06\\xf4\\x07\\x06\\x07\\x18\\x07*\\x07<\\x07O\\x07a\\x07s\\x07\\x86\\x07\\x99\\x07\\xab\\x07\\xbe\\x07\\xd1\\x07\\xe4\\x07\\xf8\\x08\\x0b\\x08\\x1e\\x082\\x08E\\x08Y\\x08m\\x08\\x81\\x08\\x95\\x08\\xa9\\x08\\xbe\\x08\\xd2\\x08\\xe6\\x08\\xfb\\t\\x10\\t$\\t9\\tN\\td\\ty\\t\\x8e\\t\\xa4\\t\\xb9\\t\\xcf\\t\\xe5\\t\\xfb\\n\\x11\\n\\'\\n=\\nS\\nj\\n\\x80\\n\\x97\\n\\xae\\n\\xc5\\n\\xdc\\n\\xf3\\x0b\\n\\x0b!\\x0b9\\x0bP\\x0bh\\x0b\\x80\\x0b\\x98\\x0b\\xb0\\x0b\\xc8\\x0b\\xe0\\x0b\\xf9\\x0c\\x11\\x0c*\\x0cB\\x0c[\\x0ct\\x0c\\x8d\\x0c\\xa6\\x0c\\xc0\\x0c\\xd9\\x0c\\xf2\\r\\x0c\\r&\\r@\\rZ\\rt\\r\\x8e\\r\\xa8\\r\\xc3\\r\\xdd\\r\\xf8\\x0e\\x13\\x0e.\\x0eI\\x0ed\\x0e\\x7f\\x0e\\x9a\\x0e\\xb6\\x0e\\xd1\\x0e\\xed\\x0f\\t\\x0f%\\x0fA\\x0f]\\x0fy\\x0f\\x96\\x0f\\xb2\\x0f\\xcf\\x0f\\xec\\x10\\t\\x10&\\x10C\\x10`\\x10}\\x10\\x9b\\x10\\xb9\\x10\\xd6\\x10\\xf4\\x11\\x12\\x110\\x11N\\x11m\\x11\\x8b\\x11\\xaa\\x11\\xc8\\x11\\xe7\\x12\\x06\\x12%\\x12D\\x12d\\x12\\x83\\x12\\xa3\\x12\\xc2\\x12\\xe2\\x13\\x02\\x13\"\\x13B\\x13c\\x13\\x83\\x13\\xa4\\x13\\xc4\\x13\\xe5\\x14\\x06\\x14\\'\\x14H\\x14i\\x14\\x8b\\x14\\xac\\x14\\xce\\x14\\xf0\\x15\\x11\\x154\\x15V\\x15x\\x15\\x9a\\x15\\xbd\\x15\\xdf\\x16\\x02\\x16%\\x16H\\x16k\\x16\\x8f\\x16\\xb2\\x16\\xd5\\x16\\xf9\\x17\\x1d\\x17A\\x17e\\x17\\x89\\x17\\xad\\x17\\xd2\\x17\\xf6\\x18\\x1b\\x18@\\x18e\\x18\\x8a\\x18\\xaf\\x18\\xd4\\x18\\xfa\\x19\\x1f\\x19E\\x19k\\x19\\x91\\x19\\xb7\\x19\\xdd\\x1a\\x03\\x1a*\\x1aP\\x1aw\\x1a\\x9e\\x1a\\xc5\\x1a\\xec\\x1b\\x13\\x1b;\\x1bb\\x1b\\x8a\\x1b\\xb1\\x1b\\xd9\\x1c\\x01\\x1c)\\x1cR\\x1cz\\x1c\\xa3\\x1c\\xcb\\x1c\\xf4\\x1d\\x1d\\x1dF\\x1do\\x1d\\x99\\x1d\\xc2\\x1d\\xec\\x1e\\x16\\x1e?\\x1ei\\x1e\\x93\\x1e\\xbe\\x1e\\xe8\\x1f\\x13\\x1f=\\x1fh\\x1f\\x93\\x1f\\xbe\\x1f\\xe9 \\x15 @ l \\x97 \\xc3 \\xef!\\x1b!H!t!\\xa1!\\xcd!\\xfa\"\\'\"T\"\\x81\"\\xaf\"\\xdc#\\n#7#e#\\x93#\\xc2#\\xf0$\\x1e$M$|$\\xaa$\\xd9%\\x08%8%g%\\x97%\\xc6%\\xf6&&&V&\\x86&\\xb7&\\xe7\\'\\x18\\'I\\'y\\'\\xaa\\'\\xdc(\\r(>(p(\\xa2(\\xd4)\\x06)8)j)\\x9d)\\xcf*\\x02*5*h*\\x9b*\\xce+\\x01+5+i+\\x9d+\\xd1,\\x05,9,m,\\xa2,\\xd7-\\x0b-@-u-\\xab-\\xe0.\\x16.K.\\x81.\\xb7.\\xed/#/Z/\\x90/\\xc7/\\xfe050l0\\xa30\\xda1\\x121J1\\x811\\xb91\\xf12*2b2\\x9b2\\xd33\\x0c3E3~3\\xb73\\xf14*4d4\\x9e4\\xd85\\x125L5\\x875\\xc15\\xfc676r6\\xad6\\xe87$7_7\\x9b7\\xd78\\x138O8\\x8c8\\xc89\\x059A9~9\\xbb9\\xf9:6:s:\\xb1:\\xef;-;k;\\xa9;\\xe7<&<e<\\xa4<\\xe3=\"=a=\\xa0=\\xe0> >`>\\xa0>\\xe0? ?a?\\xa1?\\xe2@#@d@\\xa5@\\xe7A(AjA\\xacA\\xeeB0BrB\\xb4B\\xf7C:C}C\\xc0D\\x03DFD\\x8aD\\xcdE\\x11EUE\\x99E\\xddF\"FfF\\xabF\\xf0G5GzG\\xbfH\\x05HJH\\x90H\\xd6I\\x1cIbI\\xa9I\\xefJ6J}J\\xc4K\\x0bKRK\\x9aK\\xe1L)LqL\\xb9M\\x02MJM\\x92M\\xdbN$NmN\\xb6O\\x00OIO\\x93O\\xdcP&PpP\\xbbQ\\x05QPQ\\x9aQ\\xe5R0R|R\\xc7S\\x12S^S\\xaaS\\xf6TBT\\x8eT\\xdbU\\'UtU\\xc1V\\x0eV[V\\xa9V\\xf6WDW\\x92W\\xe0X.X|X\\xcbY\\x1aYhY\\xb7Z\\x07ZVZ\\xa5Z\\xf5[E[\\x95[\\xe5\\\\5\\\\\\x85\\\\\\xd6]\\']w]\\xc9^\\x1a^k^\\xbd_\\x0e_`_\\xb2`\\x04`W`\\xa9`\\xfcaOa\\xa2a\\xf5bHb\\x9bb\\xefcCc\\x97c\\xebd?d\\x94d\\xe8e=e\\x92e\\xe7f<f\\x92f\\xe7g=g\\x93g\\xe9h?h\\x95h\\xeciCi\\x99i\\xf0jHj\\x9fj\\xf7kNk\\xa6k\\xfelVl\\xafm\\x07m`m\\xb9n\\x11nkn\\xc4o\\x1dowo\\xd1p+p\\x85p\\xdfq:q\\x94q\\xefrJr\\xa5s\\x01s\\\\s\\xb8t\\x13tot\\xccu(u\\x84u\\xe1v>v\\x9bv\\xf8wUw\\xb3x\\x10xnx\\xccy*y\\x88y\\xe7zEz\\xa4{\\x03{b{\\xc1|!|\\x81|\\xe0}@}\\xa0~\\x01~a~\\xc2\\x7f#\\x7f\\x84\\x7f\\xe5\\x80F\\x80\\xa8\\x81\\t\\x81k\\x81\\xcd\\x82/\\x82\\x91\\x82\\xf4\\x83W\\x83\\xb9\\x84\\x1c\\x84\\x80\\x84\\xe3\\x85F\\x85\\xaa\\x86\\x0e\\x86r\\x86\\xd6\\x87:\\x87\\x9f\\x88\\x04\\x88h\\x88\\xcd\\x893\\x89\\x98\\x89\\xfe\\x8ac\\x8a\\xc9\\x8b/\\x8b\\x95\\x8b\\xfc\\x8cb\\x8c\\xc9\\x8d0\\x8d\\x97\\x8d\\xfe\\x8ef\\x8e\\xcd\\x8f5\\x8f\\x9d\\x90\\x05\\x90m\\x90\\xd6\\x91?\\x91\\xa7\\x92\\x10\\x92y\\x92\\xe3\\x93L\\x93\\xb6\\x94 \\x94\\x8a\\x94\\xf4\\x95^\\x95\\xc9\\x963\\x96\\x9e\\x97\\t\\x97u\\x97\\xe0\\x98L\\x98\\xb7\\x99#\\x99\\x8f\\x99\\xfb\\x9ah\\x9a\\xd5\\x9bA\\x9b\\xae\\x9c\\x1b\\x9c\\x89\\x9c\\xf6\\x9dd\\x9d\\xd2\\x9e@\\x9e\\xae\\x9f\\x1c\\x9f\\x8b\\x9f\\xf9\\xa0h\\xa0\\xd7\\xa1F\\xa1\\xb6\\xa2%\\xa2\\x95\\xa3\\x05\\xa3u\\xa3\\xe5\\xa4V\\xa4\\xc6\\xa57\\xa5\\xa8\\xa6\\x19\\xa6\\x8b\\xa6\\xfc\\xa7n\\xa7\\xe0\\xa8R\\xa8\\xc4\\xa96\\xa9\\xa9\\xaa\\x1c\\xaa\\x8e\\xab\\x02\\xabu\\xab\\xe8\\xac\\\\\\xac\\xd0\\xadD\\xad\\xb8\\xae,\\xae\\xa1\\xaf\\x15\\xaf\\x8a\\xaf\\xff\\xb0t\\xb0\\xea\\xb1_\\xb1\\xd5\\xb2K\\xb2\\xc1\\xb37\\xb3\\xae\\xb4$\\xb4\\x9b\\xb5\\x12\\xb5\\x89\\xb6\\x01\\xb6x\\xb6\\xf0\\xb7h\\xb7\\xe0\\xb8X\\xb8\\xd1\\xb9I\\xb9\\xc2\\xba;\\xba\\xb4\\xbb-\\xbb\\xa7\\xbc!\\xbc\\x9a\\xbd\\x14\\xbd\\x8f\\xbe\\t\\xbe\\x84\\xbe\\xfe\\xbfy\\xbf\\xf4\\xc0p\\xc0\\xeb\\xc1g\\xc1\\xe3\\xc2_\\xc2\\xdb\\xc3W\\xc3\\xd4\\xc4Q\\xc4\\xcd\\xc5K\\xc5\\xc8\\xc6E\\xc6\\xc3\\xc7A\\xc7\\xbf\\xc8=\\xc8\\xbb\\xc9:\\xc9\\xb9\\xca8\\xca\\xb7\\xcb6\\xcb\\xb5\\xcc5\\xcc\\xb5\\xcd5\\xcd\\xb5\\xce5\\xce\\xb6\\xcf7\\xcf\\xb8\\xd09\\xd0\\xba\\xd1;\\xd1\\xbd\\xd2?\\xd2\\xc1\\xd3C\\xd3\\xc5\\xd4H\\xd4\\xcb\\xd5N\\xd5\\xd1\\xd6T\\xd6\\xd8\\xd7[\\xd7\\xdf\\xd8c\\xd8\\xe7\\xd9l\\xd9\\xf0\\xdau\\xda\\xfa\\xdb\\x7f\\xdc\\x04\\xdc\\x8a\\xdd\\x10\\xdd\\x96\\xde\\x1c\\xde\\xa2\\xdf(\\xdf\\xaf\\xe06\\xe0\\xbd\\xe1D\\xe1\\xcb\\xe2S\\xe2\\xda\\xe3b\\xe3\\xea\\xe4s\\xe4\\xfb\\xe5\\x84\\xe6\\r\\xe6\\x96\\xe7\\x1f\\xe7\\xa8\\xe82\\xe8\\xbc\\xe9F\\xe9\\xd0\\xeaZ\\xea\\xe5\\xebo\\xeb\\xfa\\xec\\x85\\xed\\x10\\xed\\x9c\\xee\\'\\xee\\xb3\\xef?\\xef\\xcb\\xf0X\\xf0\\xe4\\xf1q\\xf1\\xfe\\xf2\\x8b\\xf3\\x19\\xf3\\xa6\\xf44\\xf4\\xc2\\xf5P\\xf5\\xde\\xf6l\\xf6\\xfb\\xf7\\x8a\\xf8\\x19\\xf8\\xa8\\xf97\\xf9\\xc7\\xfaW\\xfa\\xe7\\xfbw\\xfc\\x07\\xfc\\x98\\xfd(\\xfd\\xb9\\xfeJ\\xfe\\xdb\\xffm\\xff\\xffXYZ \\x00\\x00\\x00\\x00\\x00\\x00o\\xa0\\x00\\x008\\xf2\\x00\\x00\\x03\\x8fXYZ \\x00\\x00\\x00\\x00\\x00\\x00b\\x96\\x00\\x00\\xb7\\x8a\\x00\\x00\\x18\\xdaXYZ \\x00\\x00\\x00\\x00\\x00\\x00$\\xa0\\x00\\x00\\x0f\\x85\\x00\\x00\\xb6\\xc4sf32\\x00\\x00\\x00\\x00\\x00\\x01\\x0c?\\x00\\x00\\x05\\xdc\\xff\\xff\\xf3\\'\\x00\\x00\\x07\\x90\\x00\\x00\\xfd\\x92\\xff\\xff\\xfb\\xa2\\xff\\xff\\xfd\\xa3\\x00\\x00\\x03\\xdc\\x00\\x00\\xc0qtext\\x00\\x00\\x00\\x00Copyright (c) 2003, Canon Inc.  All rights reserved.\\x00\\x00\\x00\\x00desc\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0bCanon Inc.\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x00C\\x00a\\x00n\\x00o\\x00n\\x00 \\x00I\\x00n\\x00c\\x00.\\x00\\x00\\x0bCanon Inc.\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00desc\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x13sRGB v1.31 (Canon)\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x12\\x00s\\x00R\\x00G\\x00B\\x00 \\x00v\\x001\\x00.\\x003\\x001\\x00 \\x00(\\x00C\\x00a\\x00n\\x00o\\x00n\\x00)\\x00\\x00\\x13sRGB v1.31 (Canon)\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00XYZ \\x00\\x00\\x00\\x00\\x00\\x00\\xf6\\xd6\\x00\\x01\\x00\\x00\\x00\\x00\\xd3-sig \\x00\\x00\\x00\\x00CRT ucmICSIG\\x00\\x00\\x01(\\x01\\x08\\x00\\x00\\x01\\x08\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00VIT Laboratory\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00CINC\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xf3T\\x00\\x01\\x00\\x00\\x00\\x01\\x16\\xcf\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x01\\xff\\xdb\\x00C\\x00\\x04\\x03\\x03\\x04\\x03\\x03\\x04\\x04\\x03\\x04\\x05\\x04\\x04\\x05\\x06\\n\\x07\\x06\\x06\\x06\\x06\\r\\t\\n\\x08\\n\\x0f\\r\\x10\\x10\\x0f\\r\\x0f\\x0e\\x11\\x13\\x18\\x14\\x11\\x12\\x17\\x12\\x0e\\x0f\\x15\\x1c\\x15\\x17\\x19\\x19\\x1b\\x1b\\x1b\\x10\\x14\\x1d\\x1f\\x1d\\x1a\\x1f\\x18\\x1a\\x1b\\x1a\\xff\\xdb\\x00C\\x01\\x04\\x05\\x05\\x06\\x05\\x06\\x0c\\x07\\x07\\x0c\\x1a\\x11\\x0f\\x11\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\x1a\\xff\\xc0\\x00\\x11\\x08\\x00\\xc8\\x01,\\x03\\x01\"\\x00\\x02\\x11\\x01\\x03\\x11\\x01\\xff\\xc4\\x00\\x1d\\x00\\x00\\x01\\x04\\x03\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x03\\x04\\x05\\x07\\x00\\x02\\x08\\x01\\t\\xff\\xc4\\x00B\\x10\\x00\\x02\\x01\\x02\\x04\\x04\\x04\\x04\\x03\\x07\\x03\\x04\\x01\\x03\\x05\\x00\\x01\\x02\\x03\\x04\\x11\\x00\\x05\\x12!\\x06\\x131A\"Qaq\\x07\\x142\\x81\\x91\\xa1\\xb1\\x08\\x15#BR\\xc1\\xf03\\xd1\\xf1\\x16$b\\xe1\\x82Cr\\x92\\t\\x184S\\xa2\\xff\\xc4\\x00\\x1a\\x01\\x00\\x03\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x03\\x04\\x01\\x05\\x00\\x06\\xff\\xc4\\x001\\x11\\x00\\x02\\x02\\x02\\x02\\x01\\x03\\x02\\x04\\x05\\x05\\x01\\x01\\x00\\x00\\x00\\x01\\x02\\x00\\x11\\x03!\\x121\\x04\\x13Aa\"Q#q\\xa1\\xf0\\x142\\xb1\\xc1\\xd1B\\x81\\x91\\xe1\\xf13b\\xff\\xda\\x00\\x0c\\x03\\x01\\x00\\x02\\x11\\x03\\x11\\x00?\\x00\\xad\\xb8_\\x89x.\\x92\\x0c\\xdb2\\x836\\xabx\\xa8\\x80\\xbb\\x89\\x19\\x1a;\\x8f\\xa0t\\xbd\\xc8\\xd8\\x9d\\x89\\xda\\xf8\\xa7\\xbe*|Cn.\\x94RQWUU\\xe5\\x94\\xf3\\x12\\xb2J|2\\x82<-\\xa5\\x86\\xb5\"\\xe4\\x10I\\x17\\xdcb\\xbe\\x12:\\x17\\x8a9\\x1fC\\xa1\\x12\\xaa\\x1b\\x06\\xde\\xf6>xR\\x90\\xd3MT\\xb1U\\x06J]`\\xb1Aw\\x0b~\\xdexky?\\x821\"\\x85_\\x81\\x18\\xd9[\\'f=\\xe1l\\x92\\x1c\\xe77\\x8a\\x8ey\\x0cQ\\xbcl\\xfe\\x025\\xb9\\x1f\\xca\\xb7\\xef\\xf8\\xfba^ \\xc9\\x97%\\xaa\"*\\x8ell\\xa0]\\x92\\xc5mm\\x88\\xf7\\xb7\\xe5\\x86\\xd2\\xd3\\xc5\\rT\\x959mC\\x08a\\x90->\\xbd\\x9c\\x8blv\\xef\\xfe\\xf8K1\\xcc\\xab3j\\x96\\x15\\xd2K;$zAe7\\x16\\xee}}\\xf1\\x1f\\xf3Q\\x06\\x08 )\\x04nF\\xb6\\xa1)mkro\\xef\\x85\\xaa\\xea\\x9e\\xa2k\\xd9F\\x91\\xa4[\\xbf\\xae\\x1a\\xc5\\xb3\\\\\\x8d\\x97|)\\xae#o\\x0bj\\xf7\\xc1\\xd0\\xbb\\x81f<\\x99\\xe2h\\xe31&\\x92\\xa3\\xc4\\xc4\\x9b\\x93n\\x96\\xf4\\xc6\\xf4\\xe1\\x9bM\\x96\\xfa\\xfao\\xbd\\xfd\\xb0\\xdcTF\\x91\\xdbB\\xb3\\x91}\\xd7\\xe9\\xfb\\xf7\\xc5\\x83\\xf0\\xe6\\x91$\\xca\\xf3L\\xca\\xb6\\x9e\\x92\\xb2-k\\x1b\\xab\\xc0dtQ\\xe2$\\xf6U;z\\x9b\\x1e\\xc3\\x18\\xa9\\xc8\\x1f\\x80O\\xdc\\xea{\\x1asj\\x90\\xb4|=][\\x92\\xd4f\\xb0\\xd2,\\xd4\\x94\\xee5i\\xd4\\xaf\\xa4\\xec\\\\\\x1e\\x84) 7qpmm\\xf1?\\x9f\\xfc9\\xcd\\xf2)\\xa9\\xd6\\x9f^d\\xf2\\x89\\x98\\xa5<E\\xdb\\x95\\x19\\x00\\xbb\\x0f#q\\xed\\xb7|Z\\xf9]0\\x8b\\x87\\x02\\xd3\\xc5\\xc8At\\x8e\\x99\\x90\\xebpw#M\\xad\\xa4\\xea=lz\\xe0\\x8b#\\xa3\\xcc\\xb3*Z\\xbf\\x94I(*\\x08\\xe4-N\\xc8\\xea\\x01\\xfaT\\xb8 0\\xb8\\xde\\xc7~\\x9ex\\xbf\\x1f\\x8f\\x89\\xb8!V\\xb7\\x17\\xd7U\\xd8?c*\\xfe\\x1c\\x00w9b\\xa3\\xe5\\xff\\x00\\x7fS\\xc9UH\\xd5Q\\x86I*\"\\xd4U\\xd8\\x03b\\xbdv\\xf2\\xf4\\xc5\\x87\\'\\x07e\\xfck\\x99=NA@r:p\\x199Q\\xbf19\\x80t\\xb5\\xc9\\x07u=w\\x01\\xad\\xd3\\x10\\xf5\\x7f\\x0f\\xf3(\\xf8\\x9b2\\xcbg\\x7f\\xdd\\xf2E(\\x02Z\\x93\\xad\\x99Y\\xbe\\xb2Tnw\\x04\\xed\\xf9\\xe1\\xcf\\n\\xe6\\xb5|\\x030\\x8a\\xbe&\\xf9J\\x90\\x0bM\\r\\x8e\\x81sm@\\xad\\xc9\\xda\\xe0\\\\\\x1b\\x1d\\xba\\xe2$\\xc3\\xc1\\x83d\\x06\\x85\\xc5\\x8f\\xb3\\rF<A\\xc0\\xf5\\x99\\x14\\x95\\xd4\\xa6hk\\x17.\\xa5\\x82y\\x9d\\x14\\xae\\x95\\x9b\\xa0\\xb7cr/\\xf9`e X\\x01i\\x94\\x06\\x04i\\xd2\\xdb\\xea8\\xe9\\x9ayr>\"\\xe0\\xfc\\xcc\\x1a\\xbc\\xae\\xb6Z\\xb4j\\xd2%\\x95\\xe1\\x12\\xe9\\x1aC\\xc9\\xd0\\x9d,\\x02\\xee|;\\x0f\"yzX\\x99K\"\\x92P5\\xf5\\x1f?,fl\\\\\\x15Z\\xab\\x96\\xeb\\xba\\xf8\\xb1\\x07*\\x84?N\\xe4\\xf6S\\x9f\\xe6yE,qPVL\\x94\\xab\\xcd\\xfe\\x017S\\xadB\\xb8*n,l6\\xf4\\x07\\xa8\\xbe\\x1e\\xe5\\xd3U\\xe69\\x9aN\\xef4\\xb3\\x04\\xf1J\\xed\\xac\\x92E\\xaeI\\xdc\\x9bXa\\x8b\\xe4\\x95Yf_C]T)g\\x82\\xb1.\\xab\\x1c\\xda\\x99\\t\\xff\\x00\\xfb\\x14n\\xa6\\xc6\\xfe\\xb6\\xc3\\xac\\x96\\x8eh\\xab#xo\\x0c\\xdf\\\\^\\x02\\xbe\\xd7>g}\\x86$\\xe7\\xc8\\x85cc\\xf3\\x84\\x80\\x83F\\x1aP\\xaeE\\x93\\xcb\\xf3\\x19\\xbd3\\xd5\\xa3\\xc4P$\\xa4\\xe9$\\xf57\\xe8\\x18[\\xa7\\xae!\\xab%X\\xe9d\\x925d\\xa42\\x7f\\xdb3\\xaf\\xf2\\xff\\x00I\\xb6\\xd7\\x1d\\xf15B+j\\xa145\\x0f#Q\\xc6\\xa6T\\x880\\x1c\\xb9\\t\\xb07=W\\xfa\\xbb\\xe0o1\\xcc\\xa5\\xaa\\xa8\\x14\\x12\\x18Iy\\xf4\\xb0\\x17\\xe5\\xdfU\\x81\\x17\\xf4=G[c1cev\\xca\\xf7\\xbd|\\x7fj?z\\x96\\x92\\x0e0+\\xfc\\xc7\\xfc1QJ\\x95\\x8fS]S\\xc9T[D\\xd6\\x00\\x16;X\\xdf\\xb7\\xb6\\x13\\xe2j\\x88?{\\xd4\\x18&\\xe7\\x8d\\xae\\xdat\\xefm\\xf0\\xdd`\\xa9\\xc9\\xe9\\x05EV\\\\\\xeb\\x0c\\xdf\\xf6\\xf2kO\\x0e\\xeb\\xaa\\xca\\x7f\\xfbX\\x1b\\xf6\\'\\x11&\\x96R\\x1aQ\\x13\\xa4@\\x9d\\x89\\xbd\\x87`O\\xdco\\x87+\\x10\\x85X\\xfb\\xf5\\xf6\\xff\\x00\\xd84x\\x80$6q(i\\x00\\xbf|G\\x95\\xe6)\\xc6\\xf9\\xb8\\x96\\x1a\\xd2\\x93\\xa9C`\\xc0\\x1f#\\xd3\\x08E&\\x94b\\xd85\\xea/!\\xb6\\x99\\xf2\\xca\\xa03a)\\xb9j,\\xbdq\\xa3\\xd4\\x12v\\xe80\\x8b1`I\\xc3\"b/k\\x9ba\\xd6P\\xb7\\xad_l48\\x7f\\x92\\x8b\\xd5\\x93\\xe4\\xb8\\xf1\\xfeS0\\x7f4\\x97\\x98\\xeeG\\x9e\\xdba\\x0b\\xbe\\xb2\\x17k\\x8c/P;\\xa0\\xd8o\\x84D\\x81\\x1fm\\xf6\\xdc[\\x12\\x19P\\xeeo\\x1cB47f\\xb1\\xb6\\xad\\xef\\x87\\x08\\xa4\\xdfM\\xd5XxN\\xad\\xce\\x1a\\xa4\\xde\\x04\\x0e\\xbb\\x03~\\x98z\\xb3\\xb1\\xd1e\\xb5\\xac\\xd6\\x02\\xc3\\tk\\x8eJ\\x9b\\x18\\x18\\xe9fr\\x80\\xdfbw#\\x0b\\x1adX\\x91\\xf9\\xc1IbZ\\xc4\\xf4\\xb6\\x12\\x8eY\\x1c\\xbb5\\xb7\\xfeP-q\\x8d\\xf4s\\xa4V \\xe8=\\xad\\xdf\\n\\xdcp\\xa8\\xf2\\x18a\\xb0w\\x94\\xc9k\\x15\\x05l\\xbfs|I\\xd3P\\xd3\\xcf\\xa28\\x9e1!`]\\xb50\\t~\\xde\\xbe\\xf8\\x89\\xa7\\xa91#\\x82S\\x96\\xc2\\xedpI\\xeb\\xdb\\xd7\\x0f2\\xfa\\xd4\\xe6j\\xabW\\x90_T\\x86\\xf6\\xdf\\xb0\\x1f\\x96\\xd8K]G%^\\xe1(\\x8ejX\\xa6\\xa5\\xccUD\\xaaB\\xc7+Fn\\x80w\\x04\\xeeoq\\x88\\xaa\\x8a)\\x01U\\xd4\\x95R6\\xda\\xc0`W\\x7f/<H\\xd3\\xd6U\\xd7#\\xad,\\x8b,\\x91\\xc6#\\xb0\\xd9\\x9c_\\xbd\\xcfl!\\x981\\xa7\\x9eH\\x1d\\x93\\x98\\x8d\\xe2u@7\\x1dl|\\xc6&M\\x1d\\xf7(m\\x8b\\x1dH\\xf7\\x8fM\\x83O\\x03\\xc9!$\\x13\\x131\\x04v\\xdf\\xdb\\r\\x1aW\\x95\\xdd\\xbf\\xed\\x8bj!\\x8f \\xeeA\\xc3\\xe4\\xae\\x98#F\\x92\\x05\\xfa\\xb4\\xb3\\r\\xbc\\xce4\\x8eX\"E\\x04\\x00\\xe4]\\xac\\xddO\\x9f\\xa6\\x1a\\rD\\xd5\\xc0\\xd6\\xa3\\xa4\\x8e\\x8e3\\x1aI\\xf3GvmvS\\xf8\\xe3j|\\xad\\xaa\\x16:X)\\xa4j\\xe3\\xb8&P\\xba\\x85\\xfa\\xd9\\xadky\\xe1ZW\\xa4\\x92\\x9f\\x9d,\\x93E(K\\xc3\\xcbP\\xdaX\\x1e\\xf7\\xed\\xb6$\\xab8\\xae\\xa3\\x89\\x0cRgej\\x0c\\x0e\\x166\\xbe\\x926\\xf4\\xd8\\xde\\xdd1\\xd4\\xb6\\x17S\\xe7\\xd5T\\x8d\\x99\\x15O\\x96\\xd7RT\\x034QD!c\\xfe\\xa9\\x0c\\xb7\\x1d\\xfb\\xfd\\x88\\xc3H*\\rET\\xad[R\\xf4\\xebk4\\xc8\\x0b\\x16\\xedc\\xdf|&\\x93\\xc8#\\xb0\\x91\\xc8-`\\x0fa\\xbe<]V\\xf1n\\xa0\\xd8\\xf6\\xb8\\xc3\\x00;\\xb8,\\xc0\\nX\\x88\\x80TH\\xcb\\n\\x08\\xc3\\xb2\\xaa\\xef\\xebn\\xfd\\xce$s^\\x1c\\x193S\\x8a\\xa9P\\xb4\\x97\\xd7\\x1a\\x9b\\x94\\x02\\xd77\\xe8{\\xfe\\x18BY\\xa0t}\\x1a\\x82\\xf5kxH\\x1e\\x9exh\\xf5S\\xd5\\xca\\x11L\\x92J\\xce\\x02\\xebk\\x91\\xbd\\x80\\xc1\\x8eD\\xeb\\xa8+\\\\M\\xf7&2\\xae\\r\\xcd\\xf3/\\x98\\xa8\\xa5\\xcbjj\\xa9)\\x8d\\xa4\\x95\\x17a\\xfe\\xe2\\xdb\\xed\\x84\\xf2|\\xea\\xb7!\\xd5\\xf2S7\\xcb4\\x81\\xda2.\\xaeA\\xeaG\\x9e\\t?\\xea\\xba\\xee\\x1c\\x8e\\xa6,\\xa2rCH\\xf6G\\x00\\x08\\xed\\xb0a\\x7fa\\xfe\\x0c\\x02K\\xa8\\xa8\\x92V%\\xd8\\x92E\\xbb\\xdf|+\\x03\\xe7.\\xc5\\xaa\\xb5Uw\\xf3q\\x8c\\x11T\\x14&\\xfd\\xe1\\xc7\\x0f|J\\xcc\\xb2Z\\xca\\xea\\xa1\\x0cU\\x12\\xd5J%\\x05\\xf7d\\xf1\\x86(\\xa7\\xa8F\\xb5\\x8d\\xb7\\xb7\\x96\\x0e\\xeb>1\\xf1\\x0c\\xf3=\\x05\\x152S\\xcbY\\x0csU,\\xb1\\xd9 \\x97Y$\\xad\\xee\\x19\\x1a2\\x14\\x83\\xd7kn0\\x0b\\xf0\\xf2\\x92\\x8a\\xbaI\\x927\\x9eI\\xd9A\\xa8\\xa7j=q\\xd8\\x1f\\x0b+\\x83t`z\\x13m\\xcd\\xacA\\xc5\\x85\\x9a\\xf0\\xf8\\xce\\x9enL\\x89I\\x99\\xbe\\x90\\xcf\\xb2\\x9b(#\\x96V\\xe3\\xf1=;m\\x8e\\x93y\\x0f\\x85\\x15=J.h~q\\xd8\\x95\\xf2\\x02n<\\xa0\\xa7\\xfd\\xe8(\\xebYh\\xa2\\x9d\\xd1\\xda\\ru\\x0b\\x1c\\xd51\\xaa\\xf8\\xb5)\\'\\xb2\\xdc\\x12G@0\\xc7\\x88\\xa8\\xb2\\x99\\xe8\\x1dsy\\'\\xa4\\x89^\\xf6\\x904h$\\xb6\\xda\\xdc+X\\xd8\\x8d\\x8d\\xb1]\\xe7\\x94\\xbcA\\xc0\\xd5\\xf3\\xfc\\xdciO.a\\x03\\xc3\\x13\\x15\\x0c\\xe1\\r\\xaeW\\xc8\\x9e\\x97\\xc1\\x86u\\x9f\\xe7U\\xb4\\x0f\\x9eS\\xd2\\xc3OP\\xb4\\x8bC\\x98R:6\\x8a\\x98\\x88\\n\\x81\\xa2`\\t\\x95\\x1a\\xe6\\xff\\x00\\xf9.\\x9b\\x8c\\x16\\x0cK\\x8cQ\\xe5j\\x08\"\\xec\\x1b\\xdd\\xfe\\x7f\\xdbQ\\x8f\\x9f\\x90+_\\xa4\\xaa\"\\x9dRX\\xf5H\\xee\\xa1\\xb6PlH\\xef\\xed\\x7f\\xf2\\xf8}Q\\x04o\\x1c3G6\\xa0\\xf7\\r\\x10\\xfa\\x92\\xdf\\xad\\xfc\\xf6\\xc7\\x94\\x99;4\\xcdOP\\xd2SV\\xc7/!\\xa0\\xe5\\x1da\\xbc\\x8d\\xed`\\r\\xaf\\xdf\\x1af9mfT\\xd0\\xc7[\\x1c\\x90\\xb4\\xa8[\\xc4\\x9av\\x04\\x8d\\x8fqq\\xd4c\\x9c\\xc8\\xd7r\\x00\\xa4-\\xd6\\xa1W\\x0e\\xd3&iC%\\x15?\\xca\\xc30eq;\\x13\\xac\\x11\\xd6\\xc4v\\x00\\xdfO{a\\xf1\\xca\\xebrH\\xbez\\x1a\\xe4\\x9a\\xa9cS v\\xbb\\xe9u\\x1e\\x12A\\xf0\\xb5\\x8fO\\xf8\\x01\\x94Y\\x8c\\xd9q/G#\\'\\x87C\\x8dDk\\x07\\xb1\\xb6\\t\\xab\\xe7\\xa3\\xcd2\\xe93<\\xb2X2\\xea\\xaeZ\\xa5U)\\xdb\\x9c\\xa3o\\x0e\\xf666\\xd8\\x81\\xb1\\x1b\\xe01\\xe2\\x04\\x9a\\xd1\\x1b\\xbb\\xfb{\\x7f\\xc7\\xdaT\\x8e\\x08\\xdf\\xb4\"\\xc8sjL\\xa5%\\x14\\xd2\\xcb1\\x95\\xbf\\x81#\\r%\\x0b\\x0b\\xb1=o\\xe2\\xda\\xde\\x98\\xd0R\\xd3\\xd5\\xe6\\xcf\\x98\\xe6S\\xbc\\xf2\\xc8AT!A\\x03\\xed\\xb0?\\xa6\\x07\\n\\x1a\\xda\\x1a\\x14\\xa1\\x92^a\\'^\\xc1B\\x8d\\xefa\\xe7\\xd3|\\x15e\\x99:@\\x11\\xaa-\\x18Qa\\xac\\x9d\\xbd\\x94n}\\xc9\\xc4\\xfeG\\x94[\\x18\\xc6\\xba\\x1f\\x94\\xe8\\xf8\\xd8\\xf9\\x9bap\\xfb*\\xaf\\xa6\\xa9\\x88E,\\x16Qk\\x07e!\\xbf\\xf7a\\x89W\\xcb2\\xfa\\x88^9)P+\\x0bi\\xd27\\x1e\\x84{`:\\x9a\\x1c\\xb9\\xc0\\xb3\\xb37c\\xcb#\\xfb\\x9cIs\\x92\\x85<\\x15\\x0e\\x10t\\x0c\\x7f\\xb68Y\\t\\x06\\xeew\\xb1\\x80uR3\\x8a\\xfe\\x19\\xd2\\xf1\\x13\\xb3\\xd3\\xb8\\xa3\\xa9g\\x0cdT\\xd5\\xae\\xc2\\xc0\\x1fOl\\n\\xff\\x00\\xfb\\x7f\\xcej#\\x91\\xa1\\xcd2\\xd8\\xd1mnl\\x8c\\xb7\\x1f\\x87\\\\\\x1c\\xc7\\xc4\\x9c\\x97\\xb3I\\xe1=\\xef\\x89Z~%\\x8c\\x8bs\\x80\\xf4\\xb5\\xb0\\xdc>n|B\\x86\\xc4Vo\\x07\\x0eSgF\\x04d\\x7f\\xb3dY\\x8a\\x85\\xccx\\xbe\\x96\\x92c\\xb6\\x98\\xa9\\x1eP>\\xe4\\x81\\x8b_\\x86\\xff\\x00a\\xac\\x8f41\\x9a\\xce7\\xae\\x91\\x08\\xbb\\x082\\xf8\\xd6\\xfe\\xc4\\xb1\\xfd\\x0e\\x1ep\\xdc\\x13g\\xb3\\xa2\\xc4\\x82\\xec\\xcaU\\xc0\\xb1\\x06\\xe4\\x13\\xf6\\xfe\\xe3\\x1dC\\xc0\\\\!6_\\x14\\x12\\xbc\\x84\\r\\x8e\\x91\\xdb\\xccc\\xb3\\xe2\\xe7\\xcd\\x94\\xfdBr|\\x9f\\x1f\\x0e!\\xf4\\x99F\\x8f\\xff\\x00O\\xee\\x034\\xe0\\x7f\\xd4\\x1cG\\xcd\\xd3\\xfe\\xa72\\x02\\t\\xf3\\xd3\\xcb\\xfc\\xaf\\x80L\\xc3\\xf6\\x03\\xcd\\xb2\\xb34\\xdc;\\xc6T5\\xa6\\xde\\x08\\xab(^\\x12\\x7f\\xf9\\xab0\\x1f\\x86;\\xf5 \\x01\\x00#ka\\xa4\\xb0\\xe9$Z\\xe3\\xa6:gb\\xa70\\x01s\\xe5w\\x14~\\xce?\\x12\\xf8X;\\xd6p\\xbdMu:\\xb5\\x8c\\xd9s\\xadZ\\xfe\\x08u\\x0f\\xb8\\xc5__\\x96\\xd6e\\x15r\\xd2\\xe6\\x94\\xb3\\xd0\\xd4\\xc7\\xf5\\xc1<M\\x1b\\xaf\\xff\\x00\\x16\\x00\\xe3\\xec}U\\x13\\x14q\\x1d\\xc6\\xf7\\x04v\\xc73\\xfcf\\xe1)s\\xb4zN(\\xca\"\\xcf,\\x0bS\\x9eI\\x12\\xa8\\xbe\\xdc\\xb7[2w\\xef\\xdb|I\\x92\\x90\\\\\\xa3\\x1a\\xfa\\x86\\x81\\x9c\\x01\\x01PJ\\xdc\\xb7}\\xfba\\xcf/Q\\xd4\\x18t\\xb0\\'\\xcb\\x07Y\\xd7\\xc3\\xe8)3N^UPH7\\x1f-<\\xa3Z\\x1e\\xe3P\\xfa\\xc7\\xa8\\xb1\\x1d\\xfc\\xf0GG\\xf0\\xf2\\x96\\xa3*h\\xbc)9]\\xaf\\xd8\\xf6\\xbf\\xafPm\\xd7\\x10>t]\\xdc\\xb7\\x1f\\x8d\\x90\\xd8\\xa9XEL\\xf1\\x0ej\\xdd\\xd1wqn\\x83\\x1es\\x81\\x05\\xb4\\x02E\\x82\\x9b\\xe2\\xf4\\xce8\\x7f&\\xa1\\xe1\\xc6\\xa2\\xe5\\xe9\\x84-\\xdeE\\xd9\\xb6\\xeao\\xe6zb\\x9c\\xcc2\\xe6\\xa7\\xa9n\\\\|\\x88\\xbb! \\x9b\\x1e\\x9f{a)\\x94d\\xb2#_\\t\\xc7\\xdck$\\x91x\\x84hJ\\xda\\xe2\\xdd\\x89\\xf5\\xc3\\xeaJ\\x84H\\xd1\\xa6\\xb6\\x9b\\x91\\xa4!&\\xe3\\xdb\\xed\\x86\\x91\\xd0\\xaa\\xc6\\x8e\\xd28RHd\\xb0;_\\xaf\\\\HR\\xc0\\xb3\\xff\\x00\\x06\\xfc\\xbe\\xae\\xacS\\xb7N\\xb8#U\\x05c\\xea:\\x88d\\x0f\\xae\\xd1[Ia\\xe2;\\x9e\\xdb\\x1b\\xdb\\x0e\\xeb\\xa0\\xa8\\xa3`\\xb5\\x0c\\xaa\\x855\\xea;\\x90\\xbf\\x8d\\xff\\x00\\x1cGK\\x93\"\\x80\\xfc\\xcbE\\xb5\\xddc\\xd8\\x81\\xf7\\xc3\\xf4\\xa6\\x9a\\xb2\\x9di\\x06\\x87;\\xdaC\\t\\x05E\\xfaaD{\\x88\\xc0}\\xa3GXd\\x8f\\x98\\x14\\xddA\\x1a\\x96\\xc0\\x92{\\x03\\xdf\\x0c\\x85D\\x14%\\xa2\\xa8a#\\xea$\\x90\\x81\\xed~\\xd7\\xc3\\x93\\x94\\xc9\\x1f\\x88F^%m,T6\\x90:~\\xbeXR\\x9f.\\xcb\\xccw\\xa8d\\x0cO\\xf3\\xc9cl\\x0f ;\\x9a\\x14\\x99[]\\xa3\\x86\\xe8A;\\xf9\\x00\\x05\\xf1\\xe5\\xac\\xca\\xb2H\\x89\\xcb\\x1c\\xc1qq\\xab\\xb0\\xdb\\xd2\\xd8\\xdah\\x9aVH\\xa4*\\x841\\r\\xd3s|3\\x9ePd{(\\x00zu\\xc7x\\x0b\\x9f/QY\\xa6\\x11\\xbb\\xe8\\x17\\xdc\\xd8c\\xd8`\\x9a\\xb4\\xc9\\xc9FnZ\\xdd\\x8e\\xae\\xd8\\xde:3Q1MJ\\xad\\xa6\\xfdm\\xf6>\\xb8\\x95\\xc8hh\\xa1\\xcc\\xd1s\\xf7\\xa9\\x86\\x86Eu-Kb\\xcc\\xdd\\x81\\x1e[\\x1b\\xe0\\x19\\x82)#\\xb8K\\x8c\\x9d\\xc80\\xe1\\x06\\x8b\\xf5\\xfc@\\xc2\\x94\\xb2\\x98\\xab\\x10\\xa9\\x08R\\xe5Kv6\\xeb\\xf6\\xeb\\xef\\x82\\x9an\\x00\\xcc3\\n\\xda\\x01E\\xcb\\x14y\\x9cr\\xcbMS(\\xb9\\x08\\x8cAV\\x03\\xa3\\xda\\xdbz\\xe1\\xe3\\xfc0\\xcdi\\xfery\\x1e\\x18\\xe9c\\x9aX)\\xa6\\x94\\x1b\\xd4\\xb2u\\xb2\\x0b\\x90\\xa0^\\xecv\\x16\\xc5\\x0c\\x8c\\xb8\\xcb\\x91\\xa9\\xab\\x8d\\xc9\\xd0\\x83\\x11E\\rP\\x97\\xe7\\xdeU\\x84\\xf8\\x90\\xc4\\xa0\\xb5\\xfa\\x0b\\xdf\\xb6\\x12y\\x15i#Q\\xc9\\x90%\\xc2\\xa8Cp=o\\x84\\xe1GY\\x18\\xcc\\xc5J\\xf5\\x03\\xb5\\xbb\\xfeX\\xda\\x9a\\xbcD\\xb3kA#0*\\x05\\xad\\x7f\\xef\\x84\\xf5\\xd4\\xc0oFNp\\xc7\\x1a\\xe6\\x9c1\\xa6*YY(^^t\\x90\\xa0\\x0b\\xb9\\xb0,\\x08\\xea\\xf6\\x06\\xc4\\xec\\xb7\\xb8\\x17\\xc5\\xa5O\\xf1\\x93 \\xab\\x8e\\xa1j\\xe1\\x96\\x92\\x03\\x04+\\x18\\x10\\xdeA1\\xd5\\xccea\\xfd\\'G^\\xa3\\xf0\\xc5\"\\xd2D\\x9c\\xb1J\\xda%\\xb7\\x8c\\xa9?{\\xe1\\n\\x84\\x85\\x1d\\x18\\xb9 \\xa0 \\x01\\xe7\\x8a\\xf0yY1\\nY\\xa1\\x8aI\\xbc\\xfb\\x88\\rnx\\x93\\xe5RI\\x1c4\\xf2\\x89bd\\x060\\x8dpu\\x04\\'J5\\xc6\\xfal\\xa4\\x8b\\x80/l_!\\xa4\\xa7\\x92\\x9e\\xb2\\xb6\\x9e\\xa6)*\\x95\\x1e)*\\xe3@\\xe1\\xc5\\xfcEV\\xea\\x1b{\\x8e\\xd7\\xc74\\xd3A.gR\\x90S\\xaa\\xac\\x8e\\xd6\\n\\xec\\x15}\\xc9=1jp\\xc7\\x18Wd59t9\\xbc\\xd5eiU\\x96WJ\\xa5\\xe6L\\x1d\\x80R\\x8f *\\xa8\\xa1\\x00\\xdcw\\'\\x04\\x8e\\x08!\\xdc\\xad\\x90l|\\x1f\\xe9\\x1d\\x85\\x8a\\x92j[\\xb9\\x17\\xc3\\xec\\xb2\\xaaZ8\\xc3M\\xfcZ\\xa6\\xa8\\xcc\\xe1\\xa9\\x89Zmd\\x13\\xad\\\\\\xef\\xa3\\xdb}\\xed\\xe9\\x81\\x0f\\x8c_\\x0e\\x12\\x83(\\x82\\xbb(\\x92\\xaa\\xb5\\xa8N\\x99\\x18\\xc4\\niv\\xdf\\xa6\\xe4\\xae\\xc4\\xb0\\x16\\x00\\x80w\\xc5\\x9d\\x91\\xf1\\x1af\\xc31\\x83!\\xcc2\\xf9\\xe5\\xa2d\\x15\\xc1Y\\xa5\\xa6,A:EF\\x95R\\xc2\\xddTw\\xef\\x89\\n<\\xfe\\\\\\xb6\\xa5\\xa9\\x84\\xafO<\\xc1\\x86\\xb4\\x94]u\\x0bj]\\xac\\xc4{l{c\\xa9\\xe6\\xbf\\x89\\x8b\\x1f<\\xab\\xa3J\\x18\\x0b\\xec\\xfc{X\\xdf\\xcc\\xadqz\\xaaUL\\xe2\\xaa\\x98\\xea\\xc9\\x05\\xa2f\\x8e\\xc0#\\x05\\xb8\\xb7\\xdb\\x12\\x94\\x19mECjtk\\xfdF\\xf6\\x00\\x9f\\xec0y\\xc6\\xf9v[\\xc3|I$9|+KL\\xd1)\\x08\\x93\\xc9/\\x8c\\x12\\x1bQm\\xf5\\x13\\xb9\\xf7\\xe9\\x81\\xc3V\\xd2\\x02\\x03r\\x97\\xcc\\x93\\xfac\\xe6<\\x8exX\\xe3#\\xa8X\\xbcTm\\x93\\xfe\\xd1\\xee_4y^\\x91\\x10\\xe7N\\xc6\\xd6O\\xd0bv\\ng\\xaaa%UF\\x85=u6\\xd7\\xf2\\x00u\\xc0\\xde^\\xfc\\xc9\\xb9t\\xcd\\xcd\\x94\\x83\\xa9\\xc8\\xb0Q\\x89\\x9a\\x08\\xa2y\\xcf2A3\\xa9\\x01\\x8bt\\x1e\\x9f\\xfa\\x1dq\\xcbq\\xef:\\xd8\\x85\\n\\x10\\xdb.Zl\\xbe!\\xc8C$\\x84ue\\xb7\\xe5\\x88\\x9c\\xf2aU6\\xb2\\xc1[\\xfa\\xb5l?\\x1c-Y!\\x8a\\x02\\x90*\\xe8Agbt\\xea>\\xb6\\xed\\xe9\\x80,\\xd33\\x08\\xccR*u\\xb1\\xb0bKo\\xe9\\xeb\\x88\\xd1\\x1b#j\\\\Yq\\xae\\xe4\\xadEcA\\xb1\\xae\\x8eV\\xbd\\xac#\\xdb\\xf1\\x18\\xb4~\\x1a\\xf0\\xd3\\xe7H\\x92\\xe6Ui\\x05;5\\x95\\x96\\x1dV>\\xba\\xba\\x03\\xfd\\xb1D\\xe5\\xd1\\xd5\\xe6Y\\xd55+6\\xb95\\x07p6\\x11\\x8fo?Lvo\\xc3\\x992\\x8aj\\x08\\xa3zH\\xd6\\xa4\\xc7gG[\\x89\\x17\\xd3\\xfc\\xdb\\x17zJ\\xb4\\x0fr\\x1fY\\x9a\\xc8\\xe8K\\x13\\x80\\xb8er\\xba\\xf8\\xa1\\xafDb\\xad\\xa4:\\xa0\\x00\\x86\\x16\\xbe\\xc0w\\x02\\xfeX\\xbf2\\xf8V(\\xd4\\xa0\\xd2\\r\\xb5\\x0f\\xfc\\xbc\\xf1[\\xf0\\xcc\\xd4\\xcf\\x0ck\\xfc\\x81B\\xa5\\xf7*;o\\xe9\\x8b\\x16\\x86pT\\x07;\\xda\\xd8\\xeb\\xf8\\xe0\"\\xeaq\\xf3\\xb1v\\xb3&,\\x08\\xdf\\xae\\x1b\\x85\\xf1\\x10l\\x0e\\xf8\\xc10b/\\xdcc\\xd5}Z\\x9b\\xb9\\xc5\\x17\\'\\x13\\xc9cUN\\x9d\\xaf\\x80n3F\\x9a\\x86xic\\x12L\\xcb\\xb5\\xfbo\\xe7\\x83J\\xc9\\x00\\x8bN\\xab1\\x1dp5\\x9bH\\xb1\\xc4c\\x8e\\xdd<M\\xdf\\xf1\\xc0\\x9d\\x835tg\\x15q\\xc6KG\\x94f2\\xc5 G\\x9c9\\xd44\\r\\x08|\\x81\\xee\\x7fO|\\n\\xaeiN\\x8d\\xa4*\\x86\\x1d,no\\xef\\x8b\\xc3\\xe2\\xc49k\\xadH31\\xa9\\x16\\x0eb:V+\\xf4P{\\xb1\\xf2\\xde\\xf8\\xe5\\x9c\\xc2\\xb1\\xa9\\xb3G\\x8a6\"\\xcd\\xd1\\xf76\\xf4=\\xff\\x00\\x0c|\\xd7\\x91\\x82\\xd8\\xd1\\x9fK\\xe3g\\xfaw\\x0e\\xa5\\x92)\\x944\\xff\\x00\\xc4\\x0b\\xba\\xa7k\\xfa\\xe0\\x0f\\x89(\\x16Y\\xdesI1\\x92\\xc6\\xcc\\x82\\xe3\\xf0\\xc4\\xc3gDD\\xa0\"\\x02\\x05\\xaed \\xe1\\xb1\\xaa\\xa8\\xfa\\xd6B\\x13\\xfa\\x88\\xba\\xfe\\xb8F.X\\xccvP\\x1eU\\xb5\\x11UB\\xce\\xb1\\xc3 \\x1a\\xadv\\x1b_\\xdb\\x1b|\\xc4\\x84\\xa4R\\xc1#0\\xe8c\\x16\\x1dqdU\\xaf\\xcd\\xc4\\xf6h\\xd6b<\\x12\\x81q\\x7f_<C\\x08\\xeb\\xe9\\x81&\\xaa!\\xa1B\\x82\\xe3E\\xfe\\xe7\\xf4\\xef\\x8e\\xa67\\\\\\x83\\xad\\xceNLo\\x8c\\xf7\\xa8/\\x16i\\x15<\\x8a!\\xa3\\x92\\xa65:\\x9bX\\xb1\\xb9\\xda\\xc2\\xd8q&|ex\\xc2\\xd1\\xe8\\x84mb\\xb6\\'\\xef\\xed\\x82D\\xf9\\xd9D\"\\'\\x81\\x9d\\x0e\\xa9#\\xd0\\x1do~\\xe7\\xb1\\xc2\\xe1\\xb3=n\\xcf\\x12\\xbc\\x10:\\x94\\x8e8E\\xc0\\x1dlp\\xc2\\x80\\xfbD\\x86#\\xde\\n\\x0c\\xe3\\x99\\xa7\\x9d\\x00\\x88\\xefm\\xb4\\xee<\\xcf\\x96\\x1cSf\\xc9,d\\xca\\xf0\\xc6A\\xb0T\\xa6,\\x00\\xf7\\xbe\\tf\\xa5\\xac4\\xba\\xa2x\\xe7*IK\\xc0\\r\\xd4\\xf5\\xea/pz\\xfaaJi\\xea\\xa6B\\xd4\\xe0i\\x06\\xd7\\x98\\x00\\xc4\\xf9\\xdbN\\xc3\\xcb\\x0b*+Q\\xa1\\x8d\\xd1\\x95\\x05[\\'>I)\\xfcW\\x06\\xc2\\xd6\\xb1\\xe9\\x86\\xf18\\x8eF\\x95\\x88,\\x1b\\xf8{_{\\xf5>\\x83\\x1b\\xd10.\\x12\\xda\\xb5m\\xa7\\xdf\\tM\\x1d\\xa5u[\\x04\\x06\\xc2\\xc7\\xcb\\x1dU\\x15\\xa9\\xf3\\xd7d\\x99\\xb5.\\xa6\\xa8\\x9d\\xcb\\xb1`\\xbd{\\x92v\\xfdp\\xb5;\\x13_\\x1f)\\x19\\xc8\\x91T\"\\xdc\\xb3\\x1f.\\xfb\\x93\\x8f`\\xa6\\x9d)\\xa5\\xa9\\x8e7\\xd2\\xec\\x16;\\x91~\\xbd\\x7f\\x1d\\xbd\\xf0\\xd9)Z:\\x83\\n\\xc8\\xd1\\xcc\\x1c\\x0b\\x15*\\xc1\\xaf\\xe5\\xd4\\x1b\\xe3\\xcbD\\x93=\\xb1:\\xae\\x96\\x98\\xd1\\xd0\\xa5k\\xe4\\xf59J\\xca\\xfc\\xc9)j\\xa3\\x11\\x14\\x97M\\x8b\\x0b\\x1f\\xe6\\xeev\\xbe\\xc6\\xd8}\\x06E\\x17\\x19\\xe5f\\x9ej\\x89h`\\x922\\x92\\xfc\\xbb\\x7f\\x13I7dS\\xa4\\xd81\\xb5\\xc8\\xdc\\x81o<Q\\xfc\\x19\\xf172\\xc93<\\x96\\x96y\\x9al\\xb2:\\xa0\\xb5p\\xb3\\x82gMGwr/\\xb17\\xfbb\\xc6\\xe2o\\x8eT\\xfc3V\\xd4<#\\r\\xabb\\x9d\\xe9\\xea\\x96-\\x06\\x19\\x94}\\x13F\\xc0\\x11\\xab\\xb1\\x16#\\xbe;8\\xf2\\xab\\xe5\\xf5\\x9b!\\tTP\\x81\\xdf\\xde\\xe5\\xe3*p\\xa9Gq\\x8f\\x0f\\xc3\\xc3<QS\\x97CYQY\\x10o\\xf5%\\xa6xI\\x04\\x9d\\xac\\xe0\\x13o\\xea\\xb5\\x8flA\\xf2\\x84l\\xd6\"\\xf1\\xae\\xe6\\xfd\\xcf\\xf8p\\xef1\\xcd\\xeb\\xb8\\x83159\\xbc\\xf3\\xd6\\xd6\\x99Iy\\xa5\\x95\\xa4v\\x04\\x92\\x06\\xfd\\x85\\xf6\\x02\\xc3\\x0b6A\\x9cOJ\\xf5\\xf1e\\xb5F\\x81u\\x1eh\\x88\\xe9\\xf0\\xfdG\\xfc\\xed\\x7f#\\x8e[\\x0enx\\rH\\x08\\xb3\\xa9\\x0f#\\xf2\\xf6\\xfe\\xae\\xa4\\x1c<t\\xa4l\\xa9Y\\x04\\xa6\\xb85\\x94\\xdf\\xc1\\xcb\\x04\\xfe{\\xe1\\xad}%E\\x1dC\\xc5S\\x1bG*\\xb6\\xea\\xc3q\\xdf\\xef\\xb1\\x07\\xef\\x87\\x01\\xa4\\x10@\\xa1\\xad!\\x1f\\x80\\xf3\\xf4\\x03\\x00\\xc2\\xa7\\x86\\x84\\xd2\\x85\\x1a\\x12j$\\xd4\\xba\\x0f\\x87n\\xad\\x87SMOS\\x13\\xb4\\xcd,\\xb5$\\x8bkc\\xd3\\xfd\\xfaa\\xc6cG\\x1c4p\\xc9\\x15[Nd\\xfe\\xb3ea\\xdc\\x83~\\xb7\\xeb\\x7f<{\\x92\\xaeW\\rj\\x8e\\'5\\rJQ\\xbc4\\xf2\\x00\\xda\\xad\\xb7\\x9e\\xd8Xk\\x17\\x19\\xc5\\x95\\xa8\\xfb\\xc7\\xdc3\\xc5\\xf9\\xc7\\r@\\xf4\\xd4uZr\\xe6\\xa8Y\\xe4\\xa7\\x96 \\xf1K\"\\xd8\\x8b\\xa7R<+\\xb5\\xecm\\xbe-\\xee\\x16\\xf8\\xec\\xb5Y\\xc6wY\\xc4\\xd1\\xd3\\xc0\\x82\\x86#AJ\\x15\\xac\\xd3\\xc6Ie\\xbd\\x89\\x05\\xc1a\\xab\\xf9N\\x93\\xd0b\\x85\\xa5\\x91c\\xa9U\\x12\\xb0\\xa6\\x12\\xa9.\\xebq\\xa6\\xf6\\xb9[\\xeem\\xdb\\x16>m\\x97\\xd2f\\x19D\\xe7.\\x8e\\x9c\\x88]\\xdbZ!\\x0c\\x14os\\xee\\x0f\\x99\\xc5x\\xfc\\x8f#\\x16\\xf1\\xec\\x7fN\\xf7_\\x11\\xd8A`w\\xd4\\x7f\\xf1\\'\\x89\\xf2\\x0e/\\xe2\\x86\\xccxZ*\\x85\\x8d\\xa0\\x8cJf\\xb0\\xbb[\\xb0\\xfeR.U\\xbb]n66\\xc0<\\xba\\xa7\\x94D\\xafe\\xbf\\x88\\xafa\\x8d)O\"\\x94.\\xa0X\\x9f\\x11\\xbf\\\\$*\\x92\\'$\\x9ef\\xfd\\x14\\x0f\\xd7\\x1c\\xdc\\xce\\xd9\\xb2\\xb6C\\xef:\\xb8\\xcf\\x14\\x00\\xc9Yk\\x97-\\xa2d\\x80i\\x96R\\x15H\\xea=p\\xfb\\x87\\x1d\\xa7\\x9e(\\xa3]~+\"\\x0f\\xe6c\\xdc\\xe0j^e[\\xf3e\\x1aW\\xa2(\\xc1w\\tS4\\x0cLW\\xe62\\x90\\xb6\\xec\\x0fS\\xef\\x89r\\x80\\xa9\\xf3\\x1d\\x88\\x97\\x7f\\x88Q\\x9cZH^0\\xe0C\\x10\\xb3\\x1dC\\xc6\\xdd\\xed\\xe9\\xfa\\xe0\\x12X\"\\xa1\\x86\\xa31\\xac \\xcc\\x80\\x8at&\\xfa?\\xf2\\xb0\\xe8|\\xb0Y\\xc5\\x12\\nUh\\xe31\\xe9\\x8a\\xc8\\xec\\xc6\\xe05\\xb7\\x00w8\\xaekj\\xd6S\\xc8`Y\\x1d\\xd7J\\x8b\\x8b\\x80w>\\xd7\\xc4\\xfe*\\x16\\x1f\\x12\\x9f)\\xc2C\\x1f\\x86\\xd9\\x0cUUf\\xb6\\xaeV\\x12\\x96\\xd4\\t\\x16\\xdf\\xcc\\x1ctFW\\x9eSRS\\x18\\xa4uF\\xea\\xba\\x86\\xc1\\xbf\\xaa\\xe3\\xa7\\xb8\\xfb\\xe2\\xa1\\xe0\\xe9 \\xa7\\xcbU#\\x89D\\x96\\xb9=\\x87\\xdb\\xfeq\\xaeeYUN\\xfc\\xfaj\\x95:O\\xd0\\xc7\\xaf\\xe1\\x85d\\xc8[)\\x87\\x8f\\x17\\x1cBt\\xe7\\x03|OZ|\\xce\\x1a,\\xc3O*G\\xb0\\x900:O\\xfb\\x7f\\x9e\\xfd#AV\\xb2D\\x8f\\x1b\\x06\\x04lGq\\x8f\\x9by\\x1ek6c*<\\x12\\x94\\x01\\xac\\xe2\\xf7*\\xc0\\xed\\x8e\\xd1\\xf8Y\\xc4R\\xbeO\\x1c\\x15R\\x19\\x19\\x11t\\x93\\xeb\\x8a\\xfcl\\xc47\\x06\\x90\\xf9X\\x01^k.d\\xa9=\\x8e=\\x15\\xbc\\xben\\xa3\\xd0\\x0bb\\x15k\\x05\\x85\\x8d\\xce#\\xab\\xf3#\\x13\\xba\\x06\\xdc\\x9ct\\x0b\\xf1\\x9c\\xc0\\xb7%\\xeas2\\xeeIca\\x80\\xfe0\\xce\\x9a\\x9e\\x82NI\\xfe!\\x1e\\x04\\xbd\\x898\\x86\\xcf8\\xde\\x8f+G\\x12\\xcc\\xa5\\x93\\xaa\\xdf\\xf0\\x18\\xe7/\\x88\\xbf\\x18\\xaa+\\xf3\\x03\\r\\x1e\\xa3\\x15\\xedd\\x04\\xfd\\xc9\\x18\\x99\\xbc\\x80\\xba\\x94\\xe3\\xf1\\xd9\\xb7\\xed\\x1eq4\\xb5\\x93J\\xefT\\x06\\xadLAyV%\\x8cw\\xd2\\xb7$\\xdf\\xcc\\xee{\\xe2\\x81\\xe3\\x97\\x8a\\x8f3\\x82b\\xe0F\\xc7Ie`t\\x9f?\\\\X_\\xbd\\xd6\\xba\\x16v\\xa8\\xa7Gas\\xad\\x19\\x888\\xabx\\xde)\\x82\\xb4\\xa7D\\xc9\\xac\\x13\\xa2\\xdb\\xfd\\xba\\xe2U!\\x9cK\\xc8(\\x86ORg\\x15+\\x04j\\x1a)\\x12\\xde\\x12c\\x04\\x11\\xe8q0$j\\x9aB\\xc9\"\\x03m\\xd6\\xdb\\x1fB1]dl\\xd4\\xca\\xbc\\xb9CS\\xc9\\xb8G;\\\\u\\xb1\\xecphB\\xc9\\x97\\xbe\\x99\\n\\xdd|\\r\\xaa\\xc5[\\xb7\\xa6#\\xc9\\x8c+\\xea[\\x8f!l{\\x8c\\xb9\\x7f,\\x0b\\xd2\\\\#\\x1d\\xd0\\xf8\\x808Bx*jc\\x02Y\\x15\\xbcW\\x00\\xa0\\xb6#r\\xbc\\xcaI)\\\\9\\xd3\"6\\xf6\\xf7\\xc4\\xb2Us\\x92\\xf6U6\\xea\\xb8a\\x05\\x0cP\\xa7\\x12*93z\\x19\\xa6\\x94T\\xba\\x17 \\x16U\\xd8\\x8d]\\xff\\x00<o&}\\x99G3h\\xaf\\x90\\xeaR\\xa09\\xd9o\\xd6\\xc3\\xf4\\xc3\\xf9\\xaa\\x07)\\x90\\x167\\x1d@\\x06\\xdf\\x9e \\xe6D\\x12\\x05\\x05\\x15\\xc9\\x04\\x12/\\xb7\\x91\\xbfC\\x86.F2f\\xc6\\xa3Q\\xd3\\xe7\\xf9\\xad\\xadO\\x99\\xca\\xa62\\\\\\x067\\xb8\\xf2\\xbd\\xb1\\xbe_\\x9f\\xd6\\xc5M\\xa0\\xcf;Y\\x8d\\xad \\xb0\\x1dl6\\xc4\\\\\\xb3#YV\\xcb\\xe2;\\x12\\x01\\'\\xa6\\x15M\\x01\\x00\\x91<@oc|\\x176\\xa8<\\x16\\xe3N\\x12\\xf8\\x7fQ\\x9f\\xd5\\xd5\\xc35lyt\\xd4\\xa7\\xf8\\x90:\\x930=\\x9fI\\xb5\\xd3\\xb1\\xb1\\xb8\\xebc\\x89\\xf9~\\x16\\xcf\\x96\\xe7/\\x97R\\xc63/\\x98\\x97\\x95\\x1dN\\x90#\\x8e\\xe0\\x1b\\x92v\\x07\\xad\\xfb\\xf9a\\x87\\x0e|A\\xceNgC\\x96E\\x98QPR\\x99\\x87\\xcc\\xd4\\xcdN\\xa6\\xfen\\xedb\\xc4\\xf6\\x1b\\xf9\\x001t\\x0c\\xd6,\\x85h!\\xccf\\x88s$\\xe5\\xf8WAfn\\x84\\\\\\xde\\xe7\\xcb\\xd7\\x1d\\xd7\\xcf\\xe2\\xa0\\xc3\\x8f <\\x9d\\x80\\xd7\\xf8\\xbe\\xbeg\\x1f\\xc7\\xc4\\xad\\xc9\\x97\\xdb\\xef\\x07\\xf2l\\x9f\\'\\xe1,\\xd9\\xa4\\xa6\\xa5Z\\xf1\\x16\\x85\\x8d$!\\x84l\\x0e\\xf6\\x02\\xe0\\xdc\\x8b\\xdf\\xa8\\xf4\\xc4W\\x1ee\\xb42\\xe5\\x94\\xf9\\xbcT1\\xa4\\xca]\\xde\\xa3\\x98#2\\xb3\\xb92\\xb0\\x16-#\\x12~\\xa2@U\\x1b\\x03\\xd7\\x13\\x1cI\\xf1s\\x84h\\xaak\\xa9\\x9e\\x86\\xaa\\xba\\xbd!\\x92;TRh\\x11Kk*\\xd9\\x8e\\xc2\\xfdv\\xc5}\\xc7_\\x14\\xa6\\xe2\\xc2(\\xe8)\\xdf*\\xca\\xc4\\t\\xcc\\xa6\\x06\\xc8\\xee@\\xdbH\\xda\\xc1\\xafb,m\\x8e\\x8e~\\x18\\xc6@\\x1c\\x15=(\\x1d\\x1frO\\xbc\\x12\\xe8\\xa3Cb?\\xca\\xbe\\x1b\\xd1\\xd4\\x88k3VzU\\xa9\\x87YP\\xe1Dgs\\xb7\\xb8*}\\xc1\\x1d\\xf0\\xb7\\x14\\xfc/\\x8b$\\x8ds\\x0e\\x13\\xaeys\\x18\\xe3i\\xbeWO3Ld\\x93\\xa8\\xb7DP\\x9d\\xd8\\xef\\xbf\\xa6#8W\\x8e\\x03%.U\\x9e4\\x8dF\\xaa\\xb1\\xc0\\xea5\\xb0bB\\x8dL\\xc7d\\x00\\x92v=\\x00\\xc1\\xdf\\xfdY\\xc2\\x155u\\xb9\\x0bSfu\\xcf\\x14\\xb2\\xac5t\\xdc\\xb9bp\\x06\\xceU\\xfc>\\x97\\xb5\\x85\\xbc\\xb08\\xd7\\x16Q\\xc6\\x87\\x12;\\xdf+\\xf7\\x152\\xd1\\x85\\xfb\\xca+*\\xab\\xd1Y-MB\\x16VR\\xe6Aa\\xa5\\x88\\xed\\xe7s\\x8bG\\xe1W\\x15OWU>L\\xb2\\xd0\\xd2B\\xa6\\xf4\\x90\\xb8s4\\xec\\xc4\\xf8W\\xaa\\xed\\xde\\xf6\\xd8\\xf7\\xdf\\x15\\xe7\\x11\\xf0\\xf5fO\\x15-EqHV\\xbc=J\\x8dK\\xaa\\xc5\\xad\\xe2U\\x16R/\\xb0\\x1b\\x1d\\xed\\xb6!j\\xab!\\xd3\\x0be\\xa9%7,]\\xdbU\\x89>\\xfdq\\x1e\\x0c\\x8d\\xe3f\\xe4\\x07\\xfeE+\\xb2\\x8a\\xb9\\xd2\\xd0p\\xd7\\x0c\\xe6\\xb0MW\\x9c\\xe5T\\xf2\\x86h\\xd5%/\\x19Q\\xcb&0\\x81\\x8b\\x81`A\\x1d@&\\xc0\\x83\\xb6(\\x1e:\\xc9\\xe2\\xc9\\xb8\\xa6\\xb6\\x87-\\xa2\\xcci\\xe0R\\x18%tj\\xafcs\\xb6\\x8f\\x0e\\x8f\":\\xe1\\xc6M\\xc7\\xd9\\xa6]\\x90\\x0c\\xb1b\\x8a\\xa2\\x9e)\\xa4(\\x8e\\xbe\\x13\\x1c\\xa8VX\\xc8\\x1fPk\\x86\\xeb\\xb1Ql\\x10\\xf1\\'\\x06f\\xd59^W[\\x994Y|\\x12\\xc0\\x91B\\xb2\\xa1\\x12\\xa8\\x00\\x0b[\\xb8;\\xb5\\xc9\\xf3\\xbd\\x8e\\x1c\\xee\\xbe\\x82\\xa2\\x82k\\xb2{\\xdf\\xdc\\xfb\\xef\\xa8\\xc3\\xf8\\xe7\\xe9\\x1b\\x95\\xbbF\\x08\\x91<*\\x00\\x16 \\x83o<6\"\\xc2\\xf2>\\xd6\\xb8\\x04x\\x8e$s\\\\\\xb0\\xe4\\xb5\\x06\\x97\\xe6\"\\xaa&\\x08\\xa5\\xba)\\x1aK.\\xad$\\x1e\\xe2\\xf8J\\x86(\\x92v5\\xb0s\\x93F\\xe5\\x9a\\xc07\\x9f\\\\J~\\x9b\\x93l\\x12\\x0cF\\x81\\xa4\\x92\\xae.[\\x08\\xb40`\\x7f\\xa6\\xdb\\xe2\\xdb\\xc8\\xb3(\\xb3\\xaa9ii9oT\\xc8RhA%\\xb4\\x9e\\xfb\\r\\xf6\\xee/\\xd4_\\x15~a6\\\\\\xaf\\x08\\xcb\\xa1\"$\\x8e\\xd2\\x86k\\xea\\x7f0|\\xff\\x00L\\x1b|<\\xe1\\xb9\\xeb\\xa0|\\xc1D`\\x92\\x16\\x94\\xc33\\x06\\x89\\xd4\\x86\\xb1\\xb6\\xc48\\x05X\\x13\\xac]Xm|7\\x08\\xc9\\x96\\xd5\\t\\x17\\xff\\x00\"U\\x8c\\xf047\\x16\\xcf>\\x1cfyu4\\xf5T\\xbaf\\xa7\\x88s\\x1e6uW\\x8dm\\xddI\\xbe\\x04#\\x8bE\\x960\\x19\\xfc\\xed\\x8b\\x87\\xe2?\\x0f\\xe75\\xdc<k\\xa4+\\x98\\x18\\xab\\xea&\\xbb\\xc6\\xaa\\xd4\\xb4\\x85\\xca\\xc4\\xa8@\\x07{\\x12W{\\xea\\xb8\\x17\\x17\\xc5N\\x91\\x08\\xd8 \\x9016\\xbf\\x9a\\x8f,\\x07\\x99\\x8c`p\\x14P\\x97\\xe3\\xfa\\xf75\\x85J\\xcc\\x01:\\xe46\\x03\\xbe\\x0f8a\\x1a\\x18*\\'\\xd2X\\xc3b=\\xed\\xb7\\xe6p5OO\\x1c$\\xc8,\\xcf\\xf4\\xaf\\xf7\\xff\\x00=\\xf0a\\x95L((Y\\xaaE\\xd5\\x00gS\\xfc\\xe4\\r\\x868Y\\xda\\xc4\\xe8\\xe0N&F\\xf1\\x05\\x17*\\x9a\\x14\\x9a\\xed9P\\xc6\\xfb\\x91}\\xc98\\xaf\\xe4\\x8eI3C\\xa0\\x0b P=\\xba\\xff\\x00|\\x1f\\xe7\\x13K*\\xf3jd\\xbbI\\xe2k\\x1d\\xff\\x00\\xe0v\\xc4\\x16_\\x97\\x99\\x0f\\xcd \\x05\\x99\\xb5\\x15\\xf2\\x1d\\xb0^;pRL\\x1f%=F\\x00L\\x9f\\x88\\xeb\\xb2\\na\\x14i\\xf5\\r\\x88l7hx\\x86\\xa6\\x86\\x8f1\\xa84\\xc9\\x05\\x7f1\\xa9\\x83\\xd5(y4\\x12\\x1a\\xcb{\\xf5\\x16\\x17\\x1b\\xf6\\xc4\\xe6w\\x96E=\\x18yWg\\x16$\\x1b\\xdb\\xc8\\xe0\\x01\\xa9\\xa4\\xa5\\x98\\t\\xa2=|.\\x01 \\xfb\\x11\\x8b|e\\xc4\\xeb\\xc8\\x8d\\xc8|\\xbc\\x99\\xf1\\xb7\\x1eZ\\x86<-\\x9eO\\x95\\xe7Q\\x8a\\xb8\\xe4\\x8b\\xf9eV\\xd8\\x91\\xdb\\x1dy\\xf0\\x7f\\x8a$\\xa9\\x10E#\\xe9f6\\x00\\x9d\\xec\\x07O\\xb68\\xb62\\xf3\\xfc\\xba\\xd3\\xeb\\x92H\\xa3\\xf11\\xb9\\xde\\xf7\\xb0>\\x98\\xeb\\xbf\\xd9\\xf3\\x87kj\\x12\\t\\x9a.@6\\x1c\\xc9T\\xd8\\x8f!lK\\x9f\\re\\x0c\\x92\\x9c\\x19Kb!\\xe7M\\n\\xdeL\\x17[\\x97`\\x00\\xc4.q$\\xe2\\x1a\\xaa\\x92\\xad\\xa5\\x10\\x9d\\xbd\\xb0^\\xb9\\\\q\\xf2\\xe3\\x03\\x98\\xe7\\xab[a\\x8c\\xcc\\xb2o\\x9b\\xa1\\xad\\xa7U\\xd1\\xae2\\xa1\\xad\\xde\\xddp\\xf6\\xc6\\xcd!\\x0c\\x01\\x9c;\\xc5\\xfcV\\xd4r\\xd4\\xd6VT\\x19B\\xb5\\x82}\\xff\\x00\\xdb\\xf5\\xc5\\x1f\\x9d\\xf1\\xbc\\xf9\\xa4\\xed\\xcb\\x0b\\x02\\xdfc\\xe9\\xed\\x82/\\x8a\\xb5\\xd3Sg5t3\\x8eY\\x86VF\\nn\\xa4\\xab\\x11\\x7f\\xc6\\xf6\\xc5P\\x85EI5\\x11\\xb4\\x90\\xf7\\n\\xfaO\\xbe\\'\\xf1<`\\xd6\\xcd/\\xf2\\xbc\\xafL\\x05X\\x7f\\x92f\\x02Q\\xa9\\xaa\\xa4g\\xf2,-\\xf8a\\xf7\\x10L*\\xb2\\xa9.\\x11\\xec:\\x14\\xff\\x00\\x0e+\\x1ea\\xa5\\xa9G\\xcb\\xdd\\xc8\\xeaT\\x9e\\x98 \\xa8\\xce\\xa4\\x14O\\x1dH*\\x1d:\\xf5\\xb7\\xbe\\x19\\x93\\xc7epA\\x81\\x8b\\xc9\\\\\\x98\\xc8\"\\xa3\\xec\\x8eHk\\xe9%\\xa2\\x99\\x8c3)\\xe6\\xc2\\xc7qq\\xb1\\x07\\xbd\\x8f\\xfbbz\\x19\\x1a\\x96\\x99\\xa9j-\\xa2T:\\\\\\x1d\\x8f\\xfb\\x1c\\x01e\\xae\\xd1\\xcd\\x13\\x83\\xb8k\\x83{z\\x11\\x82\\xfc\\xc2V\\x8b.\\xbc\\x84\\xf4\\xba\\x9f</:}Q\\xb8\\x1f\\xe8\\xfc\\xa4u\\x1b4\\x0fP\\x01\\xb1\\xb8 \\xdc\\x1f\\xd3\\x12P\\xc8n\\xaf\\xb8G\\xf2\\xecp7G8J\\x8f\\x1d\\xf4:\\xd8\\xdb\\x13\\x99t\\xa6)9r\\x90\\xf1?\\xd2\\xc3\\xbe3\"\\xf7\\x0b\\x13{I*\\x86\\x92$\\xe6\\xf2\\xe3\\xa9\\x1d\\xc8\\x16`=\\xc6\"+s(e\\x88\\x90\\xa3J\\xdb\\xc2G\\x89}\\x8f|N\\xaeS\\x15T\\x8c\\x16\\xa9\\xa9w\\xd5\\xa9_M\\xbd\\xef\\xd7\\x0c3~\\nz\\x98\\xd4\\xd2\\xe6\\xb4\\xcb#)%\\xa5\\x1a\\x03\\x0f\\xb7|{\\x160\\xde\\xf1Y\\xb2\\x15\\xbdA\\xa3V\\xadpAk\\x1b\\x83\\xd7\\x0e\\x174\\x8e\\xde1c\\xe40\\xca\\xb3\\x83\\xb3\\xca\\x15\\xd4\\x86\\x96\\xae2M\\x9a\\n\\x94k\\xfd\\xae\\x0e\\x07\\xe5\\xa8\\xa9\\xa7\\x91\\xa2\\x9d\\x0cr!\\xb3+\\x0b\\x11\\x8b?\\x86\\r\\xd1\\x90\\x7f\\x14\\xcb\\xd8\\x934n\\x94s\\xb1\\xd2\\xb3\\xd5[\\x98\\xf7\\x1b-\\xba\\r\\xbb\\xdf\\x1af\\xfcI_\\x9b9\\xf9\\xe9\\xa5\\x95U\\xae\\x91\\x86\\xb2)\\xf3\\x1e\\xa3\\x0cYZ8\\xc4H\\x00V \\xcaI\\xb6\\xe3\\xa0\\xc6.\\x8ah\\xe5\\x06\\xd2\\x19;\\x8e\\x83\\x7f?<9q\\xaf.gfr\\xc3\\x1a\\xab\\x8aT\\xd4\\xc9\\x9a\\xd4\\x9a\\xbc\\xe2\\xa2Y&\\x90\\xaa\\xbc\\x8eu\\xb3\\x00,\\r\\xfb\\xd8\\x01\\x8fgH\\xe3\\x94\\xc3I)\\x92-vY\\x1ci\\xb8\\x1d\\t\\xf2\\xc33\\xa7J\\xaa\\xd8F\\xaf\\xa8\\x8bo\\x87|\\xe8$\\xa7<\\xb4\\xb3+j\\xbb\\x1b\\xed~\\x9e\\xf86&\\xee\\x0fz\\x89F\\xce\\xca\\xcb\\x1f\\xd5k(^\\x8b\\x8b\\xa3\\x80r\\xfa\\x1c\\xdb\\x86\\xed\\x94R\\xc8\\xd5\\xd0N\\x12\\xae+s\\x1aO\\x0f\\xd4\\x1b\\xcb\\xaf\\x87\\xa7n\\xf8\\xa6ZvS\\xa66-\\x1d\\xbb\\x8b\\x12}\\xf1?I\\xc6Y\\xce_\\x92E\\x96e\\xd9\\x93\\xd2\\xd2$r\\r1\\r\\x17,\\xd7f$nX\\xed\\xb9\\xec\\x00\\xc3q2\\xaf \\xd7D\\x11\\xae\\xf7\\xf3\\xed\\x0f\\x1b\\x847:\\x16\\x83\\x87\\x7f~S4SG\\x0cu0\\xa1\\xb3T\\xc3\\x13<Jv,#\\x90\\x906\\xb8\\xd5c\\xd3\\xb6+.\\x1c\\xf8]\\x94q\\x14s\\xc5M\\x9d\\x91$FDd)\\x19^z\\x13pJ\\x9f\\xa5\\x80\\x05X\\x13qq\\x80~%\\xe3\\xba\\xde&\\xccr\\xd9`\\xbe^h)\\xc4)$R\\x10\\xc4\\xf5f-\\xd7sso\\\\!\\x92\\xf14\\xb9>`j2V\\x92\\x05\\xe5\\xda_\\x16\\xd2\\x0e\\xf7\\xf4\\xbe(9\\xb1\\xe3@\\x9cK\\xf1\\x1d\\x93\\xb3\\xf6\\xb8\\xd6uf\\xb25,Jo\\x87\\xd9\\x9f\\x07\\xcd\\x96\\xf1\\x15NT\\x9f\\xbb\\xe9\\xd0I\\x14_7\\xcb\\x99da\\xb3m{\\x05\\xdb\\xafs\\xdf\\x07\\x11\\xe4\\xf1\\xf1}%\\x15o\\xccQfU\\x95Z\\xe4ji+K\\xdc\\x8f\\x13\\x03\\xa4l\\x16\\xe2\\xf7\\x07sm\\xb6\\x18\\x15?\\x18(\\xab8f\\x9a\\x86\\xbb-\\x8f0\\xa9\\xe6\\xeb\\xa8\\xa7\\x942\\xa3\\xaa\\xfd\\x08\\xac\\r\\xf7;\\xfd\\xb1T\\xd0\\xf1]nC\\x9c\\xd5\\xd7\\xf0\\xc9\\xfd\\xdae\\x0e\\x826naDf\\xbe\\x9b\\x9e\\xb6\\xb0\\xdf\\x03\\xf8-\\x8f\\xd2qj@\\xb1{\\x07\\xbd\\x1dC\\x19\\x066\\xb52\\xdd\\xf8\\xdb\\x91\\xd0\\xd3\\xe4\\xf4u\\xa6\\x98A\\x9a\\x8b@\\xd2\\xc3fVe\\x1f\\xe9\\xb8\\xdbM\\x86\\xea\\xc3o>\\xa3\\x14r\\xc4\\xfc\\x9dl\\xacQ\\x1bCIo\\r\\xecl/\\xe7\\xe9\\x823_\\x9bq\\x18\\x98\\xe7s\\xd4T\\xcedW\\xd2#\\'r\\x15A\\xb7b| \\x1e\\xfbb1\\xe8\\xebh\\xb5P\\xe6fjH\\xd8\\xf3\\xd1%SbE\\xc0kz\\xd8\\x8b\\xe1Y\\x9dY\\xad\\x05\\x01C\\xfe>b\\xb2\\x0eG\\x97\\xdeD\\xea\\xe5\\x9b\\xb2X.\\xe4Z\\xc7\\xff\\x00X*\\xe0~+<9\\x98\\x89*\\xa8\\x16\\xae\\x96h\\xb4\\xf3\\x01\\xd1$j\\xa4\\xee\\x0fB.M\\xc1\\x06\\xf6\\x16\\xb1\\xc4w\\x0bp\\x86a\\xc69\\x9bP\\xe5\\x02\\xd2\\\\3\\xcb#iE\\xbb\\x00I?\\x7f\\\\:\\xce\\xb2Z\\x8c\\x82\\xb8Pf\\xd0:\\xd5\\x18\\xd5\\xca\\x17\\xb5\\xd4\\xfd\\'o=\\xcd\\xb6\\xc6\\x02\\xf8\\xc0p?\\xde\\nr]\\x89\\xd5\\x9c3\\x14\\x9cG\\xfb\\xde\\x92\\x9a\\xbe,\\xc1bm\\x12\\n:\\xa5Ic\\x16\\xd9\\x81*\\xd6\\x06\\xfdG\\xe21\\xce\\xbca\\x93\\xd3e\\xdcM]O\\x97\\xc5$q\\xc0\\xfb\\xa4\\xd5)P\\xd7\\xe8It\\x00\\x1fk\\x02;\\xef\\x89\\x0e\\n\\xab\\xa5\\xa0zY2z\\xca\\x9c\\xbe\\xbd\\x883\\xb4s\\x10\\xc8\\x01\\xf1(\\xd8xH\\xdb|D\\xf1TF\\x87>\\xab\\x92\\x072,\\xd7\\x97SK\\xad\\x9a\\xe3r\\xdeW7\\xd8\\xf6\\xb6\\x05\\xfd!\\xe1\\xae,K\\\\OWt\\r\\xff\\x00\\xbdN\\xca3r\\xe4\\xde\\xf3Hj\\x16\\x88\\x19$B\\xec\\xa2\\xe7\\xc8y}\\xf0\\xbcu\\xefV\\xea.\\xc5Z\\xc4\\x0b\\xf7\\'\\xfc\\xfc0\\xca0+\\x94D.!r\\x0c\\x8d\\xddv\\xe9\\x89sC\\x15\\x0cw\\x88\\xdd\\xc9\\xd8\\xda\\xfa\\x7f\\xf7\\xbf\\xe5\\x8e+\\xd0\\xef\\xb9\\xd0K#]M\\xeb\\xe52FF\\xc5\\x13v=\\xc9\\xb7O`-\\x8f8)\\xe0\\xae\\xa6Xda\\xccQ\\xf4\\xde\\xdfpp\\xd2\\xb6\\xa5\\x05<\\xe1n#H\\xf6=\\xce\\xdb\\x9c\\x12\\xfc5\\xf8}W\\x9f\\xc1\\xaf)\\x02\\xa4\\x80\\r\\xa36u>\\xd7\\xc6\\x05\\xfc31\\x9b\\xf1\\x04u]\\x93\\xce\\xe9\\xa5#\\xbc$}E\\x81\\xb7\\xae\\x05f\\xc8\\x8b\\xd4\\x14\\x80>\\xa7kXu8\\xean\\x1b\\xfd\\x9cx\\x97:\\xa7_\\x9f\\xa8\\x87/\\x80\\xd8\\x9eq%\\xbf\\x01\\x82x\\xbffX\\xf2\\xe5\\x02\\x96\\xb0VU\\xb1\\xb1\\x95\\xa3\\xb2F\\x0fR\\x07s\\xef\\x85\\xe3\\x19\\x90]G3\\xe1}1\\x9c\\xb7\\xf0\\xeb\\xe1~o\\xc5|Y\\x16Y\\x92\\xa3\\xb9 \\xac\\xcf\\xa6\\xe9\\x12\\xf7$\\xf4\\xc7\\xd2\\x9e\\x10\\xe0j>\\x1a\\xc9(2\\xdahS\\xfe\\xd9\\x14\\x16\\x03\\xa9\\x03\\xae\\x18|9\\xf8{\\x92\\xfc:\\xc9\\xd6\\x1c\\xbe\\x9c\\n\\x86\\x03\\x9d3\\x0b\\xbc\\x87\\xd4\\xe0\\xd5\\xb3H\\xa2\\x8bU\\xc08\\xeccJ\\x16\\xdd\\xce6\\\\\\x80\\xda\\xa7Q\\xed.Q\\n\\x10\\xcc\\x05\\xc6=\\xa8\\xa5\\x80\\xc7 \\xd1\\xb1\\x168b\\x99\\xbb\\xbe\\xe3q\\x85\\x173\\x8eEd _\\xd7\\x15\\x06R*K\\xc4\\xce\\x15\\xfd\\xad\\xfe\\x14\\xfc\\x84\\xad\\xc4\\xb9U6\\xaaf:j\\x84j?\\x87\\xe4m\\xe5\\x8e1\\x92\\x8aI\\x81b\\xcc\\x9bym\\x8f\\xb0?\\x10\\xb8~\\x87\\x8a\\xf2\\x1a\\xcc\\xb6\\xb5u\\xc7<eH\\xee=A\\xc7\\xcc\\x9e6\\xe0*\\xce\\x11\\xe2\\n\\xda\\tP\\xb2C!\\xd0\\xc1~\\xa4\\xbe\\xc7\\x123\\x0c=J\\x95?\\x88\\x1b\\xf6\\x95\\xdd\\x0e[w\\xdc\\x97=\\xc8\\x1d\\x06\\x08\\xabr\\x7f\\x9a\\xcbf\\x921k-\\x86\\xd8\\x7fE\\x91\\xc8\\xf2\\'(iS\\xfc\\xd82\\x19tq\\xe5\\xe6\\x9c\\x82\\xde\\x12\\t\"\\xc7\\x10e\\xf2-\\x81\\x12\\xdc>2\\xaa\\x91\\xf7\\x94\\xdeT\\x85\\xc3$\\xa3\\xe8;\\x8c\\x16\\xd6\\xa1|\\xa7\\x96\\x18\\xb1\\xb0\\x0b\\xbd\\xecGk\\xf7\\x18\\x82\\xe4\\x1c\\xbb6\\x91\\x1a\\xeb\\xfcM\\x8e\\'\\xa3\\x95\\'\\x8d\\xa1\\xbe\\x89\\x15\\x89U&\\xc0\\xdf\\xb7\\xe3b>\\xf8,\\xc6\\xc8\"g\\x8e)J\\x989\\xf2\\xd2BCFn\\xb7\\xfaO\\x9e\\x1e\\xd3\\xcc\\xf0Y\\x89\\xfe\\x19;\\x83\\xb8\\xc2\\xf3S\\xc9\\xac\\xeb\\xd3\\xabk\\xaa\\x9b\\xef\\xdb\\x1a\\xb51\\xa7\\xa7\\xbb\\xb2\\xb6\\xa2t\\xaf\\xb1\\xb64\\xb5\\xf74\\'\\x1b\\xa8\\xff\\x00\\xe7\\xf5@\\xae\\xd6\\xb8s\\x19\\xda\\xfb`F\\xa6\\xaeI\\x99\\xb5\\xb1u\\xbf\\xf3n?\\xf5\\x85+s\\teA\\x04QN\\x91+\\x92H\\x8c\\xdd\\x8e\\x19\\x11o\\xa1&\\xb7\\xacGlU\\x87\\x17\\r\\x99\\xcc\\xf23z\\x86\\x87QT:m\\x7fu\\x1eXzr\\xe1\\x99\\x05\\x9aEg`4\\xdc\\x02ol2\\x82#!\\xb7.A~\\x80\\xc6pe\\x93\\xd3\\xd5AD\\x16:Y\\x98\\x16&\\xfc\\xb6\\xff\\x00l1\\x8du\\'E\\xb8;\\x91\\xe4Rg\\x91\\xd7V\\x19\\xa01P\\xa6\\xb9\"v\\xe5\\xb3\\x8d\\xf6Q\\xdf\\xcb\\xef\\x88:\\xf9!5\\x8f%,F\\x9a\\'\\'\\xf8c}?\\x8e\\x1cS\\xc8\\xe1\\xb9\\x02\\xf1\\x8e\\xac\\x83n\\x9d/\\xe7\\x84k\\x9a\\xc7\\x92\\xab\\xf4\\xb1\\xb9\\xf38%\\x046\\xe2\\x0b\\x0e!@\\x8cc}\\x1a\\xac5\\x7fN$f\\x8d`vER\\t\\xb0\\xd2\\x07C\\xfe\\x1f\\xcf\\x1e\\xd3em4\\x90\\tT\\xc1\\x1fWp.\\x0fS\\xf6\\xc6T\\xc5QS3\\xf3\\x99@\\xd7rC\\x86\\x08;\\x0b\\x83li`Op\\rF\\xa0\\x97~ZjK)&\\xfd\\xb0\\xf6~I<\\xb52\\xae\\xc3\\xc6T\\x1d\\xfc\\xac:\\xe1x\\'\\xa5\\xe7\\x96-\\xccro$\\x85vU\\xbfA\\xf9a\\x94\\xdc\\xe9kez7\\xb0RB0!M\\xaf\\xb63\\xb3\\x06\\xa2SB\\xd1\\xa3)$\\xb6\\x9b\\xf4\\xb0\\xb7\\xb6\\x14\\x829\\x12\\x07*\\x97\\x0f\\xa7\\xf0\\xff\\x00\\x9f\\xd3\\x0b\\xac\\x13\\x15\\xe6U\\xeadQ\\xbd\\xfc\\xbb~\\xb8\\xd2#\\xff\\x00q\\xe1o\\x02\\xae\\xc4\\x8f\\xce\\xdeX\\xdb\\xd4\\xf02b\\x8a\\x91\\x88\\x86D\\x1a\\xf4\\xb1\\xd4\\x01\\xb1\\x04\\x0b\\x85\\xfb\\xdc~\\x18\\xf6\\x933\\x96\\x8b)\\xa9\\xa5\\x92\\x9a\\x82\\xf5O\\xe0\\x9aX\\xae\\xf1\\xdbk\\x03m\\x81\\x17\\xb8\\xc2\\x19~n\\x92%M<(\\xf1\\x81\\x11\\xbb\\x06\\xdd\\xc7s\\xd3\\xae\\x14\\x92\\xa7-1\\xa4SUL\\xdc\\xa0\\x0f-\\xe3$\\x06\\xfb\\x1d\\xce%\\xa6\\xe5L!\\xa9(lK\\x1b\\x83x\\xcf-\\x8a\\x82\\x8a,\\xd9\\xa9\\xa5\\xcc)\\xe14\\xcb70\\x86x\\x83jP\\xdbo\\xa4\\x81o/LD\\xf1vm\\xc3uC2\\x9d)j\\xb3L\\xda{\"\\xcae\\x10\\xd3R*\\x8b(D\\xfa\\xa4 wb\\x01$\\xed\\x80\\t91\\xcc\\xb2P\\x19\\xdeR\\xda\\x9eGU@<\\x80Q|2\\x8ag\\x152\\xab\\x1bs.\\xad\\x7f\\\\\\\\se~\\xce\\xab\\xaa\\xfd\\x7f8E\\xedx\\xcb\\x03\\xe1\\xb7\\x14\\x1e\\x1b\\xae\\xac\\x8a9\"Zi\\x8a\\xbc\\xadP\\xfa4\\x90?\\x95{\\xb1$\\r\\xbb`\\x9f\\x8a\\xf8\\xb7$\\xcf\\xf8o0\\xa3\\xa3\\xac\\'3\\xcd+#\\x96\\xa8\\x88E\\xcaG\\xf4\\x87\\x90\\xff\\x00(\\x00*\\xa2\\xed\\xd2\\xfd\\xc9\\xa9\\x96\\x82\\xaa\\x92dY#\\xff\\x00\\xe9\\xebR\\xa4\\x1d^X\\xf0\\xc3P\\xae\\x12\\tD\\x92\\x1b\\xe8\\x8a\"\\t\\xd5\\xec:\\x9c\\x0e<\\xce,+X\"\\xbe?1\\xf3\\r2\\x15\\x1cH\\x934\\x15\\xaf\\x93L\\xe6\\x17\\x13\\xc4\\x1c\\x19\\x16\\xc1CX\\x1b(;\\xda\\xd7\\xc1/\\x18\\xd6RVP\\xd2M\\x97\\xc9\\x04\\xb0\\xc8\\x00\\xbd\\xb4\\xc9\\x0blY\\x0fb\\r\\xf66\\xecp7\\x93d\\xd5\"\\x97\\x99W\\x03\\xac2\\x04q!\\x17\\x1b\\x96PO\\x95\\xca\\x91l\\x14~\\xe3\\xe7\\xe5\\xe5\\x15um\\xb0\\xb5\\xc1\\xc61*\\xa4\\x11\\xb3\\xef*\\xc6\\xe4\\x1f\\x88/F$Z\\x86\\xb5\\xf9}[\\xf1\\xc1\\x0c2\\x90~Y\\xe3f\\xe5/2Bv\\x1b\\xf5&\\xfdq\\x05\\x1dK\\xe5\\xf3\\xbc\\x15\\x16\\xfe\\x19\\xb6\\x82\\xb6\\xdf\\xb5\\xfc\\xf1\\xbc\\xd55\\x15\\x90\\xb9D3\\xa1rB\\xae\\xde\\x1d\\xbb\\xf9\\x83}\\xb1\\xcdt,gQ\\x1c(\\x9bfLDu)\\xafy\\x98l\\xbe\"\\x01==\\xff\\x00\\xce\\xd8\\xbc\\xff\\x00f\\xd8R,\\xd5\\xe0/\\x14\\x95$\\x0e_2\\xe1U\\x81\\xe8\\xc4\\x1b\\xf4\\xed\\x8a\\x9b/\\xc9\\xca\\xab4\\xd1\\xea\\x99SV\\xe2\\xf6n\\x83\\xef\\xbe\\x0b\\xf8\"\\xa2\\xb7\\x87\\xf3h\\xaai\\xe5X\\x00;_\\xb0\\x1dv\\x180\\x00\\x15&f\\xe4\\xc4\\xcf\\xa3\\xfc=AW\\x1c\\xb2\\xcbWU\\x0c\\x94\\x8c\\xa8\"\\x89\\x16\\xda,7\\xef\\xbd\\xf0K\\xf3\\x94\\xa3\\xc0\\xa0\\x80\\r\\xb7\\xc5W\\xc0<a\\x0es\\x92S\\xcd\\x1c\\x85\\x89]\\xc1m\\xf6\\xdb\\x04\\x95\\xd5\\xcci\\xa4h\\x89W#c\\xd4b\\xa5!DE\\x16;\\x8f\\xb8\\x932jev\\xa5`\\xf6^\\x9d\\x8e9?\\xe2G\\xed\\x19\\x98\\xd2fU\\x19FG\\x1e\\x99bm\\x12\\x19\\x14\\xddXu\\x03\\xcf\\x17\\xad5FgSE*\\xe6a/\\xb8\\x0e\\xa6\\xc4\\x8f;\\x1c|\\xf4\\xf8\\xd7-~]\\xf1\\x0b;\\x14\\x8f$\\x8b\\xf3\\x04\\xa1N\\xc3\\xdb\\x00\\x9f\\x88\\xdb\\x86\\xff\\x00\\x86\\xba\\x97nU\\xfbRqFZ9uJ\\x95\\x03\\xcc\\xf9`\\x93\\x86?k*\\x99\\xb3H\\xa9\\xf3\\xcaq\\x1cN@\\xe6\\x0b\\x1b1?\\xa68\\xa3\\xf7\\x8dZ\\x00ewY:\\xb0n\\xa0\\xe32\\xfc\\xca\\xaa\\xa6\\xad\\x11\\x0b\\x17g\\x00\\x00/s\\x87\\xfa`u&\\x19\\x89\\xd4\\xfa\\xab\\x95\\xf1\\x9d>w\\xa4\\xc7(%\\xc0 )\\xbf\\\\\\x03q\\xbf\\xc3\\xea\\x0e&\\xceRj\\xc8ocfu\\xd9\\x80#\\xae\\x19\\xfc&\\xcbNS\\xc3ydy\\x94\\xa1\\xaa\\x12\\x15$\\x0fk\\xe2\\xcc\\x15(&\\x0c\\xe0Y\\xc5\\xafk\\xe2Z\\xe6\\xb4\\xd2\\xbb8\\xcd\\xac\\xa1\\xb3/\\x814\\x140\\xc94\\x0f$\\xd1\\x00H\\t\\xb5\\xbf\\x0cT|G\\x96G\\x93\\x89\\x82\\xa58\\x89.\\x08yY\\\\c\\xa1\\xfe.q\\xa2\\xf0\\x86Q$\\xcbv\\x92K\\xa4!\\t\\x00\\xb5\\xbb\\xf9\\x0f|pG\\x16f\\xd9\\xa6w\\x9c\\xcd6mS$\\xc5\\x9bP\\x17\\xb2/\\xa0\\x1d0\\xa1\\x81I\\xea\\x11\\xf2\\x1c{\\xc7\\xd5\\x03\\xf7\\x96e,\\x9c\\xa5H\\xc0\\xd8\\x06\\xbd\\xfdN\\x10\\x919r\\x02\\xe4\\x84[\\x12\\x0fk\\x7f\\xc6=\\xa1S\\x04N\\xba\\x8d\\xf4\\x8d\\xba\\xed\\x84*\\x1d\\xf4(&\\xea\\xcd\\xee\\x0e\\x04\\xed\\xa8G\\xae\\x97}\\xcfhj\\x8c\\x95\\x85\\x9a\\xfdK\\x01\\xeb\\xff\\x00\\x18\\x97\\xca\\xe9\\xd5k\\xa3\\x96\\xa5u\\xc2\\x847\\xd4\\x06\\xad\\xee\\x07\\xb6\\x07\\xe3q\\x04\\x8ac\\xb1*n}\\xb1$\\xf9\\x9aSF\\xcdi\\x02/\\x88\\xa2\\xaf\\\\\\x15}Z\\x80Z\\x90\\xc3?\\xde\\x19`\\xd7j\\x18\\xdbW_\\x10\\xeb\\xf8\\xe1\\x01\\x98P\\x89,h\\x91\\x97\\xcc\\xb0?\\xdf\\x15\\xd3q\"\\x92|r\\x8f\\xfe#\\t\\x9e \\x88\\xde\\xef)\\xf7PqO\\xa6\\xd2.k,\\xf8\\xb3\\x1c\\xbb]\\xfeM@\\x0b\\xa4\\x00\\xc7\\xfba\\xfc<G\\x152r\\xcaT\\xafp\\x16M\\xbe\\xdbb\\xa1\\xff\\x00\\xa8\\x90tw\\xb7\\xacc\\x0b\\xc5\\xc5\\xad\\x1a\\xe9\\x040\\x1d5D\\x0e3\\xd3q\\xd0\\x83\\xcd~\\xf1\\xfea\\x922\\xc4s:Ji[.V\\xe5\\xa5N\\x8b+\\xb5\\xf7\\xf6\\x07\\xae\\x1b\\xe4\\xbc\\x15\\x9f\\xf1#fS\\xe49y\\xadJ\\ng\\xac\\xac\\x902\\x81\\x04@\\xee\\xcd\\xa8\\x81\\xdcXu=\\x05\\xf1\\'\\'\\xc4\\xaa\\x96\\xe1h\\xb2\\x93\\x12\\xf2\\xa1\\x8f\\x92\\xc4Yu\\x83~\\xd6\\xdb\\xb6\\x06\\xe4\\xcf\\xf3\\x0c\\xb6\\x9ahr\\xca\\x99 \\xa5\\xcc#Q:/\\xd3*\\xab]A\\x1d\\xec\\xc2\\xfe\\xf8F\\x13\\xe50`\\xc0\\x03z\\xf7\\xd4\\x95\\xd7\\x17!\\xc4\\xd8\\xf7\\xfc\\xe3\\xca\\x8aNM\\x1cT\\x11\\x7f\\xa9#\\x96\\x9c\\x95\\xde\\xe2\\xdb\\x1e\\xdd\\x0e!*DiTiQ\\xef\\x10:M\\x85\\x85\\xef\\xf9\\xfb\\xe1z\\n\\xaa\\xa7\\x8db\\x8eY\\x0b\\xca\\xd7o\\x19\\xd8y\\xe1\\xaaS\\xbf2I\\x04m+\\xb4\\x85\"\\x16\\xfen\\xe4\\xfb\\\\b\\xd4^7f$\\x0b1Y#\\x86\\x04h\\xb5j\\x0e\\xc3Q\\xeb\\xb8\\xe80\\xdbL\\x01\\xca\\xe97\\xf57\\x03\\x1b\\xe5\\xd4\\xedUT\\xd1ll\\ta~\\xb6\\xc6\\xd5\\x91G\\x0c\\xce\\x11\\xc9{\\xd9\\xd4\\x8b[\\xd4z`\\xc6\\x8d\\\\\\xf6\\xe4\\xa5+%Uc\\x1d P$Z_^\\xc4 \\xeb\\xb0\\xeeO\\xe7l%^\\xbc\\xc5\\x96h\\x96(c \\x04P\\x08\\xb2\\xf6\\x00\\xe1\\xf6@\\x8b\\xfb\\xbf0\\xa3\\x8e\\x8a\\x9aik\\x84q\\t\\xaa\\x01\\x06!ru!$[\\xb6 \\x8b\\xcdG,\\x90\\xac\\xae\\n\\xf8\\x08\\x07b7\\xdb\\xdb\\t_\\xa9\\xc8\\x1e\\xd3*-\\x96:\\n\\x85\\xd0<L\\x19E\\xbb\\x9b\\x1cy5\\x02D\\x8a\\xb7i\\'\\xb6\\xa6\\xb9\\x00\\x00w\\x17\\xf5\\xb7_|fWS\\xc9\\xad\\x89\\xe9\\xc1I\\x15\\xbc.\\x96\\x04\\x13\\x87\\xb5\\x19i\\x8a\\xae75\\x1a\\xcb\\x11%\\x886a}\\xc7\\xbe\\x08\\xe9\\xfb\\x9e\\x8d~Y\\n\\x07:bpE\\xec\\xc0\\x83\\xeb\\xb6<\\x9e\\x99i\\xdbQ\\x91\\x0b\\xb1\\xdb~\\x9f\\xe5\\xc6%(r\\xeaRm1z\\x98\\x0c\\xba\\xa4XE\\xca\\x8d\\xc5\\x85\\xbb\\xef\\x86\\xd5\\xd9kKS+\\xc7O<\\x14\\x91\\xdc\\x83\"h$\\x01\\xeaz\\xed\\xdf\\xff\\x00DC\\x8b\"x\\r\\\\\\xde\\x92\\x96\\x81\\xb2*\\xa9\\xeb\\xaa\\xa4j\\xe6x\\xd2\\x8a 6\\'W\\x89\\x98\\xf6\\x00l\\x07\\xbe&\\xf2\\n\\t`\\x94V4iT\\x91\\x10\\xad2\\x1br\\x98\\x9d\\x88=G\\xbf\\xae\\x04y\\xe1\\xd0\\xb3\\x15\\xe5\\xda\\xcb\\x18n\\xc3\\xa0\\xc1\\x87\\x00\\xe70SU\\x8a*\\xc8\\x93\\x9d4\\x80D4\\x16i\\xdd\\xcd\\x80f\\'J(\\x1b\\x9d\\xaeqF\\x0cd\\xbe\\xda\\xa3R\\x8fr\\xd0\\xc8\\xab\\xe0\\x9a6\\x8d\\xe1\\x86~[\\x86e\\x90\\x02\\x8a\\xe0\\x92\\x18\\x8f\\xe6\\xb1$\\xdb\\xa5\\xf15\\x0e^**\\xa4zx\\x01\\x80\\xda\\xe6\\xc6\\xfa\\xbb\\x9d\\xfc\\xf1\\xad,\\xd96EZ\\xc2I~ZI\\x022:\\xa6\\xbb\\xab^\\xc4/pJ\\xee:\\xee\\x08\\xc1~SA5uT\\x93\\xd3\\xd9\\x11\\x8f\\x84(`\\x07\\xd8\\xee1nr\\xc3\\x07\\x1c\\xac\\x0b_\\xb7\\xdaZk\\xda\\t\\xd7p5.ig\\x9e\\x92\\x17m$\\x07\\x0b\\xbe\\xf8\\x88\\xa7\\xf8r\\xb9d\\xe6T2\\xb1\\xb5\\x91\\x9b\\xc4\\x10zb\\xf8\\x83*A\\x10\\xe6Aw\\xb6\\xe4.\\x1b\\xd5e\\xc0+\\x14R\\x07\\xa8\\xc7\\x1d\\x92\\x1a\\x99L\\xc9\\x90\\x98\\x8b\\xb4\\xab\\xd5z\\x83\\xb3zb.W9<\\x90OX\\xb7\\x89\\xad\\xe0\\x03\\xaf\\x90\\x03\\xfc\\x1b\\xf9\\xe2\\xc7\\xcf)\\xf9\\x11H\\xc4i\\x01\\xaf\\xe8p\\x0b\\x9d:\\xcc\\x02\\xba)} mk[\\xa8\\x03}\\x8f\\\\*\\xa1\\\\\\xb48\\x17\\xe2u-\\x13\\xc7m1\\x02,\\xd1\\x87\\x17>\\xfe_\\x9e:\\x07$\\xe2H3:$\\x9a9\\x04\\x88\\xc2\\xe1o\\xbe>|\\xab=\\x1c\\xd2US\\x96\\x8ePl\\x14\\xf4\\'\\xd4zb\\xdc\\xe0\\x8f\\x89\\xc7-\\xa6Nl\\xa6\\x19Q\\x14\\xbb1\\xd9\\xc9\\xf4\\xc6\\x80f\\x86\\x13\\xaa3\\x1a\\xe8\"W*\\xd7r7\\x03\\xb0\\xc7%|i\\xe01\\xc45\\xf3f\\x943-<\\x8a\\x0e\\xdb\\xf8\\x87\\xf9|Yg\\x8f&\\xaa\\xa7\\xd7\\xcaY\\xb5\\x8f\\xad[\\xb7|\\x0b\\xe6y\\xfc\\xf5w\\tB\\x1dnvc\\xee/\\x80\\xe7\\xc4\\xc6\\xf1\\x0c(\\xceR\\x1c?_Q\\x98\\x9ah\\xd0\\xc8\\xf7\\xb6\\xb3p\\xa7~\\xb7\\xc5\\xcd\\xf0\\xa3\\xe1-T9\\xc4u\\xfcDc1S\\xb5\\xd6>\\xab\\x7f2q+\\nVQ\\xd6\\xac\\xb3e\\x90\\x85S\\xb6\\x85\\xe9\\x83\\x0c\\xaf\\x8b\\xe1\\xa2\\x0b\\xccC\\x06\\xc7V\\xd6\\xbf\\xf6\\xc3[=\\x8a\\x11\\x0b\\x84)\\xb3/l\\xae\\xb6\\x9a\\nE\\xbc7Q\\xe1%z\\xae\\x16|\\xce(\\xe4\\xb4Rk\\xbfLU\\xd4|cDF\\xd5kfQ}\\xf6#\\xd7\\x01\\xbcq\\xf1\\x86\\x97$V\\x83*\\x91g\\xae\\x91l\\x9b\\xdc-\\xba\\xdf\\x02\\xacL#\"\\xbfh\\xdc\\xf2\\xa7\\x89\\xabir\\xfc\\xa2)O\\xc8\\x963\\xc8\\x9edt+\\xfc\\xc2\\xdd\\xc7Ls\\xa7&jw\\xf9y\\xd5\\xa2\\x93r\\xaao\\xb1\\xed\\xf66\\xb1\\xfb\\x1cZ\\xf9W\\x10=\\\\\\xcd4\\xae_\\x98\\xc5\\x981\\xb9V>\\xb8\\xdb\\x8brq\\x9b\\xc1\\ru\\x0c\"Z\\xcaE&\\xc0}I\\xd6\\xf6\\xeeG\\x97\\xaf\\xa6\\x0c?\\xfaH\\x81\\xc7\\xfdBU\\xb1\\xcag\\x92-*\\xc4\\x9bj\\xb6\\xc0\\x8cJ\\xcbM\\xcc\\xa3}n\\xb2\\x15$\\xa2\\xafP\\x7f\\xcf\\xd7\\x119`v\\x80F\\xaa\\x03\\x93\\xb8=\\xad\\xdb\\x0f\\xa5\\xa9\\x83,\\x99\\xcdC\\xa70\\xef\\xca\\xf3\\x1d\\xbe\\xf8\\x9d\\x81-BZ\\xac\\x02\\xdbHy$X\\x18\\xb71T\\xae\\xc48\"\\xfe\\x98g\\x98\\xe7\\xadSHii\\xa1Xb?S)7a\\xe5\\xe81\\xa6g^39\\x96H\\xd5\\xa3\\x88\\x0b*1\\xbd\\xbc\\xce\\x18\\x14\\xd3|t\\x13\\x10\\xa0Xnr\\xf2e6B\\x9dF\\x9e\\xf8\\xcc*c\\x178\\xf0\\xc7a\\x87\\xc9\\xe2x\\xcd\\xb1\\xb6\\x9cy\\xa0\\xe3g\\xa4\\x86\\x91QD\\xee\\x90\\x80\\xaan\\xec\\x01\\xbf\\x95\\x89\\xfc\\xff\\x00\\x1c9\\xcbr\\xf4\\xcc)\\xe7\\x85?\\xd5\\x8du\\xa1/\\xb1^\\xe0\\xf9bLC=%\\x02RB\\x84\\x9dE\\xe5\\x8c_F\\xa2,\\x01\\xf3 _s\\xe6q\\x17G\\r<\\x92H\\xf1\\xb9\\x89\\xe3> v[t\\xfdz\\xfbb@\\xf6\\x0c]O\\x18,\\r\\x1cT\\xe7T\\xca\\x07O1\\xdf\\xd7\\x13\\xb49|\\x93e\\x19\\x8d\\\\K\\x1c\\x91FQ\\xe4\\x8fU\\xd8\\xb6\\xa0\\x0e\\xc3\\xb6\\x92w\\xc4^CL\\xf5\\x99\\x9c\\x10\\xc5\\xe3\\xe6?/u\\xb0bz}\\xbc\\xf0\\xf6\\xa8~\\xe9\\xcd3h(\\x1d\\xa4\\xa6]@(\\xdd.[M\\xcd\\xba\\xd8\\x92\\x01\\xc2\\xd8\\x9b\\xe2\\x0e\\xff\\x00\\xeey5\\xb3#\\xeb\\x992|\\xce\\xa5\\xf2\\xe8\\x99\\xe1\\x8evHd~\\xeaw\\x02\\xd6\\x17\\xf0\\x91\\xd7\\x18\\x03\\xd7\\xf8\\x9e\\x85d\\x94-\\xcf 0n\\xa0n\\x05\\xef\\xd4bf\\x92\\x87\\xf7\\x9e\\\\\\xa5\\x95\\xd9z-\\xcd\\xed\"\\r\\xbf\\x156\\xfbb2h\\xf4\\xe6\\x13EH\\n+#\\x80A\\xbd\\x8f\\xd4\\x07\\xff\\x00\\xe4c\\x17 m\\x1e\\xc4\\xf1\\xab\\x88RB\\xd5\\xc4\\xd2S\\x89[\\xe6\\x1br\\xe2\\xec\\x96\\xfdG\\xfb\\xe3Z\\\\\\xaaH\\x876\\xb0\\x08\\xc9\\x1e\\x15n\\xbf\\x87\\x9e\\na\\xa53g49\\x9c\\x91\\xc7OEF\\xb4\\xca\\xd0E\\xb6\\xc17\\x17\\xb5\\x8f\\x88\\\\\\xdfr\\x0e#3$L\\xc6\\xa6\\xa2~D\\xe3.\\xa5t\\x8c\\xcd2\\xf2\\xf4\\x16\\xb9\\xb9\\x1e\\xa4\\x1bu\\xda\\xd8\\xd5\\xcb}u4\\xa9\\x03Q\\x86]-=\\x1dcJ\\xf1,\\xc8\\x10\\xaaD\\xc0\\xaf\\x8a\\xfd|\\xff\\x00\\xe7\\x1b>b%6uE\\x8eM\\xc6\\x95\\xba\\x826\\xe8}\\xb0\\xc9\\xb3\\x15k\\x94\\x8dU\\x7f\\x94\\xb0\\xb98\\xc9\\xe5\\x8e%`bx\\xe7\\x8d\\xc1dam \\xff\\x00\\x83\\x0c\\xe2n\\xcc\\r\\xd4~k\\xea\\xa3\\x85V\\x95\\xa5\\x880\\xfa\\xd8\\xdb\\xec\\xb6\\xd8aq\\x9ffHcG\\xae\\x8aX\\xf7i\\x14\\x05k\\xa8\\x17 \\x827\\x16\\x1d\\xfb\\x9cF\\xf3\\x12h\\x19#R\\xb2\\x94%X\\x1b_\\x11\\xb0\\xa3\\x08\\xa7a{\\x94\\x00\\\\y\\xb0\\xff\\x00lyq\\x83\\xd8\\x85BMf\\xb4B\\x92\\xa9RV\\xd1\\x14\\x9e(\\xac\\xa1W\\x7f\\xef\\xd3\\x1b\\xe5\\x99;IT\\xad\\xcfI,\\xd7=\\x88\\xf48i\\x1dEM}4Tn\\xae\\xc6\\x05y_S\\\\\\xb2\\xfd]\\xfc\\x85\\xff\\x00\\x1c\\x17\\xe4\\xd4\\x14\\xd5\\x93\\xd3\\xcbQ#G$\\xd1\\xa0`\\x00;\\xa8\\xd3v\\xf7\\xb07=o\\x82\\x16\\xa2j\\xa9\\x97\\'\\x04p\\xf4u\\xf1A-|\\xa9`\\x02\\xa9\\'V\\xc0m\\xf8\\r\\xba\\xe2\\xf0\\xe1\\xce\\x1bJ:]q\\x03(\\xb1a\\xdd\\xbd\\x87\\xfbb\\xac\\xe0\\x9aJj\\x1aE\\xa6\\xa1f\\x91Qt\\xad\\xd6\\xfb\\xf7\\xfc\\xf1v\\xe4\\x15\\x89S\\x14)\\x19\\xe5\\xa3\\x12\\xf2\\x10vTS\\xbe\\xe3\\xcc\\xed\\xed|\\x08ar\\xc1\\xd4\\x98\\xca\\xa9 \\xa9\\x99)\\xd5\\n\\xd4\\x18\\x04\\xef\\x1b\\xa9\\x05\\x14\\x9b\\r^F\\xe0\\x8bz\\x1f,N\\'\\x0c\\xc0\\xf7\\x13\\x1dw\\xdc\\x0bm\\x86\\xdc.\\x03^\\xb2e1\\xd4\\xe6\\xccg@\\xc3\\xa4H\\x00\\x8d~\\xc8C[\\xcd\\xce\\x0e#\\x8a8\\xe3[\\x9b\\xb1\\x18h\\xfa\\x85\\xcf\\x03+\\xec\\xcf\\xe1\\x8e_\\x9a\\xc6CB\\x8aORE\\xf0\\x03\\x9f~\\xce\\xa9\\x98)JJ\\xf8\\xe1\\x90\\xb17xo\\xdb\\xa1\\xb7Q\\xdf\\xfb\\xe3\\xa2\\x16\\x11`zcqN\\x1fO\\x87\\xc6v\\xe9|\\x01[\\x8c\\x06q\\x8ey\\xfb0\\xf1l\\x14\\xaer\\xaa\\xfc\\xb6\\xb5\\xecJ#3FG\\xa0$\\x1fO\\xf7\\xc5C\\xc4<\\x1b\\xc4\\xbc\\'\\xfc>%\\xca\\xa5\\xa1Y\\x9a\\xc2@u\\x02@\\xf3[\\x8c}:\\x8e\\x848\\x03B\\x92\\xa2\\xdb\\xfex\\x83\\xe2n\\r\\xcb3\\xda\\t\\xa9\\xab\\xa8\\xa1\\x9e)\\x07\\x89Y.>\\xdf~\\xf8\\x1e\\x13\\xda\\x9f5\\xa98\\x831\\xcb\\xa9\"\\x8a\\x96\\xa5\\xb9`\\x92W\\xce\\xc7\\x04\\x14\\x1f\\x10\\xaa\\x04<\\xba\\x98\\x91\\xd8\\x8d\\x9a\\xd6=\\xc1\\xc1\\x17\\xc6?\\x83u\\xdf\\x0es\\x0f\\x9b\\xa0-W\\xc3\\xf3I\\xa6)H\\xf1@I$#\\xfe\\x81\\xbb\\xfb\\xe2\\xa1\\xab\\xa9\\x82\\x9e\\xe5\\x8e\\x92\\xbe /\\xd6\\xe7\\xff\\x00X\\x1e\\x17\\x03\\x91\\x12\\xc4\\xac\\xf8\\x89\\x1d4t\\xe5\\xd0\\xc8\\xee\\xa3X\\x07\\xa6\\xfb~\\x98\\x17\\xcdx\\xf7\\x9d h#M\\x17 \\x0b\\xf5\\x1ex\\x02\\x9f1y]\\x83\\x9f\\x11\\xb9U\\xfe\\x91\\xe7n\\xd8h\\xd5K\\x7f\\x17\\x84\\r\\x86\\xd8\\xf0\\xc0\\xb3\\xde\\xa9\\x93\\xf5\\\\K\\x98T\\xf3\\x19\\xa5h\\x83\\x82\\x01A\\xd3\\x10\\x9a\\x98\\xb1gwg\\r\\xabQ\\xdf\\x1e\\xd5\\xd4\\xa2\\xacq\\xea\\x16H\\xd7o+\\xf8\\x8f\\xeb\\x86\\x7f6#q\\xb8#\\xcf\\x0cU\\x15\\xa8\\x05\\xa1nG\\\\b\\x94-\\xec[\\xa7\\xbe\\r(\\xb36NX\\xd5\\xb1\\x04\\x9f\\\\V\\x19uh\\xd7\\xd8[\\x06-\\x98Db\\xa1<\\xb1\\r\\xe9\\xc2\\xea^\\xe4\\x12\\t>\\xa7k\\xe1L\\xb4Db\\xbc.\\xa4\\xa9\\xa2z\\xbedT\\x14\\xedP\\xc7\\xc5+B/\\x7f3\\xb5\\xc9\\xc4\\xaeg\\xc396oN\\xa6\\xb2\\x92)\\xe7a\\xe1\\x92\\xc00>\\xc2\\xdbb\\xbd\\x8b6\\x90N\\x02_R}-}\\xf0O\\x93\\xe6\\xb5\\x0bR\\x8fT~\\x91{\\x13\\x8c\\xbe=C\\xd3I\\xdc\\x9b\\xe1?\\n\\x98\\x02\\xd6ek\\xad\\xbb\\t\\x9c\\xfe\\xa7\\x0f\\xb3/\\xd9\\xf7\\x86j\\xa9\\\\\\xd1\\xa4\\xf9|\\xa4]\\\\J]~\\xe0\\xf6\\xc4\\xdeU_\\x14\\xce\\x8c\\xdb+\\x0b\\xde\\xf8.\\xa0\\xcc\"\\xccJD\\xa8\\xcf\\x04gs\\xfdg\\xd7\\xd3\\xf5\\xf6\\xea~\\xa1\\x99\\xe9\\x8f\\xb4\\xe7\\xc9\\x7ff\\xec\\xf9)\\xa6\\x93,\\xaa\\xa1\\xaa\\xd7~[\\xb9e\\xf0\\xfa\\x0blO\\x99\\xed\\xd3\\xcf\\x15Vq\\xc3\\xf5\\xbc3SQG\\x9cS\\x1az\\xe0Jhn\\xc3\\xbb}\\xfa\\x0f\\xbe;\\xe2yd\\xa7U\\x14\\x96\\x95\\xe4\\x1b/\\xf4\\x8e\\xecG\\x90\\xff\\x00\\xd6\\x04\\xf8\\xb3\\'\\xe1\\x8e#\\xcae\\xa4\\xe2\\x0eD\\xbb\\x1d\\x0c\\xe0\\x19\\xd1\\xbf\\xa8\\x11\\xe2\\xb9;\\xf9`\\x86@4LSc\\x1e\\xd3\\x86R.q\\x01WS\\x13`\\x07s\\xe5\\x87\\\\\\xaa*o\\x05B<\\xf2\\x0f\\xa8\\xa4\\xc1T\\x1f!\\xb1\\xbf\\xbe\\x0f\\xf3~\\x0e\\x87(YBJ*yl\\xd1G%\\xf9d\\xc7~\\xad\\xb1 \\xeeWlB\\x0c\\xa4\\xdb\\xf8\\x12P\\x84\\xedh\\xc9\\xfc\\xca\\x93\\x8d\\x19\\x03\\xf5\\x13\\xc4\\xc4V\\xa6\\xa7\\x9dH\\xce\\xa6\\xd5(\\xed\\x06\\x8d\\xc3\\x9dz[\\xf3\\x07\\xf2\\xc4T\\xea\\x82\\xb2B\\x90\\xf2\\x1efgh\\xc9\\xb8\\x03{\\xdc\\xf9Z\\xe7\\xef\\x83zZX\\xf2\\xca4\\x81\\xd4\\xbbP xd\\x1bl\\xc3\\xc7\\xd3rn/\\xf8`^\\x8e\\x07\\x92j\\xaed\\x05\\x1eX\\xfcj\\xc9\\xfe\\x8cz\\x86\\x91oR.}\\x00\\xf3\\xc4K\\x94\\x12\\xd5\\xd0\\x8b+\\'\\xf8w-\\x83-\\x9e7\\x8eV\\xe7\\x18\\xc4\\x11.\\x9f\\xa9\\xdc\\xb33\\x8f \\x10\\x01\\xbfrp\\xc9\\xf2\\xd0)\\x9c@\\xcb\\x1f1\\xc4\\xbc\\x89d\\xbc\\xb2&\\xe5I\\xb7bn\\xd6\\xda\\xd7\\x18v+M$\\xc8\\xea\\xe7\\x98\\x1dX_o\\x15\\xadkz\\xf7\\xfb\\xe1\\xbcT\\xf2\\xca\\xb5\\x95\\xd1!)K \\x8aWaqvVe\\x17\\xf2\\xfdq\\x1a\\xb3\\x16.Ou\\xfb\\xfdf\\xdf\\xb5G\\xb4YeU\\x1e]\\xcf\\x8aX\\xef\\x02\\xab\\xc7\\x1d\\xfe\\xa9\\x8b\\x0b\\xd8w$k\\x1e\\xca1\\x1d\\xc54\\xd1R\\xe7\\xf9\\x8c\\xa3@\\x95\\xaa\\x0b\\xc6\\xb1\\xa6\\xa0\\x14\\xb5\\xc9>\\xa4\\xb7\\xdb\\x13yMe=,\\x10KT\\xd2\\x8ek\\xf8\\xcd\\x81$\\xde\\xdb~$}\\xce2z\\'\\xcd3\\xbc\\x8e9\\x94F\\xb3\\xca\\xb0\\xce\\x80\\r\\xc1\\xfek\\xdbk\\x8e\\xbe\\xd8\\xc5\\xc8\\xcb\\x96\\xcfD\\x1f\\xdf\\xe9\\xfa\\xc2\\x1f\\xcb!\\xb2\\xf5\\xd3-I(]%\\x98\\x12Kme\\x0c\\x9b\\x8f\\xc3\\x0f\\xf3\\xac\\xcal\\xc2j*Y\\xb4E\\x97\\xc5B\\xd0F\\x91\\xa0\\xfatX\\xea\\xf3o\\xa6\\xc7\\xa8\\xd20\\xe5k\\x92ye\\xa5U\\xd4\\xb1\\x16X\\x19~\\x98\\x99o\\xb0>gr{\\\\\\xe2:\\xa7(\\x99\\xe1\\xa8\\x96\\x1b\\x00P\\x90\\x87\\xf9\\xcd\\xeeE\\x87}\\x86\\xfeX\\xd0\\xd6\\xf6\\xda\\x83\\xb0(A\\x9c\\x9b$\\xf9\\x86\\xad-2\\xa9\\xa5O\\x1d\\xfb\\xa3\\x1d\\x04\\x8f\\xff\\x00+\\xfd\\xb0\\xecd\\xd0\\x95\"i\\x03\\xcaCE+\\x05\\'\\xe9;\\x11\\xe7\\xb0\\x1b\\xe3z7\\x96>d\\xd2\\xe9Q*\\x88\\xa6Y6\"\\xf7\\xdf\\xa5\\xfa\\xe2w+\\x15Y\\xb6oO\\x1a\\xc2\\'\\xa7Z\\x7f\\x96uY6\\x8c\\x82w\\x03\\xb6+\\xc9\\x99\\xc1&`\\x00\\xea\\x08\\xfe\\xe5\\x9a\\x1aI3JG\\xe6\\xd3GU\\xc9D\\xb7\\x8dv\\x04\\x96\\x1d\\x86\\xea/\\xd3|I\\xf0\\xf5\\x1cuY\\xeaS\\xd6\"\\xc3\\x15\\x1c\\xc9$\\xae\\xacYZ\\xce.\\x80\\xfa\\x9d\\x87\\x96\\xf85\\xcc\\xe0\\x05*(r\\xf0\\xf7\\xa9\\xac1\\xd3\\xc2\\xabmD\\x18\\xcc\\x92\\xdf\\xca\\xd1\\xdbsm\\xf1\\x17\\x9bPAGYS\\x0c\\x10|\\xa54\\xae\\x03\\x05V\\xd5\\xa9\\xb7g\\x0cz\\xfbz\\xe0S\\xc9l\\xa9\\xf3\\x19\\xc6\\xb6 \\x9d\\x14<\\xca\\xe8L\\x91rdh\\xaab\\xa8T\\xd8\\xeb\\x1a\\xbby\\xd9\\x94}\\xb0G\\xc2\\xd4\\x12\\xc9T\\xb2\\x8dGX\\x04\\xdbm\\x88\\xc3\\xfc\\xe6\\x91\\x8dDR-;\\x07\\x8ee\\x0c\\xd6\\x03T\\x86C\\xcd#\\xcc0\\xd0\\xdfs\\x87\\\\;\\x00\\x8f\\x94DrJ\\x15\\x17SX\\xa9\\x17\\x1e[\\xfe8\\xa13\\x06\\xdc\\xf5Q\\x967\\x0fT=3i\\x98\\x92\\xad\\xb1\\x1a\\xae\\xc0\\xefr=v\\xfc\\xc6->\\x12\\xcec\\x9e\\x0f\\xddP7\\xf1\\xab\\xea\\xcc!\\xbc\\xe9\\xc5\\xcc\\x8c\\x0f\\x9d\\xb5\\x0fB\\xc3\\x15r\\x04\\xa6\\xa3I\\xa1\\n\\'\\xb8\\tm\\xf9\\x8aT\\x82\\xb6=\\xfa~\\xb8\\xdf\\x85sa\\r@\\xcc#3\\x7f\\x01\\x98\\xa0V\\x01\\xe3\\xb9\\xe8\\xb7\\xf2\\xb0\\xbf~\\xb8\\xe6\\xb6p\\xb9\\x01\\x1f\\x94;\\x9dr*\\x96,\\xc3&*m\\xe2\\x9c\\x05\\x03kr\\x8e\\xdf\\x90\\xc1\\x15\\x15rM-\\xaf\\xa8\\x82CzX\\xf4\\xc76O\\xf1C1\\x91\\xb2\\xf7\\xa2+$\\xf1\\xbc\\x81\\x95\\xec\\x85\\xd4\\x8b\\x1d#}\\xed\\xb8\\xff\\x00l\\x1dp?\\xc4*L\\xcdgTiR\\xa1%b\\xd4\\xae\\xba]F\\xabj,vk\\x9f,t\\x93\\xc9Fj\\x10\\xc1\\x12\\xf6\\x12\\x84\\x88:\\xa8{\\x10\\r\\xcfA}\\xc9\\xf6\\xc3\\xe8SD\\x9a\\xcf~\\x98\\x0f\\xcb\\xb3\\xa9\\x0c\\xb1)h\\x90?\\xf2}LG\\xa9\\xe9\\xf9`\\x82*\\xd1\\x03\\xac-vR\\xa7\\x95\\xea\\x07\\xf2\\xfd\\xbfLUc\\xb8P\\x86>\\x86\\xc3\\x1a\\xb8\\x1a\\xbf\\x89\\xba\\xdb\\xc4Oa\\x889\\xf8\\x96\\x92\\x9e\\xa6\\x8a.z+\\xd5n\\xa3W\\xf4\\x82[\\xfbbN*\\x84\\xab\\xd8\\xdd\\x16\\xe2\\xcc\\xfb\\x02}\\xba\\xe3\\xdc\\x81\\x9a#,\\xf7\\x83r\\xbe&\\xcbj(\\xb3X\"\\xa9\\xa7\\x9e=/\\x1b\\x8b\\x82\\x0e8\\x83\\xe37\\xec\\x9f\\x9ep\\xedeFi\\xc1i&e\\x92\\xb5\\xdb\\x93\\xb3KLw\\xbe\\xddY}F\\xf8\\xefy\\x92\\x08\\x94G\\x0c\\x8c\\xee\\xb6\\x0c\\x06\\xc0a&\\xa7\\x90\\xad\\xc4\\x81n|\\xf1\\xa0\\x89\\xe2\\xb7>=O\\x94\\xbeYV\\xd4\\xf9\\x92<n\\xdb\\x90\\xc0\\xa9\\xf47\\xf7\\xc6G\\x93\\x9a\\x99\\xaf\\x1a\\x87\\x10\\xd9\\x8cw\\xbf0\\x7fqo\\xbd\\xb7\\xf5\\xc7\\xd5>/\\xf8A\\xc2\\xdc\\x7fL\\xf0\\xf1\\x16WOQ)\\xb9Y\\xd5\\x02J\\x84\\xf7\\x0e7\\xc7\\'|M\\xfd\\x92\\xb8\\x87 \\x96Z\\xae\\t\\x90f\\xd4h\\xda\\xa3\\x81\\x8e\\x99\\xd1o\\x7ff\\xb7\\xa6\\xfe\\x98\\xc3`X\\x8b\\xaa\\x9c\\xc3\\x98e4\\x92\\xd4\\x10?\\x86&Eho\\xb8+\\xa4m\\x7f1\\xd3\\xbfL4N\\x1d\\x8eH\\xc0\\x86+T!\\xb5\\x9b\\xc4\\xaeo\\xb5\\x81\\xd8{w\\xc5\\xae\\xfc>\\xe2x\\xa83\\xba)\\xa8f\\r\\xcb\\x8eJ\\x98\\xda\\x15\\x17\\xff\\x00\\xc4\\x8b\\x9d\\xc5\\xeda}\\xfc\\xf0\\x8dFG&Z\\xa1dJj\\x88\\xd8\\xe9\\x8eX,C\\\\\\x81p\\xd7\\xda\\xdeF\\xd6\\xbe!\\xf5\\xca\\xad\\x1d\\x1f\\x99\\xea\\x04J\\xb6\\xb3+\\x92\\x96\\xaeD\\xa7\\x04\\x12\\xd6X\\x94\\xd8\\xa8\\xf3?\\xed\\x875\\x94\\xb9\\x94y<L\"r\\xd0,l6#f\\xb8`<\\xect\\x1f\\xbe,\\x03\\x94\\x1a\\xcaj\\x91U\\x11J\\x9f\\xa6\\x06\\x89\\t\\xf1\\xdd@\\'\\xff\\x00\\xc8w\\xbf\\xe7\\x87U\\xf4s\\xe5\\x91\\xc1J\\x85j)\\xa1c\\xcdp>\\xa4\\x03@P|\\xef\\xac\\x93\\xdbl-\\xbc\\xa5\\x00L\\xe3*\\xcc\\xba\\xb2\\xa9$\\x0bS\\x1c\\xaaA\\xb5\\xc2\\x92\\x08\\xf4;\\x8c\\x17RfO\\x04\\xe8$\\xd8\\x9b\\xae\\x96\\x1aN\\xde\\x7f\\x8e%\\xa1\\xa0\\xa6\\x96\\xa5\\xe1\\xae\\xa3!T\\xe9IP\\x07\\x02K\\\\3w=\\xbc\\xbf,;\\x83\\x86\\xa9)\\xea\"Y#f2\\xdc-\\x97W,\\xde\\xfa\\xc9\\xbd\\xb7=\\xfc\\x87\\xae=\\x93\\xc8@9B\\x16\\x04 \\x875\\xa4\\xa7\\xa6\\xe5\\xa3Jd\\x88\\xf2\\xc8\\x0c.\\xcf\\xe4\\xa7\\xa5\\xbb~8%\\xc8\\xf3:\\xaa\\n\\xc7\\xab\\xaaTYnb\\x88 \\x0e\\x14\\x85\\x1b\\x01}=\\r\\xaen{\\x01\\x80\\xb4\\xcbi\\xc4\\\\\\xe4\\x9a\\xa4;\\xcaQ\\x02B|F\\xc4\\xea\\xdfb\\r\\x8f~\\xc7\\x0fM\\\\\\x94Q:\\xc4J\"]\\\\\\xf2\\x18\\xebcqm&\\xda[\\xa0\\xf2\"\\xd8\\xe7\\x9f \\x93f\\x18\\xe4va\\xedE|U3I,\\xb5\\xb3DdU\\xbb\\xd5\\x16A5\\xc5\\x81\\xd2\\xbe\\x05\\xdc\\x10.\\x7f=\\xf0\\xe4f\\x10\\xd0QO\\xf2q\\xd3\\x84\\x997+\\x1d\\xa4f\\x02\\xff\\x00U\\xfb\\xf4\\xb9\\xc5x\\x95\\x952\\xca\\xdf8\\x19(\\xe6\\x8d\\xa6\\x8d\\xe4&\\xe60l\\x06\\xdb\\x81\\xb6\\xc4\\xf7\\x1e\\x98G9\\xcef\\xac\\x8e\\t\\xa3\\x8cK\\x19\\xef\\x02\\x9b\\x91b\\r\\xce\\xdb\\xeco\\xd6\\xd81\\x94\\x83\\xf36\\xe3j\\xfc\\xa4\\xd6(\\x85mP\\xa6$*T\\xeeA[\\xef}\\xbb\\xf5\\xf4\\x1dq\\x17\\xff\\x00LP)\"ic\\x12\\x0f\\xa8\\x01\\xd0\\xfd\\xf1!\\x1de]$|\\xaaY\\x13\\x96\\xaa\\x80\\xbc\\x8ad*\\xa6\\xe4Z\\xdb\\x8e\\x80_\\xa67\\x93\\x84f\\xcd\\xc2W\\x9aU\\xad5+\\xaf]<\\x01\\xd4nE\\x8e\\xa3pv\\xe9\\xeb\\x87\\x0c\\xf7\\xbb\\xa9\\xe5R\\xdf\\xca.\\x0f\\x8c\\x972\\x9a\\xb2\\x95\\xe8\\xb2\\xb9\\xe9\\xe9j\\xd7B;&\\x95\\x04\\xdc\\x8d \\xfd#\\xb8\\xf4\\xc3\\x1c\\xff\\x00\\x87k\\xb2Z\\xb9\\xe2\\x91c\\x86y\\x90=D\\xe6\\xa1X\\xc9kl\\x00$\\x8b\\xdb\\x13O_*\\xe45\\x95H\\xb3\\xabEW$jy\\x8c\\xda\\xcd\\xc2\\xd8\\x03\\xe46\\xfba\\x87\\x11\\xd0\\xc9\\x0e_\\x1eaZ`\\x865)L^@C\\x994k{\\x0e\\xf6&\\xdf\\xf1\\x88p\\xb9g\\xa2~?3\\xfb38\\r\\xc1\\xf7\\xcb!\\xaa\\x8cI:J\\xf1\\x89/\\xceS\\xa6\\xcc\\x01\\xb1\\x17\\xd8\\x8b\\xedn\\xc3\\x13\\xff\\x00\\xbbY\\xf8j(!\\x8f\\x95\\x04\\xf2\\x99\\xe7\\x95;\\x9d\\xd5H\\xfb\\x1f\\xcf\\x11\\x99\\x06W[\\xc6\\x19\\xc4t\\xf4\\x11\\xcdX\\x8a|C\\xa0T\\x16\\xdf\\xfc\\xf3\\xc5\\xa2\\xfc9O\\x0eS5CW\\x83\\x98B\\xfc\\x99(\\xf4\\x0eS)\\xdb\\x97\\xb7\\x92\\x8b\\xdb\\xcc\\xe0\\xbc\\x97\\x18\\xf8\\x82z\\x9e\\x18\\xefbUU\\x195Q\\x84\\x05\\x85\\xe2\\x82\\x95\\x06\\xb9\\x18\\xd9#[\\x92/\\xdfQ6\\xc2\\xf9q\\x95\\xaaa\\xa9\\x13\\x18\\xf4M\\x1c\\x8e\\xf6\\xfa\\xc8&\\xf6\\xfb\\xdbl\\x16T\\xf0\\x96d\\xac(\\xab)\\xaa\\xa12\\xd9\\xc4h\\xba\\xcb\\xc7bn\\x14u*\\x0f\\xdb|e\\n>c\\x99Sd\\xf4\\xf4\\x86\\x08a\\x95c\\xa6s\\xa7S\\xdb\\xae\\xaf@I$\\x9e\\x98\\x1fW\\x90\\xdc\\x0fJ\\xb5\\x05\\xe9Zl\\xc6\\xbd\\xd9)#\\x89)\\xa3~PX\\xc0\\xe5)?Q=\\xc9$\\xdd\\x9a\\xe4\\xdf\\r\\xe0\\x87\\x91S(\\x10\\xf8\\x90\\x87.\\x14\\x97`E\\xc0\\x07\\xd0\\x9b\\xdb\\x16\\xa5\"\\xe5\\xf9D\\xf0Rd\\xd5IY\\x1d<\\x8c\\x95\\x95\\x93\\x05\\x0bQ\\'BUm\\xd0^\\xc2\\xfd\\xf7\\xc0\\x82\\xb3\\xc5<\\xb3PE\\x19X\\xcb\\\\\\xcb\\xe2\\xb8\\x1b[\\xef\\xd0\\xe3\\x17\\xc8L\\x8e\\xc0t!\\x14\\x1fy\\x102\\xe8\\xf3s\\xf2\\xd2S\\x19\\xea<\\t\\xadT\\x86!\\xc9\\xd3\\xee/\\x7fk\\xe0\\x998F\\x97)\\xcd\\xf9\\x949\\x8aA\\x1d\\x04#\\xc0\\x80\\xb7\\xcf\\xce\\xf7\\x0eT\\xf6\\x0bq\\xb9\\xdbo\\\\He\\x92\\xcbI\\x05Ffb\\x8d\\'\\xf0AL\\xcbo\\xe16\\xf7a\\xe7\\xa4\\x13a\\xe6p\\xc9\\xb2\\xcc\\xc1e\\x86\\x9f9\\x8eZH\\xea W\\x843i\\xb0\\x17\\xd1a\\xd6\\xd7\\xb5\\xee;\\xe0NR\\xc4\\x84:\\xeaz\\x94t$\\x1dH\\x92Yj\\xd1fzxR\\xf0\\xebAr\\xee\\x0e\\xa2=\\xaf\\xb7\\xe1\\x874t\\x19\\x95Ll\\x99\\xbdML\\xe5$U\\x10\\xe9\\xb9\\xde\\xdeb\\xc3\\xdf|=\\xa6\\xa5H\\xe6\\x8e\\x86\\xa2X\\xe9e\\x9aR<lK\\x17\\xb1\\xdc\\xff\\x00\\x9d\\xf13K[\\x15^L\\xb02\\xc8\\'\\x15\\xae\\xf2\\x046\\xba\\x04\\x03\\xa9\\xeeM\\xff\\x00\\x1cb\\xe4\\xf4\\x92\\x84\\xf2\\x89\\x116I\\xf3\\x95\\xf0RS\\x1f\\x9aH\\x14\\xc4\\xa1M\\x99\\xce\\xad\\xd4[\\xb9=-\\xbe\\xdeX\\xd2.\\x1e\\xcca\\x9c\\xb5]:\\xd3\"\\xbb\\xe9\\x8a`\\xc4\\xdc=\\x89:N\\xdd\\x08\\x1e\\xd8\\x9a\\xa6\\xae\\x9b\\x85i\\xdf1\\xa6\\xd0\\xf5r\\xa9\\xe5Kk\\xe8S\\xb1a\\xdfP\\xb5\\x81>\\xf8\\xca\\x9a\\xba8\\x1a\\x8d\\x08\\x9aYg\\xb2\\xcaRR\\xe1\\x87P\\x05\\xacO]\\xc9\\xb5\\xef\\x81L\\xcc\\x8d\\xf4\\x8b\\xfd\\xee\\x10@bU9v\\x8c\\x95\\xe4\\xaf\\xa6H`\\x8em:\\xd5\\x98i\\xf7\\xf27\\xf5\\xef\\x88zJ\\xcb\\xb3\\xd7\\t\\x08\\x12\\xbe\\xb0F\\xc1\\xd8\\xdc\\xf4\\xe9{_\\xf2\\xc1\\x1d\\x14\\x12OGV*\\n\\xd4PJ^&\\x8e\\xa4\\x9b\\xb8\\xbd\\xfbmq\\xb7N\\xe4\\xdf\\x1aU\\xe5y\\x8b\\xc0#\\xa1\\x8a(\\xa0\\x07\\xc0\\xcc\\xa14\\xb6\\xda\\xb4\\xae\\xc0\\xdf\\xc2<\\xec-\\xd0aM\\x98\\x13W\\x19\\xe9+\\x02DcS-^aON\\x12\\x15\\x0f,\\xc2DdR\\xda\\x00\\xb6\\x9d\\xff\\x00\\x0e\\xf8w\\x90Q\\xd7\\xe5\\\\C5\\\\\\xd5\\xd2S\\xd2\\xeb 3\\xdc)\\x17\\xd4,o\\xbb\\x12\\x06\\xde@\\xe22\\xacW\\xd3Gz\\xda\\xc7\\xe5\\xca\\xc8X\"\\xdfq\\xfd6\\xe9\\xe5\\x89.)\\x96*\\xe8\\xb2l\\x97)\\x81\\xa9\\xe8\\xf2\\xeaQ!\\x9d\\x81\\x95\\x9ew\\xb1y\\x00\\xe9\\xb5\\xd5A=-\\xb6\\x1b\\x85\\xdc7u\\x14\\xabwr\\xc9\\xca>3I\\x97TJ\\xf9\\x8f:\\xa2\\xc8\\xca\\x81 \\xe5\\xa9:\\x86\\xe1\\xafn\\x9d\\xb0|~.\\xd2\\xd4\\xa5;G$\\x81\\x82\\xb4\\xea\\xae45\\xc2\\xec\\x01;o\\xef\\x8em\\xcdi\\xa1\\xa1\\xa6AQU\\xa9%r\\xb6k\\x96\\xb0\\xb7@\\x00\\xb1&\\xe7\\xcb\\xae#\\rD\\xe9\\xa4\\xd9\\x8a\\xa5\\xca\\x85%\\x94\\xefu?\\xfd\\xdbv\\xc5\\x9f\\xc6\\xe5\"\\xa7\\x8e\\xbb\\x9d\\x17[\\xf1\\x16/\\xfa\\xb3\"\\xaa\\xa8u`\\x90V\\x0eZ\\xfd0j\\x8e\\xeb\\xb7\\x98\\xdf\\xd6\\xf8\\xbf\\xf8J\\xbe\\xa3;\\x82\\x1c\\xca\\xadZ(\\xd9A\\x82\\x9d\\x88\\xd4\\x80\\xff\\x00;\\xff\\x00\\xe6|\\xbf\\x94z\\xdf\\x1f=#\\xcf\\xdf(\\x9dsY\\x11g\\x8aY\\xd1Y\\x08\\xdd#\\x0e\\x0b\\x85\\xedk\\x001\\xde_\\x0bs\\xea\\\\\\xff\\x00\"\\x88\\xe5\\x0f\\x08\\xba\\x87\\x0b\\xa8\\\\\\x83\\xd3a\\x8b\\xbcl\\x85\\x89f\\xeab\\xee\\xe5\\xa5L\\x90N\\xad\\xcem*-\\x7f3\\x89*X2\\xf9\\x85\\x9eB[\\xa0\\xd4m\\x81g\\xa9\\x14\\xea\\x11\\xace-k_\\xa5\\xfb\\x93\\x86y\\xdbN2\\xd0a\\x98D\\xf1H\\x1a\\xfd\\x98\\x7f\\xc6.,F\\xc4hP\\xda\\x84\\x99\\x94q\\xd2\\xcbjY\\x0b\\x00=\\xf1\\x16\\xb9\\xacs/*\\xacX\\xb5\\xc2\\xbf\\xaf\\x91\\xc6RN\\x8f\\x04+\\xe2\\xecA;\\xdc{\\xe1\\xb5m,\\x0fO$g\\xc0\\xc4\\xeaRO|\\x10cV\\'\\xa8t`7\\xc4|\\x82\\x8b\\x89\\xb2\\xa9\\xe8sH\"\\x942\\x9eL\\x8e\\x80\\xb27m\\xf1\\xcby\\xd7\\x03\\xd3\\xc1\\xc3\\xf1V\\xbc\\xe4\\xcb\\x175+\\xf9\\x11\\xd8\\tP\\xf8v\\xee\\x08\\xd8\\xf7\\xb8\\xbe\\xf8\\xec<\\xcf\\x93W@5\\xba\\x8d@\\xa1\\xb9\\xdc8\\xed\\x8eN\\xf8\\x81\\xc4Pp\\xbf\\x12\\xe6t\\xf3,rd\\xf9\\xe4F\\n\\xc8\\x9b\\xaaL6\\xe6\\x0fPl}\\xb1\\xcf\\xf3\\x10:\\x86\\x1d\\xcdP\\x01\\xfa\\xa5\\x7f\\x96,\\x99Nc%U<\\xec\\xc6\\x91]\\xc1\\x17\\x05\\x94\\xa1\\xb1\\xbe\\xfbo\\xb1\\xf3\\\\C\\x9aJ\\xac\\xc6br\\xd9\\xa0x\\x15\\x1fQyt\\x1d+\\xa8\\x9d\\xbdO_S\\x84\\xd5\\xeb\\xb2\\xfa\\x8a\\xcc\\xa2y\\x02H\\xb3\\xaa\\xc6\\xfdn\\xa3~\\x9d\\xc1\\xb7A\\xe7\\x89\\xba\\x8c\\xc2\\x97.\\xae\\x95\\xb9\\x91\\x95\\x12\\x80\\xe9L\\x8a\\xacE\\xee\\x10\\\\x\\xaf\\xdf\\xd7\\xd3\\x1c\\xb0\\xa1\\x7f\\x7f\\xbf\\xbc\\xde\\n\\xc7z\\x11,\\xa7+\\xac\\xa6\\xca\\xe4\\xcck\\xe9\\xe1\\x14b\\xa3\\x92`Si^VR@\\x16\\xfe]\\xb7#a\\xbe<\\xd1#\\xca\\xe8\\xb0\\xba\\xb6\\xa2\\xae\\xb1\\x80\\x02\\xd8\\xdb\\xa9\\xb1\\xda\\xff\\x00I\\xdb\\xf5\\xc7\\x93f\\x9aVF\\xbbG\\x11\\x99\\xa5jve\\xb2=\\x80Qs\\xd0\\xdb\\xd7\\xae$\\xa9j\\xa0\\xfd\\xc5O&]A;\\xd4\\xd5M\\xcd\\xe7\\x84ff\\x00\\xfd7;X\\x11\\xf9\\xe2l\\x8cE\\xfc\\x9a\\x83@hHzJ~~L#\\x9c9Y\\xe6\\x1a\\x9bQB\\x80\\x13\\xd3}\\x8d\\xec|\\xb7\\xb7}\\xa4\\xe8\\xe4\\x11M$5u\\x13II\\xccx\\xdfC\\xdd`\\xd4H\\xb0>B\\xfe[o\\x8d\\xda\\x14\\xcc3\\t\\xdat\\x84D\\x08zzX\\xae\\xe1\\x1a\\xfb\\xea\\x00\\x10\\x06\\xfe\\xbe[[\\x134Y\\x14T\\x94\\xf4r.Q\\x16Y\\x0c\\x93\\xb1\\x99g`\\x8cA6-\\xb9=\\x89\\xdbq\\xe5l\\x11\\xca\\xa0\\x1d\\xc3\\xadh\\xc1*\\xb1=,\\xd2e\\xbf\\xbc$\\x85\\xe5\\x87\\xf8\\x8co\\xa68\\x82\\xb0\\n\\xbe\\x84\\x0b\\xed\\xdc\\xfacJ\\x1c\\xaaG\\x8e\\xa9\\xa7\\xfe-\\x18P \\x96\\x19\\x8b1]7\\x17?\\xae\\xd7;u\\xc1\\x06a,\\x10\\xe6?3\\n\\xa5jDXC}\\x81\\xb1\\xb8\\x03\\xa5\\xc0\\xb9\\xb5\\xf6\\xdf\\x03\\x89\\x98\\xfc\\xaf\\xce,\\xf1\\xbc\\xd0\\xb4\\xba\\x15\\x17\\xc2T\\x93\\xb1\\xdb\\xd6\\xddo\\x86.Nc\\xf3\\x8a\\'[\\x9b\\xe5\\x9c\\xd9jfeFD0^\\x05\\x96-%\\xc8\\xbe\\xa2\\x05\\xae\\r\\x83Xt8U\\xe5Wr\\xd4NL&\\xd6\\xb0+c\\xdc}C\\x0b\\xd0\\xe62Q\\xd8O\\x08\\x12EK)^q\\xb9\\x05\\x86\\x95\\x1d\\xc9;\\x9ck\\x04-\\x98+\\xcf\\x1c\\xa9\\x1a\\x16!V\\xfamoA\\x8d9\\x0fk0r\\xaaS\\x082\\xae\\x14\\xf9~\\x1cZ\\x9a\\xc1\\xce\\xa9\\x95\\xea*\\x163f.\\xeeOQ\\xd8n\\xa0{b~\\xab\\xe1\\x95$Y.UI\\xc5\\xe9\\x1dq\\x9e)*e*Ie\\x94\\xb6\\xa6\\xd3n\\xd6\\x168\\xcaw\\x9d\\xa0\\x8b0\\x92\\x05d\\x89\\xd9\\xc8\\xdf\\xa5\\xac\\x00\\x18S\\x893z\\xcc\\x9e\\x9a\\x92\\x9a\\xa2i\\x1e\\xa2\\n\"\\xc8\\xc2\\xfe\\x15m\\xc8\\'\\xa97=1\\xf2K\\xe4\\xe7\\xe4Xh\\xdf\\xeb\\xb9Zq\\x0bdF\\xf97\\x01\\xd3T\\xd1G\\xf2<HrL\\xa2(\\xc41\\xcd\\xa0\\xc4\\xc8\\xba\\xefbz\\x9dcW\\xe1|\\x14\\xe5\\xdc)\\xc2\\xb0\\xd2Q\\xd3\\xa7\\x12\\x0c\\xbe\\xa1%i!\\x8a\\x1ad\\x99e{\\xdf\\xc4O\\x8b\\xdc\\xdb\\xb6\\x00\\xf8n*\\xfc\\xda\\x9a\\x96\\xbf:J\\x89\\xb2\\xf5b\\xa5\\x95\\xac\\x0cJ:\\x91\\xfew\\xc5\\x97\\x91p\\xe7\\x08\\xe5\\x9f9\\x98\\xcd\\x9e\\xd4\\xfc\\xfb:\\xcb\\x10\\x8e51\\xdbI\\xb4g\\xbe\\x9b_alR\\xd9r6R\\x8cn\\xbf\\xaf\\xf9\\x84\\xa0}\\xa8A\\xac\\xc6\\x8d\\xce_\\xccg\\xa6\\x9fU+D\\xb5hY\\x8a\\x80H\\xb1\\x1dzx\\xad\\xdfl\\x0b%U\\x1egM\\xae\\x92\\x18\\xd34\\x99\\xb95&\\xca\\x85|6\\xe6(\\x1eb\\xd7\\xb6\\x0e\\xfeVl\\xb2\\x08\\xe9\\xf2\\x89 \\xcc\\x0c\\xb3\\xbb\\'\\x83O\\x84\\xa1:Y[\\xd6\\xd8\\x1a\\xcai*h\\x970\\xaa\\xcf\\xa8\\xe8\\xe9\\xaa$\\x8fDZ\\xa2\\x01\\x85\\xb7\\x00[\\xb612\\x9fI\\x8b\\x1f\\xca\\x0b_\\xbc\\x87\\xc9\\xb8\\x0e\\n\\xb6|\\xaf/i\\xa2\\xcc \\x98I$\\xf1*\\xbcQ\\x8e\\xda\\xb5\\x11\\xeep\\xd3\\x86\\xfe\\x19\\xe6\\\\G\\x1c\\xb3\\xd7fT\\xf0\\xc1\\xcch\\xd1\\x10jy,z\\xdc\\xd8(\\xbe\\xf7\\xdf\\x05\\x94T\\xdf\\xf4\\xcd\\x13\\xd7Uj\\xa9\\xac\\xaf\\x1a\\xda\\x02\\xc1mk\\x9d\\xc5\\xfb\\xe2\\x1b4\\x83\\x88j\\xb3(d\\xaeVJV\\x8d\\\\AL\\xde\\x10\\x8d\\xfc\\x87OO|7\\x17\\x92\\xf4x\\xef\\xeeO\\xf6\\x81\\xc5\\x00\\xd8\\x8f\\xf3\\xeaz\\x1f\\x87y\\x0cTYrR\\x8c\\xd9W\\x9d\\x05z\\xb8\\x95\\xa3\\xd2\\xd6,ulnO`1W\\ts|\\xe5\\x1a\\xab0\\x92z\\xea\\xca\\x93\\xcbi\\x9a\\xfb-\\xef{\\xf4\\x04\\xdcXy\\x03\\x83\\xaa\\xaa:\\t\\xf3I\\xa7\\xa8\\xa4\\x15%c\\n\\x82w\\x16\\x8c\\x82I\\xf0\\xfam\\xd7\\xae\\x13\\xaf\\xcdr\\xfc\\xc6i\":\\xd9\\x00\\x11\\x98^\\xe9\\xab\\xd6\\xcb\\xb7Q\\x8a\\xf1g*8\\xa8\\xb2vL\\x06R\\xda\\x11\\xaek\\x93A\\x98\\xd2\\xe5Y\\xf5\\\\@\\xd4\\xd2A\\x1d.e\\x1d:i\\x06T#L\\x9e\\xa4\\xa8\\x00\\x91\\xd4\\xe2C?\\x9d8~\\xa6\\xb6<\\x9e\\x02\\x91\\x899\\xcd\\xe1\\x00\\xbe\\xad\\xc0\\xbf`\\x01\\xdf\\xd7\\x0e\\xa9\\x84\\x9445\\x07\\x929\\xf5S\\xa0E\\x04\\x0b!\\xfaA\\xbe\"\\xf8\\xa1\\xd6\\x9e\\nx$\\x96&\\x92g\\x0c\\x0b\\x8b\\xa3G{\\x01|{\\x93;\\x8b:\\x9e(\\xc2\\xe0\\xbem%~cE\\x15+\\xeaUVj\\x82U\\x08\\x17n\\x96\\xf3\\xdb\\xb60<\\xa5a\\xa3\\xa4\\x9b\\x93\\xf3C\\\\\\xf2\\x15\\xb5\\x94\\x0b\\x0b~\\x1f\\x8e\\x17\\xaa\\xaa\\xcde\\x90S\\xc7\\xfcZ\\x9b\\x86T\\x0c\\x11,\\xbd:\\xf4\\x1d7\\xc4\\x8d\\x1e[\\x9aMGOUS\\x04\\x1c\\xc9\\xa4\\xdfD\\xc1\\x99T\\x03\\xd0w\\xdf\\x165(\\x17\\x04)\\xef\\xde\\rW\\xe6\\x95\\x14\\xcf\\x16]K%\\xa3\\xa5m\\x08\\x01\\xb0\\xb17-n\\xe4\\x9d\\xf0v\\x8d\\x1df]F\\xe2eVAuC-\\xca\\xdbf\\xbf\\xbfl0\\xcaxr\\x8eW\\xa9\\xac\\xcd\\xcdu%\\x0c\\xb7\\x8e\\x97\\x9a\\x14<\\x8d\\xdc\\xad\\x80\\xda\\xff\\x00\\xdf\\x1e\\xbb\\xf0\\xf5!z\\x1a,\\xaag\\xa3\\x82R\\xd3L%m\\xd8\\x0f\\xe6n\\xa4\\xe2\\x7f\"\\x99J\\xa8\\xdf\\xbcv\\xea\\xa4~cE\\x94\\r-U\\x99\\xce\\x8e\\xa3H\\x1aI\\xe6X\\xf8\\xb4\\x81\\xd0\\xfa\\xe2k \\xe1\\xa3\\x99e\\xf1I\\x96\\xd6\\xd4\\x08\\xa9\\xda\\xee$K\\x96C{\\x02o\\xd0y\\xe2\\x16z\\n\\xac\\xb9\\xd6\\x18\\xa9\\xe6\\xf9\\x1a\\xa4/\\x0b\\xdd|G\\xa9\\xdf\\xd8\\xe0\\xdf\\x80jb\\xf9\\n\\x9c\\xc2\\xb2\\xca\\x91\\xc6KC\\xd3\\x99\\xa8i\\xd1o \\r\\xed\\xe9\\x85e\\xcf\\xc3\\n\\xb4\\xc5U\\xee\\xa4\\x1f\\x18\\xe5t\\x9c\\xf4\\xca(\\xa6\\x8e:\\x99\\x08\\x9d\\x8bu\\xbf\\xf4\\x8fK\\\\m\\x81,\\xc71H\"\\xa6\\xc9\\xe8#jJD\\xd5\\x1a\\xe9\\xbb;\\x92n^\\xfeD\\xdf\\x16\\x15nA&WQ\\x9b\\xd5\\xa8J\\xbc\\xc2\\x9aSIB\\xd2(<\\xc5e\\xd4H\\xf2\\xb2\\xfex\\x12\\xcb^\\xba\\x08\\x1eG\\t*\\xc89P^+\\xb2j$i\\x1d\\xc9\\xbd\\xf6\\xc5\\x1e>R\\xe3\\x89\\xf6\\xfe\\xb0H<\\x8a\\xf5 \\xa8 \\xf9\\x97j\"\\xd1\\xec\\x06\\x80\\x100e\\xee-\\xd3\\xd7\\x167\\xc2\\x9e#\\xcc8\\x0b3\\xd5\\n\\xc9\\x1eW\\xa7\\x96\\xcc\\xc7A\\xbd\\xf6\\x1a{\\x0f+`r^\\x12\\x93\\x84\\xc6_QR\\xb1\\xde\\xad\\x1ajX\\xd9\\x89\\xb2\\x7fQ6\\x16\\x17\\xe81\\x1b\\x94Q\\xd4f)QQ\\x99\\xd4\\xcb\\n\\xc9P\\x0c\\xf2j\\'Ljo\\xb7\\x95\\xefk\\xe2\\xa5\\xcbM\\xdfP\\x02\\x154\\xdd\\xce\\xc1\\xca~/d\\x99\\xeef(\\xd2\\xae \\xa8\\xc0\\xcc\\x88\\xd7\\xfaw\\xd8\\xf9\\xe2~\\x1e/\\xa3\\xe2J\\xbf\\xddH\\xaf>\\xa5\\x90\\xabD6m\\xbc\\x04\\x1fR~\\xd8\\xe3\\xdc\\xb6\\x86\\x9a\\x8b3\\xe6e\\x90\\xc6\\xf9|\\xceD\\x0e\\xd7\\x07\\x98\\x05\\xac\\xe7\\xd7\\xf3\\xc4\\xbf\\x0c\\xf1\\xe5W\\x0c\\xe61V\\xd2\\xd57\\xefjJ\\x92\\x1d\\x1bx\\xe4\\x8c\\x80-oq\\x8a\\xcf\\x98n\\xa3P\\xf0?P\\x9d\\xde\\xf9;e9}4Q\\xf8\\x99!U`M\\xcd\\xed\\x8a\\xff\\x00\\x8cs\\x8c\\xc2\\x96\\r\\x10\\xe5\\xf5\\x15GX\\xb9\\x89o\\xa7}\\xef\\xe5\\x81~\\x19\\xf8\\xf2\\xbcg\\x9b\\xe5T\\xf9\\x9d3\\xe45\\xf3+\\xaa\\x15\\x97\\x99\\x1c\\x8e\\x16\\xe3b/\\xbd\\x8e\\xd80\\xe2\\xdf\\x8aynO\\xc3u\\xd4\\xf2\\x88\\xa3\\xcd\\n\\xda8\\xe37\\xe6X\\xdc\\xb0\\xef\\xb0\\x04\\xd8\\xe3\\xa7\\x8f*dBA\\xd4Yb\\r\\xca\\xd37\\xcf\\xf3J\\'\\xccD\\xd4\\x93K\\x19<\\xc5\\x84\\x1b8 u7\\xe8n1B\\xfc@\\xa8\\xa7\\xe2\\x8f\\xfb\\x89\\xa9\\xa4\\x8a\\xb1\\x01\\xe6@\\xfanv\\xebcq\\x8d\\xb3\\xef\\x8c\\xd9\\xa6g\\xc4Y\\xd6e\\x93\\xd5\\xa8\\xa1\\x81ZX\\xf5\\xdc4\\x82\\xf66\\xf5\\xc0\\x8d\\x7f\\xc4\\x1a~ \\x86\\x91\\xebr\\xfds9<\\xd9\\xa4\\xba\\xc8\\x8d\\xe6\\x18}V\\xee\\xa7\\x12\\xfa\\x80\\xa9\\x1d\\xd4\\xd2y\\x0b1\\xcf\\x0b\\xd4\\x988\\x96\\x1a\\x9a\\x8a\\x98\\xe6\\x11\\x12\\xa6\\x12\\x80s\\x1bM\\xcf\\xb9\\n;w\\xc4f\\\\\\xb1\\xe6u\\xf2C#<\\x00N\\xed\\t\\x9c\\x9bF\\xe4\\x1d\\x1b\\x1e\\xd7\\xeb\\xe5\\xb6\\x10\\xa1\\xceEEUDk\\x14P\\xa4 i\\xa9Hv%\\xba]{\\xe1\\xdc\\x0e\\xf4u@V\\xb5<\\x10:\\x8959&\\xcb\\xff\\x00\\x80\\xdf\\xd4m\\x8eaBI\\xa9\\x88Am\\xcc\\xcd \\x96j\\xb5\\xa5\\x96\\xa2\\x9d\\xa5\\x13\\xb1p\\x12\\xc5\\x8fN\\x80\\x7f\\x97\\xc1\\x1a\\xc7\\x1d6\\\\\\x99T\\xf9\\x8c\\xb5\\xdb,\\x9c\\xa8#\\xff\\x00\\xf8\\xcfc\\xe3\\xd7\\xd0\\x8e\\x80\\x81\\xe7\\x86\\xd5YsS\\xe6+\\x0eQ\\n\\xd6\\xe6p\\xa2\\x17\\xd7\\x19^ku\\x1b\\x9b\\xa966#\\xf1\\xc1?\\x06e0T\\n\\x91\\xc4\\xe6N\\x19p\\xd2I\\xa4F\\x0bH\\xd7\\xb0\\x1dl\\x06\\xff\\x00\\x96\\x11\\x93\\xa1\\xc8\\xfe\\xff\\x00\\xacj\\xe1\\x1c\\xbb\\x91$%\\x19\\xa4.\\xbf+EOR\\xab2BU^D\\xb5\\xff\\x00\\xd4\\xeb\\xe7\\xd3\\xfa\\xb0[G5.aFi\\x97\\x86\\xfeY\\x1a7X\\xeaj*%\\x95\\x8b\\x05\\xba\\x8b\\x92\\x06\\xe4\\x81\\xd3\\xbe\\'\\xd3$\\xcb\\xe3\\xa7\\x8e\\xb5o\\xfb\\xa0/\\xf0\\xd6\\xa2\\x90\\x0ecZ\\xc3HRv$_}\\xef\\xe9\\x89J\\\\\\x82l\\xc6\\x9e\\xa2\\xb2.I\\x9fN\\x95V\\x97J\\xe8\\x04\\x10-\\xd6\\xfd7\\xc7+/\\x90\\x00\\xa5\\xf6\\x8d\\xf4\\x98]@\\n\\xde\\x1a\\x15\\x14\\xf0\\xfc\\xda\\xab\\xd0K\\xac\\xcd\"\\xb7.D mqk8\\xb8\\xdb\\xa7\\xbe\\x01\\xf38+\\xe0ij\\xbeV\\xf9lL\\x08\\x9c\\x8f\\x15\\xc6\\xde!\\xd8z\\x8cZ&z\\xb3\\x99\\xe6\\x19^g\\x1b\\xd1\\xa1\\n\\xac\\xd2%\\x99\\x8d\\xce\\xe0\\x81\\xe1\\x17;a\\xbb\\xc3AMV\\xf43\\xd4\\x1c\\xd9\\xe2\\x1a\\xf9\\x11!E\\xe9\\xb5\\xdc\\xfd^V\\xc3\\xf0\\xe5\\xc9\\x7f_S=0E\\xddAh\\xb8z\\x9b>\\xca\\xceg\\\\e\\xaa\\x92(WH@\\x074\\xa9#N\\x9e\\xa7Q\\xb7\\xe1\\xeb\\x87\\x99_\\xc3,\\xf75\\xa7w\\xa2\\xcb\\x12H\\xa1\\x90\\xc2\\x08b\\xa2\\xeb\\xd4\\x01\\xe9{}\\xb0\\xe9*i^\\n\\x9aj\\xc8\\xe9\\x95\\x03\\xab\\xf2\\xefu\\x177 \\xda\\xdd\\xf0[?\\x16\\xe6\\x10\\xac\\x03*\\x8d\\xcd;D\\x18\\x05\\n\\x02\\x9d\\xf6\\xdc\\xe1\\xab\\x9d\\x81\\xe2?\\xea{\\x1a!\\x1b\\xee\\x0e\\xe4\\x14\\xd5S\\xe4yfb\\xa5\\xeb\"X\\xd7\\x9d\\x1a\\x7f\\xf5\\x1b\\xef\\xd0t\\xc3l\\xdf;\\x91$\\xac9\\xb1\\x89\\xea\\x95VU\\xa6\\x97\\xe9R{_\\xbd\\xfb\\x0cf3\\x1clJ\\r\\x8f\\xff\\x00G\\xfa\\xcdm)\\x8d\\xa9\\xf8\\x9d\\xf3\\xac\\x9ah#\\x0f\\x97\\xca\\xeab\\x86\\x9fO\\x86\\xe3\\xad\\x87\\x96\\x19\\xf0\\xde]\\x19\\xcd`\\xa5\\xabW\\x8c*\\xf3\\x15\\x96S\\xa9\\x9dlw\\x1e]q\\x98\\xcc\\x1b\\xd2\\x17U\\x15\\xdf\\xf7\\x8a\\xdd\\x03\\x08/U.cKY\\x98\\x951\\xbd[\\xdbI\\xd2S{/\\xe5\\x898>{4\\x15\\xf1;\\xc3\\x9aU\\xc4\\x07\\xcaC\\xb2\\x84\\xb5\\xedf=O\\xfbc1\\x98\\x93\\x11\\xe4\\x00??\\xd6\\x18\\xfa\\x98\\x03\\xfb\\xd4e?\\tep\\xe5c:\\xe2\\xcay\\rh*\\xb0\\xacs021\\xbe\\xcd\\xd8u\\xc2|Y\\x98IE\\x93%FY2\\xd0\\xc2\\x91\\x88\\xc0\\x84\\\\\\x07\\xb6\\xd7\\xf3\\x17\\xc6c1C\\xe4e|\\x7f&\\xbfX\\xc6\\x00)0Er\\x8c\\xd2\\xbe\\x01]<\\x90\\x9a\\x94p\\x12E7\\x135\\x81!\\x97\\xd7\\x0e\\x1eJd`j\\xb2\\xfa\\xac\\xb2U\\x97\\x99\\xce\\x86\\xfaK\\xeel\\xc2\\xd6\\x17\\xdf\\x19\\x8c\\xc7U\\\\\\x96\\xa8\\x9a\\xe0\\xda\\x87y8\\xa6\\x7f\\x96\\xa3\\xe2\\\\\\x83.\\xaa5\\xe8Y\\xab\\xa4\\xd4\\xe5GD\\xb0\\xe8\\x08\\x1dp5\\xfb\\xa2\\xaa\\xaf\\x8ceZ\\n\\x14\\xae\\xcb\\xa0p\\x89\\x0c\\xab\\xfc0\\x00\\xe9\\xbfc\\x8c\\xc6b\\x03\\x95\\xbd>^\\xf1\\x8d\\xf5\\xa0\\xbf\\xbc\\xdf\\x8a8eir\\xeel4\\x91G^\\xc5\\x91\\xa9\\xe1\\x92\\xeb\\x0cd\\x93e\\'\\xfb\\xe3\\xce\\x08\\xe1\\x063\\xc56_Vk)\\x97KJ\\x95\\x02\\xce\\x9e^\\xe2\\xf8\\xccf\\rs9\\xc0O\\xccMSI\\xee*\\xe0\\xe7\\xaa\\xa8\\x8f1\\xcf\\xb3*a\\r\\x10+\\x0ch\\xc4h\\r\\xd0_\\xb5\\x87\\xeb\\x80\\x0c\\xde\\x9a\\x07\\x87NF\\xf5\\x15\\xd0S\\xca9\\xb4\\xe8\\xe0\\x82\\xb6\\xdd\\xadaq\\xf9\\xe31\\x98\\xe9x\\xe3\\x92\\x9b\\x95\\x00\\x01&7\\xa8\\xae\\xa7L\\xba\\x19Z0\\x93R\\xd9dRHWQ\\xb0\\xb5\\xfd;bc \\xcb\\xa6\\x9e\\n\\xa8`\\xa6x\"\\x88\\xa5@\\x05\\xaf\\xcc,w\\x17\\xf3\\x03\\x19\\x8c\\xc4\\xbeQ\\xe3\\xe31\\x1e\\xdf\\xe4Il\\xb6\\x8c.\\xce\\xb2\\xaaZ:\\x99\\xab\\xd6\\t\\xe4ddUQ!\\xb1\\x99\\x88,\\xc4\\x1f\\xc3\\x0e \\xe1\\xea:\\xdc\\xdf\\x90%JZ\\xa7\\x906\\x91\\xe2\\xe5\\xd8\\x12X)\\xea\\xde\\xb8\\xccf%\\xc0K\\x1b&t\\xb0\\xe3V\\x00\\x9f\\xb7\\xf9\\x859\\xd7\\x07\\'\\x12eT\\x95\\xb9\\xf4\\xbc\\xf9\\x1a\\x15\\x82\\x99c\\x1a\\x0b\\xaa\\x02\\x06\\xdd\\xbab\\xb4\\xcd2\\x9a|\\xae\\x8di\\xe9j\\x04\\x1aX\\xadZ9\\xb6\\xbb\\x1d\\x94\\x9cf3\\x0c\\x19\\x1c\\xe4\"\\xfa0s\\x00^\\xe0\\xd5K\\xd2\\x8axh \\x92H\\x82K\\xf3\\x05\"\\x16\\x03\\xa0\\xb8\\xbf\\xa6\\x16\\x9a\\x9a\\x87,\\xcf3\\x18\\xb2\\xfa)\\xf3\\tV0\\xf1N^\\xc2\\xdd\\x80\\xf5\\xdf\\x19\\x8c\\xc7F\\xce\\x8f\\xc4\\x90(e\\xb8\\xc2z\\xf6\\x8a\\xa6)\\xe7\\xaazz\\xc1 \\x95\\x12\\x12n\\x8e\\r\\x85\\xbdq-\\x9df\\x99\\xdf\\x12F\\xe9WA2\\xb3\\r->\\x90\\x18\\x91\\xdc{\\xdf|f3\\x17\\xaf\\xff\\x001\\x04(1\\xaeu\\xc2\\xf9>W\\x16YI<o\\x15t\\x94\\xe5$1\\xa7\\x80\\x92?\\x9b\\xad\\xb0\\tS\\xc2\\x90\\xc34\\x10\\t$\\x89\\xde})\\xa0\\x12\\x06\\xb3\\xd4\\xdf\\x19\\x8c\\xc20;\\x10\\r\\xf6?\\xcc\\xdc\\xf8\\xd4\\x1dI\\xcc\\xf3\\xe4r|\\xce\\xa3-H\\xb4A\\x02\\x01\\xea\\xdd\\x01?\\xe7\\x9e%r\\x8c\\xa9i\\xe2\\xcb_3Y\\x1a\\x92P$\\x82mkk\\x1b\\x90\\x00#\\xa9\\xdblf3\\x0bge\\n~\\xff\\x00\\xe2!v\\xe6\\xe2\\xb4\\xf5kIURr\\xea\\x89)\\xea\\x83\\x82\\xce\\xf7%\\xaf\\xdc=\\xf0\\xbd\\x16q5^e\\x04\\xd9\\xbdG5#R\\x19\\x16;\\x89;\\r^g\\x19\\x8c\\xc6\\x1f\\xa8\\x1b\\x8e\\x0cH\\xa8Y\\x06qU\\x99\\xd4+H#\\x85\\x98\\x04(\\xab\\xa0\\x08\\xd4}Dy\\xec7\\xc3\\xf4\\xcfi)\\xaa\\xd1\\xaak\\'\\xaf\\x10\\xd9TFt\\x8b\\x0e\\x97\\xf48\\xccf$>>2.8\\xff\\x00%\\xc6<I\\xc4\\x9c\\xc7\\x9e\\xb2i$\\x15\\x15\\x0e\\xad2\\x85\\xf0\\xdf\\xf9m\\xdc\\x8c\\x0bRg\\xf4\\xf4\\xf5F\\x1a\\x98\\x16I\\x8b1:X\\x80M\\xae.|\\xf1\\x98\\xcc50%I\\xf2\\x1d\\xdckE\\x96V\\xe7Y\\x84\\xcfr\\xab>\\xeaY,\\xab\\xbe\\xc0\\xf9a\\xf5nZ\\xf1U\\xcc\\x82\\xad\\xa7\\xd2\\xd6&9\\xec\\x01\\xf2\\xc6c18j\\xceG\\xc4\\xf2cV\\x16g\\xff\\xd9')"
      ]
     },
     "execution_count": null,
     "metadata": {
      "image/jpeg": {
       "width": 200
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_fn = Path('samples/puppy.jpg')\n",
    "Image(filename=img_fn, width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb0ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"role\": \"user\",\n",
      " \"content\": [\n",
      "  {\n",
      "   \"type\": \"text\",\n",
      "   \"text\": \"hey what in this image?\"\n",
      "  },\n",
      "  {\n",
      "   \"type\": \"image_url\",\n",
      "   \"image_url\": \"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/4gxUSU...\n"
     ]
    }
   ],
   "source": [
    "msg = mk_msg(['hey what in this image?',img_fn.read_bytes()])\n",
    "print(json.dumps(msg,indent=1)[:200]+\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ebb192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This image features a close-up of a brown and white Cavalier King Charles Spaniel puppy lying in the grass next to a bush of purple flowers. The puppy has long, floppy ears and dark, soulful eyes, looking directly at the camera. The background is slightly blurred, focusing attention on the puppy's face and paws.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=67, prompt_tokens=1087, total_tokens=1154, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=67, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=7, image_tokens=1080), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"This image features a close-up of a brown and white Cavalier King Charles Spaniel puppy lying in the grass next to a bush of purple flowers. The puppy has long, floppy ears and dark, soulful eyes, looking directly at the camera. The background is slightly blurred, focusing attention on the puppy's face and paws.\", role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7jGQpNP1DRd1tav/grJb6ED4zU8Ew1m8r9+RM9jOVFSe4Xn7MHGnXlWP/dJo5']}))], usage=Usage(completion_tokens=67, prompt_tokens=1087, total_tokens=1154, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=67, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=7, image_tokens=1080), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f958cae",
   "metadata": {},
   "source": [
    "Let's also demonstrate this for PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160351e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the text in the document, the author is **Jeremy Howard**, a co-founder of **fast.ai**.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=25, prompt_tokens=541, total_tokens=566, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=25, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=9, image_tokens=532), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Based on the text in the document, the author is **Jeremy Howard**, a co-founder of **fast.ai**.', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7IUTOoe0uN4AAEf5p+wd535MPKZbLikXIal+d62oOUBCmIWWqp93YcZ0f++9z']}))], usage=Usage(completion_tokens=25, prompt_tokens=541, total_tokens=566, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=25, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=9, image_tokens=532), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_fn = Path('samples/solveit.pdf')\n",
    "msg = mk_msg(['Who is the author of this pdf?', pdf_fn.read_bytes()])\n",
    "c(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e5e1e2",
   "metadata": {},
   "source": [
    "Some models like Gemini support audio and video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38313733",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_data = httpx.get(\"https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav\").content\n",
    "# Audio(wav_data)  # uncomment to preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a81fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The audio says: \"The sun rises in the east and sets in the west. This simple fact has been observed by humans for thousands of years.\"\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=30, prompt_tokens=181, total_tokens=211, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=30, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=174, cached_tokens=None, text_tokens=7, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='The audio says: \"The sun rises in the east and sets in the west. This simple fact has been observed by humans for thousands of years.\"', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7YItSrO0hwN8rJa/pp4Qfg1duHZzlm9dyEKS9fs8C4MB2ZGoStyTZJUzWKLyu']}))], usage=Usage(completion_tokens=30, prompt_tokens=181, total_tokens=211, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=30, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=174, cached_tokens=None, text_tokens=7, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = mk_msg(['What is this audio saying?', wav_data])\n",
    "completion(ms[1], [msg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b32b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_data = httpx.get(\"https://storage.googleapis.com/github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e904bf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A photographer showcases the Google Pixel 8 Pro's new \"Video Boost\" feature by capturing nighttime scenes in Tokyo, including areas like Sancha and Shibuya. The video demonstrates the phone's ability to enhance low-light video quality using \"Night Sight,\" resulting in bright, clear, and detailed footage of the city's streets and alleys.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=70, prompt_tokens=5205, total_tokens=5275, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=70, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=12, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='A photographer showcases the Google Pixel 8 Pro\\'s new \"Video Boost\" feature by capturing nighttime scenes in Tokyo, including areas like Sancha and Shibuya. The video demonstrates the phone\\'s ability to enhance low-light video quality using \"Night Sight,\" resulting in bright, clear, and detailed footage of the city\\'s streets and alleys.', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7DSK2NehBOG01UfdyhDDzpgI79pv8+ZKMZWtT342XPVuXI1vZrAcqqPUHmFfG']}))], usage=Usage(completion_tokens=70, prompt_tokens=5205, total_tokens=5275, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=70, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=12, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = mk_msg(['Concisely, what is happening in this video?', vid_data])\n",
    "completion(ms[1], [msg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc01faf",
   "metadata": {},
   "source": [
    "### Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23176bd8",
   "metadata": {},
   "source": [
    "Some providers such as Anthropic require manually opting into caching. Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ad26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpr(i): return f'{i} '*1024 + 'This is a caching test. Report back only what number you see repeated above.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b7f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "disable_cachy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84103a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# msg = mk_msg(cpr(1), cache=True)\n",
    "# res = c(msg, ms[2])\n",
    "# res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e39380",
   "metadata": {},
   "source": [
    "Anthropic has a maximum of 4 cache checkpoints, so we remove previous ones as we go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220ab7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = c([remove_cache_ckpts(msg), mk_msg(res), mk_msg(cpr(2), cache=True)], ms[2])\n",
    "# res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaf17a3",
   "metadata": {},
   "source": [
    "We see that the first message was cached, and this extra message has been written to cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.usage.prompt_tokens_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f286d9dd",
   "metadata": {},
   "source": [
    "We can add a bunch of large messages in a loop to see how the number of cached tokens used grows.\n",
    "\n",
    "We do this for 25 times to ensure it still works for more than >20 content blocks, [which is a known anthropic issue](https://docs.claude.com/en/docs/build-with-claude/prompt-caching).\n",
    "\n",
    "The code below is commented by default, because it's slow. Please uncomment when working on caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf0f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h = []\n",
    "# msg = mk_msg(cpr(1), cache=True)\n",
    "\n",
    "# for o in range(2,25):\n",
    "#     h += [remove_cache_ckpts(msg), mk_msg(res)]\n",
    "#     msg = mk_msg(cpr(o), cache=True)\n",
    "#     res = c(h+[msg])\n",
    "#     detls = res.usage.prompt_tokens_details\n",
    "#     print(o, detls.cached_tokens, detls.cache_creation_tokens, end='; ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197632a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_cachy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e9f01",
   "metadata": {},
   "source": [
    "### Reconstructing formatted outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80633d31",
   "metadata": {},
   "source": [
    "Lisette can call multiple tools in a loop. Further down this notebook, we'll provide convenience functions for formatting such a sequence of toolcalls and responses into one formatted output string.\n",
    "\n",
    "For now, we'll show an example and show how to transform such a formatted output string back into a valid LiteLLM history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee01a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt_outp = '''\n",
    "I'll solve this step-by-step, using parallel calls where possible.\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01KjnQH2Nsz2viQ7XYpLW3Ta\",\n",
    "  \"call\": { \"function\": \"simple_add\", \"arguments\": { \"a\": 10, \"b\": 5 } },\n",
    "  \"result\": \"15\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01Koi2EZrGZsBbnQ13wuuvzY\",\n",
    "  \"call\": { \"function\": \"simple_add\", \"arguments\": { \"a\": 2, \"b\": 1 } },\n",
    "  \"result\": \"3\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Now I need to multiply 15 * 3 before I can do the final division:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_0141NRaWUjmGtwxZjWkyiq6C\",\n",
    "  \"call\": { \"function\": \"multiply\", \"arguments\": { \"a\": 15, \"b\": 3 } },\n",
    "  \"result\": \"45\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details class='token-usage-details'><summary>Cache hit: 81.8% | Tokens: total=23,276 input=23,158 (+18,910 cached, 0 new) output=118 (reasoning 23)</summary>\n",
    "\n",
    "`Usage(completion_tokens=118, prompt_tokens=23158, total_tokens=23276, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=23, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=18910, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=18910)`\n",
    "\n",
    "</details>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8886f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "tool_dtls_tag = \"<details class='tool-usage-details'>\"\n",
    "re_tools = re.compile(fr\"^({tool_dtls_tag}\\n*(?:<summary>.*?</summary>\\n*)?\\n*```json\\n+(.*?)\\n+```\\n+</details>)\",\n",
    "                      flags=re.DOTALL|re.MULTILINE)\n",
    "token_dtls_tag = \"<details class='token-usage-details'>\"\n",
    "re_token = re.compile(fr\"^{re.escape(token_dtls_tag)}<summary>.*?</summary>\\n*\\n*`Usage\\(.*?\\)`\\n*\\n*</details>\\n?\",\n",
    "                      flags=re.DOTALL|re.MULTILINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec2686",
   "metadata": {},
   "source": [
    "We can split into chunks of (text,toolstr,json):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a3f160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-  [\"\\nI'll solve this step-by-step, using parallel calls where possible.\\n\\n\", '<details class=\\'tool-usage-details\\'>\\n\\n```json\\n{\\n  \"id\": \"toolu_01KjnQH2Nsz2viQ7XYpLW3Ta\",\\n  \"call\": { \"function\": \"simple_add\", \"arguments\": { \"a\": 10, \"b\": 5 } },\\n  \"result\": \"15\"\\n}\\n```\\n\\n</details>', '{\\n  \"id\": \"toolu_01KjnQH2Nsz2viQ7XYpLW3Ta\",\\n  \"call\": { \"function\": \"simple_add\", \"arguments\": { \"a\": 10, \"b\": 5 } },\\n  \"result\": \"15\"\\n}']\n",
      "-  ['\\n\\n', '<details class=\\'tool-usage-details\\'>\\n\\n```json\\n{\\n  \"id\": \"toolu_01Koi2EZrGZsBbnQ13wuuvzY\",\\n  \"call\": { \"function\": \"simple_add\", \"arguments\": { \"a\": 2, \"b\": 1 } },\\n  \"result\": \"3\"\\n}\\n```\\n\\n</details>', '{\\n  \"id\": \"toolu_01Koi2EZrGZsBbnQ13wuuvzY\",\\n  \"call\": { \"function\": \"simple_add\", \"arguments\": { \"a\": 2, \"b\": 1 } },\\n  \"result\": \"3\"\\n}']\n",
      "-  ['\\n\\nNow I need to multiply 15 * 3 before I can do the final division:\\n\\n', '<details class=\\'tool-usage-details\\'>\\n\\n```json\\n{\\n  \"id\": \"toolu_0141NRaWUjmGtwxZjWkyiq6C\",\\n  \"call\": { \"function\": \"multiply\", \"arguments\": { \"a\": 15, \"b\": 3 } },\\n  \"result\": \"45\"\\n}\\n```\\n\\n</details>', '{\\n  \"id\": \"toolu_0141NRaWUjmGtwxZjWkyiq6C\",\\n  \"call\": { \"function\": \"multiply\", \"arguments\": { \"a\": 15, \"b\": 3 } },\\n  \"result\": \"45\"\\n}']\n",
      "-  [\"\\n\\n<details class='token-usage-details'><summary>Cache hit: 81.8% | Tokens: total=23,276 input=23,158 (+18,910 cached, 0 new) output=118 (reasoning 23)</summary>\\n\\n`Usage(completion_tokens=118, prompt_tokens=23158, total_tokens=23276, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=23, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=18910, text_tokens=None, image_tokens=None, cache_creation_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=18910)`\\n\\n</details>\\n\", None, None]\n"
     ]
    }
   ],
   "source": [
    "sp = re_tools.split(fmt_outp)\n",
    "for o in list(chunked(sp, 3, pad=True)): print('- ', o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303951a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _extract_tool(text:str)->tuple[dict,dict]:\n",
    "    \"Extract tool call and results from <details> block\"\n",
    "    try: d = json.loads(text.strip())\n",
    "    except: return\n",
    "    call = d['call']\n",
    "    func = call['function']\n",
    "    tc = ChatCompletionMessageToolCall(Function(dumps(call['arguments']),func), d['id'])\n",
    "    tr = {'role': 'tool','tool_call_id': d['id'],'name': func, 'content': d['result']}\n",
    "    return tc,tr\n",
    "\n",
    "def fmt2hist(outp:str)->list:\n",
    "    \"Transform a formatted output into a LiteLLM compatible history\"\n",
    "    lm,hist = Message(),[]\n",
    "    if token_dtls_tag in outp: outp = re_token.sub('', outp)\n",
    "    if tool_dtls_tag not in outp: return [outp]\n",
    "    spt = re_tools.split(outp.strip())\n",
    "    for is_last,(txt,_,tooljson) in loop_last(chunked(spt,3,pad=True)):\n",
    "        if is_last and not (txt or '').strip() and not tooljson: continue\n",
    "        txt = txt.strip() if tooljson or txt.strip() else '.'\n",
    "        hist.append(lm:=Message(txt))\n",
    "        if tooljson:\n",
    "            if tcr := _extract_tool(tooljson):\n",
    "                if not hist: hist.append(lm) # if LLM calls a tool without talking\n",
    "                lm.tool_calls = lm.tool_calls+[tcr[0]] if lm.tool_calls else [tcr[0]] \n",
    "                hist.append(tcr[1])\n",
    "    if hist and isinstance(hist[-1], dict): hist.append(Message('.'))\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad493d98",
   "metadata": {},
   "source": [
    "See how we can turn that one formatted output string back into a list of Messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac22b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b40b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Message(content=\"I'll solve this step-by-step, using parallel calls where possible.\", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 10, \"b\": 5}', name='simple_add'), id='toolu_01KjnQH2Nsz2viQ7XYpLW3Ta', type='function')], function_call=None, provider_specific_fields=None),\n",
      " {'content': '15',\n",
      "  'name': 'simple_add',\n",
      "  'role': 'tool',\n",
      "  'tool_call_id': 'toolu_01KjnQH2Nsz2viQ7XYpLW3Ta'},\n",
      " Message(content='', role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 2, \"b\": 1}', name='simple_add'), id='toolu_01Koi2EZrGZsBbnQ13wuuvzY', type='function')], function_call=None, provider_specific_fields=None),\n",
      " {'content': '3',\n",
      "  'name': 'simple_add',\n",
      "  'role': 'tool',\n",
      "  'tool_call_id': 'toolu_01Koi2EZrGZsBbnQ13wuuvzY'},\n",
      " Message(content='Now I need to multiply 15 * 3 before I can do the final division:', role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 15, \"b\": 3}', name='multiply'), id='toolu_0141NRaWUjmGtwxZjWkyiq6C', type='function')], function_call=None, provider_specific_fields=None),\n",
      " {'content': '45',\n",
      "  'name': 'multiply',\n",
      "  'role': 'tool',\n",
      "  'tool_call_id': 'toolu_0141NRaWUjmGtwxZjWkyiq6C'},\n",
      " Message(content='.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None)]\n"
     ]
    }
   ],
   "source": [
    "h = fmt2hist(fmt_outp)\n",
    "pprint(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5249772a",
   "metadata": {},
   "source": [
    "### `mk_msgs`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a375774e",
   "metadata": {},
   "source": [
    "We will skip tool use blocks and tool results during caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cb84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _apply_cache_idxs(msgs, cache_idxs=[-1], ttl=None):\n",
    "    'Add cache control to idxs after filtering tools'\n",
    "    ms = [o for o in msgs if o['role']!='tool']\n",
    "    for i in cache_idxs:\n",
    "        try: _add_cache_control(ms[i], ttl)\n",
    "        except IndexError: continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad6deec",
   "metadata": {},
   "source": [
    "Now lets make it easy to provide entire conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b326d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_msgs(\n",
    "    msgs,                   # List of messages (each: str, bytes, list, or dict w 'role' and 'content' fields)\n",
    "    cache=False,            # Enable Anthropic caching\n",
    "    cache_idxs=[-1],        # Cache breakpoint idxs\n",
    "    ttl=None,               # Cache TTL: '5m' (default) or '1h'\n",
    "):\n",
    "    \"Create a list of LiteLLM compatible messages.\"\n",
    "    if not msgs: return []\n",
    "    if not isinstance(msgs, list): msgs = [msgs]\n",
    "    res,role = [],'user'\n",
    "    msgs = L(msgs).map(fmt2hist).concat()\n",
    "    for m in msgs:\n",
    "        res.append(msg:=remove_cache_ckpts(mk_msg(m, role=role)))\n",
    "        role = 'assistant' if msg['role'] in ('user','function', 'tool') else 'user'\n",
    "    if cache: _apply_cache_idxs(res, cache_idxs, ttl)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4624e2",
   "metadata": {},
   "source": [
    "With `mk_msgs` you can easily provide a whole conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ecc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Hey!'},\n",
       " {'role': 'assistant', 'content': 'Hi there!'},\n",
       " {'role': 'user', 'content': 'How are you?'},\n",
       " {'role': 'assistant', 'content': \"I'm doing fine and you?\"}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = mk_msgs(['Hey!',\"Hi there!\",\"How are you?\",\"I'm doing fine and you?\"])\n",
    "msgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bf277c",
   "metadata": {},
   "source": [
    "By defualt the last message will be cached when `cache=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a34c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Hey!'},\n",
       " {'role': 'assistant', 'content': 'Hi there!'},\n",
       " {'role': 'user', 'content': 'How are you?'},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': \"I'm doing fine and you?\",\n",
       "    'cache_control': {'type': 'ephemeral'}}]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = mk_msgs(['Hey!',\"Hi there!\",\"How are you?\",\"I'm doing fine and you?\"], cache=True)\n",
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc360a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq('cache_control' in msgs[-1]['content'][0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ba87c3",
   "metadata": {},
   "source": [
    "Alternatively, users can provide custom `cache_idxs`. Tool call blocks and results are skipped during caching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289d855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'Hello!',\n",
       "    'cache_control': {'type': 'ephemeral'}}]},\n",
       " {'role': 'assistant', 'content': 'Hi! How can I help you?'},\n",
       " {'role': 'user', 'content': 'Call some functions!'},\n",
       " Message(content=\"I'll solve this step-by-step, using parallel calls where possible.\", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 10, \"b\": 5}', name='simple_add'), id='toolu_01KjnQH2Nsz2viQ7XYpLW3Ta', type='function')], function_call=None, provider_specific_fields=None),\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'toolu_01KjnQH2Nsz2viQ7XYpLW3Ta',\n",
       "  'name': 'simple_add',\n",
       "  'content': '15'},\n",
       " Message(content='', role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 2, \"b\": 1}', name='simple_add'), id='toolu_01Koi2EZrGZsBbnQ13wuuvzY', type='function')], function_call=None, provider_specific_fields=None),\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'toolu_01Koi2EZrGZsBbnQ13wuuvzY',\n",
       "  'name': 'simple_add',\n",
       "  'content': '3'},\n",
       " Message(content='Now I need to multiply 15 * 3 before I can do the final division:', role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 15, \"b\": 3}', name='multiply'), id='toolu_0141NRaWUjmGtwxZjWkyiq6C', type='function', cache_control={'type': 'ephemeral'})], function_call=None, provider_specific_fields=None),\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'toolu_0141NRaWUjmGtwxZjWkyiq6C',\n",
       "  'name': 'multiply',\n",
       "  'content': '45'},\n",
       " Message(content=[{'type': 'text', 'text': '.', 'cache_control': {'type': 'ephemeral'}}], role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = mk_msgs(['Hello!','Hi! How can I help you?','Call some functions!',fmt_outp], cache=True, cache_idxs=[0,-2,-1])\n",
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787a783d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'tool',\n",
       " 'tool_call_id': 'toolu_0141NRaWUjmGtwxZjWkyiq6C',\n",
       " 'name': 'multiply',\n",
       " 'content': '45'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bebd211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'Hello!',\n",
       "    'cache_control': {'type': 'ephemeral'}}]},\n",
       " {'role': 'assistant', 'content': 'Hi! How can I help you?'},\n",
       " {'role': 'user', 'content': 'Call some functions!'},\n",
       " Message(content=\"I'll solve this step-by-step, using parallel calls where possible.\", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 10, \"b\": 5}', name='simple_add'), id='toolu_01KjnQH2Nsz2viQ7XYpLW3Ta', type='function')], function_call=None, provider_specific_fields=None),\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'toolu_01KjnQH2Nsz2viQ7XYpLW3Ta',\n",
       "  'name': 'simple_add',\n",
       "  'content': '15'},\n",
       " Message(content='', role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 2, \"b\": 1}', name='simple_add'), id='toolu_01Koi2EZrGZsBbnQ13wuuvzY', type='function', cache_control={'type': 'ephemeral'})], function_call=None, provider_specific_fields=None),\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'toolu_01Koi2EZrGZsBbnQ13wuuvzY',\n",
       "  'name': 'simple_add',\n",
       "  'content': '3'},\n",
       " Message(content='Now I need to multiply 15 * 3 before I can do the final division:', role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 15, \"b\": 3}', name='multiply'), id='toolu_0141NRaWUjmGtwxZjWkyiq6C', type='function', cache_control={'type': 'ephemeral'})], function_call=None, provider_specific_fields=None),\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'toolu_0141NRaWUjmGtwxZjWkyiq6C',\n",
       "  'name': 'multiply',\n",
       "  'content': '45'},\n",
       " Message(content='.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = mk_msgs(['Hello!','Hi! How can I help you?','Call some functions!',fmt_outp], cache=True, cache_idxs=[0,-3,-2])\n",
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf73b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(content='Now I need to multiply 15 * 3 before I can do the final division:', role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 15, \"b\": 3}', name='multiply'), id='toolu_0141NRaWUjmGtwxZjWkyiq6C', type='function', cache_control={'type': 'ephemeral'})], function_call=None, provider_specific_fields=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fadef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(content='', role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 2, \"b\": 1}', name='simple_add'), id='toolu_01Koi2EZrGZsBbnQ13wuuvzY', type='function', cache_control={'type': 'ephemeral'})], function_call=None, provider_specific_fields=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq('cache_control' in msgs[0]['content'][0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ef1acb",
   "metadata": {},
   "source": [
    "Tool result blocks are skipped and cache control is placed into tool calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd5fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq('cache_control' in msgs[-5]['tool_calls'][0], True) \n",
    "test_eq('cache_control' in msgs[-3]['tool_calls'][0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939c493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "L(msgs).map(remove_cache_ckpts)\n",
    "test_eq(any(L(msgs).map(_has_cache)), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910677d4",
   "metadata": {},
   "source": [
    "Who's speaking at when is automatically inferred.\n",
    "Even when there are multiple tools being called in parallel (which LiteLLM supports!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8d1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Tell me the weather in Paris and Rome'},\n",
       " {'role': 'assistant', 'content': 'Assistant calls weather tool two times'},\n",
       " {'role': 'tool', 'content': 'Weather in Paris is ...'},\n",
       " {'role': 'tool', 'content': 'Weather in Rome is ...'},\n",
       " {'role': 'assistant', 'content': 'Assistant returns weather'},\n",
       " {'role': 'user', 'content': 'Thanks!'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = mk_msgs(['Tell me the weather in Paris and Rome',\n",
    "                'Assistant calls weather tool two times',\n",
    "                {'role':'tool','content':'Weather in Paris is ...'},\n",
    "                {'role':'tool','content':'Weather in Rome is ...'},\n",
    "                'Assistant returns weather',\n",
    "                'Thanks!'])\n",
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq([m['role'] for m in msgs],['user','assistant','tool','tool','assistant','user'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475862e9",
   "metadata": {},
   "source": [
    "For ease of use, if `msgs` is not already in a `list`, it will automatically be wrapped inside one. This way you can pass a single prompt into `mk_msgs` and get back a LiteLLM compatible msg history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e7663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Hey'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = mk_msgs(\"Hey\")\n",
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea8c2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'tool', 'content': 'fake tool result'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "msgs = mk_msgs({'role':'tool','content':'fake tool result'})\n",
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c828056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Hey!'},\n",
       " {'role': 'assistant', 'content': 'Hi there!'},\n",
       " {'role': 'user', 'content': 'How are you?'},\n",
       " {'role': 'assistant', 'content': \"I'm fine, you?\"}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = mk_msgs(['Hey!',\"Hi there!\",\"How are you?\",\"I'm fine, you?\"])\n",
    "msgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284fbfc3",
   "metadata": {},
   "source": [
    "However, beware that if you use `mk_msgs` for a single message, consisting of multiple parts.\n",
    "Then you should be explicit, and make sure to wrap those multiple messages in two lists:\n",
    "\n",
    "1. One list to show that they belong together in one message (the inner list).\n",
    "2. Another, because mk_msgs expects a list of multiple messages (the outer list).\n",
    "\n",
    "This is common when working with images for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d315d964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " {\n",
      "  \"role\": \"user\",\n",
      "  \"content\": [\n",
      "   {\n",
      "    \"type\": \"text\",\n",
      "    \"text\": \"Whats in this img?\"\n",
      "   },\n",
      "   {\n",
      "    \"type\": \"image_url\",\n",
      "    \"image_url\": \"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD...\n"
     ]
    }
   ],
   "source": [
    "msgs = mk_msgs([['Whats in this img?',img_fn.read_bytes()]])\n",
    "print(json.dumps(msgs,indent=1)[:200]+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad470e4",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec3dc5d",
   "metadata": {},
   "source": [
    "LiteLLM supports streaming responses. That's really useful if you want to show intermediate results, instead of having to wait until the whole response is finished.\n",
    "\n",
    "We create this helper function that returns the entire response at the end of the stream. This is useful when you want to store the whole response somewhere after having displayed the intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad6fc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def stream_with_complete(gen, postproc=noop):\n",
    "    \"Extend streaming response chunks with the complete response\"\n",
    "    chunks = []\n",
    "    for chunk in gen:\n",
    "        chunks.append(chunk)\n",
    "        yield chunk\n",
    "    postproc(chunks)\n",
    "    return stream_chunk_builder(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f16571",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = c(mk_msgs(\"Hey!\"), stream=True)\n",
    "r2 = SaveReturn(stream_with_complete(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797136b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! How can I help you today?"
     ]
    }
   ],
   "source": [
    "for o in r2:\n",
    "    cts = o.choices[0].delta.content\n",
    "    if cts: print(cts, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897ec073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello there! How can I help you today?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=10, prompt_tokens=3, total_tokens=13, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Hello there! How can I help you today?', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7NzEFwGj6/jmcCv+puObXaXf3bBqeb4SwMM995gjvbSNOW/GbajtO6L+hYLsN']}))], usage=Usage(completion_tokens=10, prompt_tokens=3, total_tokens=13, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e11c0",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4301402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lite_mk_func(f):\n",
    "    if isinstance(f, dict): return f\n",
    "    return {'type':'function', 'function':get_schema(f, pname='parameters')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b103600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_add(\n",
    "    a: int,   # first operand\n",
    "    b: int=0  # second operand\n",
    ") -> int:\n",
    "    \"Add two numbers together\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100fc27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'simple_add',\n",
       "  'description': 'Add two numbers together\\n\\nReturns:\\n- type: integer',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'a': {'type': 'integer', 'description': 'first operand'},\n",
       "    'b': {'type': 'integer', 'description': 'second operand', 'default': 0}},\n",
       "   'required': ['a']}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toolsc = lite_mk_func(simple_add)\n",
    "toolsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2af29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmsg = mk_msg(\"What is 5478954793+547982745? How about 5479749754+9875438979? Always use tools for calculations, and describe what you'll do before using a tool. Where multiple tool calls are required, do them in a single response where possible. \")\n",
    "r = c(tmsg, tools=[toolsc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb1817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I will calculate the sum of 5478954793 and 547982745, followed by the sum of 5479749754 and 9875438979, using the addition tool for both operations.\n",
       "\n",
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"b\": 547982745, \"a\": 5478954793})\n",
       "\n",
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"b\": 9875438979, \"a\": 5479749754})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=138, prompt_tokens=160, total_tokens=298, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=138, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=160, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content='I will calculate the sum of 5478954793 and 547982745, followed by the sum of 5479749754 and 9875438979, using the addition tool for both operations.\\n\\n', role='assistant', tool_calls=[ChatCompletionMessageToolCall(index=0, provider_specific_fields={'thought_signature': 'EjQKMgG+Pvb79iYGwnLRoG8ROXZW8VRk9WJjfinj+Oq640juoZSixN9JJTOpyEW9lzTMSIFa'}, function=Function(arguments='{\"b\": 547982745, \"a\": 5478954793}', name='simple_add'), id='call_438709f4b4f943e097417df9e25f__thought__EjQKMgG+Pvb79iYGwnLRoG8ROXZW8VRk9WJjfinj+Oq640juoZSixN9JJTOpyEW9lzTMSIFa', type='function'), ChatCompletionMessageToolCall(index=1, function=Function(arguments='{\"b\": 9875438979, \"a\": 5479749754}', name='simple_add'), id='call_f9d65e4e7ce743a0acd7f6022d1d', type='function')], function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb79iYGwnLRoG8ROXZW8VRk9WJjfinj+Oq640juoZSixN9JJTOpyEW9lzTMSIFa']}))], usage=Usage(completion_tokens=138, prompt_tokens=160, total_tokens=298, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=138, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=160, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c274a8",
   "metadata": {},
   "source": [
    "A tool response can be a string or a list of tool blocks (e.g., an image url block). To allow users to specify if a response should not be immediately stringified, we provide the ToolResponse datatype users can wrap their return statement in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac2035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class ToolResponse:\n",
    "    content: list[str,str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fa7798",
   "metadata": {},
   "source": [
    "When `tc_refs=True`, tool results are wrapped with their `tool_call_id` so the AI can track which result corresponds to which call and reference them in subsequent tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _prep_tool_res(res, tcid):\n",
    "    \"Prepend tool call ID text block to result\"\n",
    "    id_block = {'type': 'text', 'text': f'[tool_call_id: {tcid}]'}\n",
    "    if isinstance(res, list): return [id_block, *res]\n",
    "    return [id_block, {'type': 'text', 'text': str(res)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d7d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test _prep_tool_res - string result\n",
    "test_eq(_prep_tool_res('hello', 'toolu_123'), [\n",
    "    {'type': 'text', 'text': '[tool_call_id: toolu_123]'},\n",
    "    {'type': 'text', 'text': 'hello'}\n",
    "])\n",
    "\n",
    "# Test _prep_tool_res - list result (e.g. ToolResponse content)\n",
    "img_block = {'type': 'image_url', 'image_url': {'url': 'data:...'}}\n",
    "test_eq(_prep_tool_res([img_block], 'toolu_456'), [\n",
    "    {'type': 'text', 'text': '[tool_call_id: toolu_456]'},\n",
    "    img_block\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac31511",
   "metadata": {},
   "source": [
    "During a tool loop, the AI may want to reference the result of a previous tool call. We support syntax `` $`tool_call_id` `` in tool arguments which gets resolved to the actual result value before calling the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda90f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "_re_tool_ref = re.compile(r'^\\$`([^`]+)`$')\n",
    "\n",
    "def _resolve_tool_refs(args_str, tc_res):\n",
    "    \"Resolve $`tool_call_id` references in tool arguments\"\n",
    "    d = json.loads(args_str)\n",
    "    if tc_res is None: return d\n",
    "    for k,v in d.items():\n",
    "        if isinstance(v, str) and (m := _re_tool_ref.match(v)):\n",
    "            tcid = m.group(1)\n",
    "            d[k] = tc_res[tcid] if tcid in tc_res else f\"Tool result '{tcid}' not found!\"\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037bfea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test _resolve_tool_refs\n",
    "tc_res = {'toolu_abc123': 'hello world', 'toolu_xyz789': 42}\n",
    "\n",
    "# Basic substitution\n",
    "test_eq(_resolve_tool_refs('{\"content\": \"$`toolu_abc123`\"}', tc_res), {\"content\": \"hello world\"})\n",
    "\n",
    "# Multiple refs\n",
    "test_eq(_resolve_tool_refs('{\"a\": \"$`toolu_abc123`\", \"b\": \"$`toolu_xyz789`\"}', tc_res), {\"a\": \"hello world\", \"b\": 42})\n",
    "\n",
    "# No refs - passthrough\n",
    "test_eq(_resolve_tool_refs('{\"x\": 1}', tc_res), {\"x\": 1})\n",
    "\n",
    "# Empty tc_res\n",
    "test_eq(_resolve_tool_refs('{\"x\": 1}', None), {\"x\": 1})\n",
    "\n",
    "# Missing ref - error message\n",
    "test_eq(_resolve_tool_refs('{\"x\": \"$`toolu_missing`\"}', tc_res), {\"x\": \"Tool result 'toolu_missing' not found!\"})\n",
    "\n",
    "# tc_refs=False - syntax passes through unchanged since tc_res is None\n",
    "test_eq(_resolve_tool_refs('{\"x\": \"$`toolu_abc123`\"}', None), {\"x\": \"$`toolu_abc123`\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1381bc",
   "metadata": {},
   "source": [
    "When `tc_refs=True`, tool results are stored in `tc_res` for later substitution via `` $`tool_call_id` `` syntax. Some callers might return string reprs of Python objects. `_try_eval` attempts to convert these back to Python objects using `ast.literal_eval`, falling back to the original value on failure. This ensures substituted values are actual objects, not string reprs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f1e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _try_eval(o):\n",
    "    if isinstance(o, str):\n",
    "        try: return ast.literal_eval(o)\n",
    "        except: return o\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a7935",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(ast.literal_eval(\"'hello'\"), 'hello')\n",
    "test_eq(_try_eval(\"{'a': 1, 'b': 2}\"), {'a': 1, 'b': 2})\n",
    "test_eq(_try_eval(\"[1, 2, 3]\"), [1, 2, 3])\n",
    "test_eq(_try_eval(\"<MyClass object at 0x123>\"), \"<MyClass object at 0x123>\")\n",
    "test_eq(_try_eval(42), 42)\n",
    "cts = [{'type': 'image', 'url': 'http://example.com/img.png'}]\n",
    "test_eq(_try_eval(ToolResponse(cts)), ToolResponse(cts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238576e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _mk_tool_result(tc, res, tc_res=None, tc_res_eval=False):\n",
    "    \"Unwrap `ToolResponse`, store result if needed, and format tool result message\"\n",
    "    is_tr = isinstance(res, ToolResponse)\n",
    "    res = res.content if is_tr else res\n",
    "    if tc_res is not None: tc_res[tc.id] = _try_eval(res) if tc_res_eval else res\n",
    "    content = _prep_tool_res(res, tc.id) if tc_res is not None else (res if is_tr else str(res))\n",
    "    return {\"tool_call_id\": tc.id, \"role\": \"tool\", \"name\": tc.function.name, \"content\": content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aab6b00",
   "metadata": {},
   "source": [
    "Ensure `ToolResponse` content (e.g. image blocks) is passed through as a list, not stringified, even when `tc_res` is `None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d54cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tc = ChatCompletionMessageToolCall(index=0, function=Function(name='test_img'), id='_test', type='function')\n",
    "img_content = [{'type': 'image_url', 'image_url': 'data:image/png;base64,abc'}]\n",
    "res = _mk_tool_result(fake_tc, ToolResponse(img_content))\n",
    "test_eq(res['content'], img_content)  # ToolResponse should pass through\n",
    "\n",
    "res_str = _mk_tool_result(fake_tc, ['hello'])\n",
    "test_eq(res_str['content'], \"['hello']\")  # other tools results are stringified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468a19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _call_func(tc, tool_schemas, ns, callf, tc_res=None):\n",
    "    \"Call tool function synchronously and return formatted result\"\n",
    "    fn, valid = tc.function.name, {nested_idx(o,'function','name') for o in tool_schemas or []}\n",
    "    if fn not in valid: return f\"Tool not defined in tool_schemas: {fn}\"\n",
    "    else:\n",
    "        try: fargs = _resolve_tool_refs(tc.function.arguments, tc_res)\n",
    "        except json.JSONDecodeError: return f\"Failed to parse function arguments: {tc.function.arguments}\"\n",
    "        else: return callf(fn, fargs, ns=ns, raise_on_err=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b5fcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _lite_call_func(tc, tool_schemas, ns, tc_res=None, tc_res_eval=False):\n",
    "    \"Call tool function synchronously and return formatted result\"\n",
    "    res = _call_func(tc, tool_schemas, ns, call_func, tc_res=tc_res)\n",
    "    return _mk_tool_result(tc, res, tc_res, tc_res_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af607c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tool_call_id': 'call_438709f4b4f943e097417df9e25f__thought__EjQKMgG+Pvb79iYGwnLRoG8ROXZW8VRk9WJjfinj+Oq640juoZSixN9JJTOpyEW9lzTMSIFa',\n",
       "  'role': 'tool',\n",
       "  'name': 'simple_add',\n",
       "  'content': '6026937538'},\n",
       " {'tool_call_id': 'call_f9d65e4e7ce743a0acd7f6022d1d',\n",
       "  'role': 'tool',\n",
       "  'name': 'simple_add',\n",
       "  'content': '15355188733'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcs = [_lite_call_func(o, [toolsc], ns=globals()) for o in r.choices[0].message.tool_calls]\n",
    "tcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6327211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageToolCall(index=0, provider_specific_fields={'thought_signature': 'EjQKMgG+Pvb79iYGwnLRoG8ROXZW8VRk9WJjfinj+Oq640juoZSixN9JJTOpyEW9lzTMSIFa'}, function=Function(arguments='{\"b\": 547982745, \"a\": 5478954793}', name='simple_add'), id='call_438709f4b4f943e097417df9e25f__thought__EjQKMgG+Pvb79iYGwnLRoG8ROXZW8VRk9WJjfinj+Oq640juoZSixN9JJTOpyEW9lzTMSIFa', type='function'),\n",
       " ChatCompletionMessageToolCall(index=1, function=Function(arguments='{\"b\": 9875438979, \"a\": 5479749754}', name='simple_add'), id='call_f9d65e4e7ce743a0acd7f6022d1d', type='function')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.choices[0].message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0081078",
   "metadata": {},
   "source": [
    "Test tool calls that were not in tool_schemas are caught:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90ccb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tc = ChatCompletionMessageToolCall(index=0, function=Function(name='hallucinated_tool'),id='_', type='function')\n",
    "test_eq(_lite_call_func(fake_tc, ns=globals(), tool_schemas=[toolsc])['content'],\"Tool not defined in tool_schemas: hallucinated_tool\")\n",
    "test_fail(_lite_call_func(fake_tc, ns=globals(), tool_schemas=None)['content'],\"Tool not defined in tool_schemas: hallucinated_tool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d384d",
   "metadata": {},
   "source": [
    "Test tool calls that were not in tool_choice are caught:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd9871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_text(msg):\n",
    "    \"Extract printable content from streaming delta, return None if nothing to print\"\n",
    "    c = msg.choices[0]\n",
    "    if not c: return c\n",
    "    if not hasattr(c,'delta'): return None #f'{c}'\n",
    "    delta = c.delta\n",
    "    if delta.content: return delta.content\n",
    "    if delta.tool_calls:\n",
    "        res = ''.join(f\"ðŸ”§ {tc.function.name}\" for tc in delta.tool_calls if tc.id and tc.function.name)\n",
    "        if res: return f'\\n{res}\\n'\n",
    "    if hasattr(delta,'reasoning_content'): return 'ðŸ§ ' if delta.reasoning_content else '\\n\\n'\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4790a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will use the `simple_add` tool to calculate the sum of 5478954793 and 547982745, and then another instance of the tool to calculate the sum of 5479749754 and 9875438979.\n",
      "\n",
      "\n",
      "ðŸ”§ simple_add\n",
      "\n",
      "ðŸ”§ simple_add\n"
     ]
    }
   ],
   "source": [
    "r = c(tmsg, stream=True, tools=[toolsc])\n",
    "r2 = SaveReturn(stream_with_complete(r))\n",
    "for o in r2: print(delta_text(o) or '', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b21118c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I will use the `simple_add` tool to calculate the sum of 5478954793 and 547982745, and then another instance of the tool to calculate the sum of 5479749754 and 9875438979.\n",
       "\n",
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"a\": 5478954793, \"b\": 547982745})\n",
       "\n",
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"a\": 5479749754, \"b\": 9875438979})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=146, prompt_tokens=160, total_tokens=306, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='I will use the `simple_add` tool to calculate the sum of 5478954793 and 547982745, and then another instance of the tool to calculate the sum of 5479749754 and 9875438979.\\n\\n', role='assistant', tool_calls=[ChatCompletionMessageToolCall(provider_specific_fields={'thought_signature': 'EjQKMgG+Pvb7lQx16vXIy/6gHonzmLKWY22jJ2rZdF47/8ZNvYPbypzcgZLE3tn80pIWXWrS'}, function=Function(arguments='{\"a\": 5478954793, \"b\": 547982745}', name='simple_add'), id='call_b37a8985497d463ca8a212e0b988__thought__EjQKMgG+Pvb7lQx16vXIy/6gHonzmLKWY22jJ2rZdF47/8ZNvYPbypzcgZLE3tn80pIWXWrS', type='function'), ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 5479749754, \"b\": 9875438979}', name='simple_add'), id='call_b0fe7de94b4f45b590a12da0ec77', type='function')], function_call=None, provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7lQx16vXIy/6gHonzmLKWY22jJ2rZdF47/8ZNvYPbypzcgZLE3tn80pIWXWrS']}))], usage=Usage(completion_tokens=146, prompt_tokens=160, total_tokens=306, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bca992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ To find the derivative of the function **$f(x) = x^3 + 2x^2 - 5x + 1$**, we use the **Power Rule**.\n",
      "\n",
      "The Power Rule states that if $f(x) = ax^n$, then the derivative is $f'(x) = n \\cdot ax^{n-1}$.\n",
      "\n",
      "Here is the step-by-step breakdown:\n",
      "\n",
      "1.  **Derivative of $x^3$:**\n",
      "    Multiply by the exponent (3) and subtract 1 from the exponent:\n",
      "    $\\frac{d}{dx}(x^3) = 3x^2$\n",
      "\n",
      "2.  **Derivative of $2x^2$:**\n",
      "    Multiply the exponent (2) by the coefficient (2) and subtract 1 from the exponent:\n",
      "    $\\frac{d}{dx}(2x^2) = 2 \\cdot 2x^1 = 4x$\n",
      "\n",
      "3.  **Derivative of $-5x$:**\n",
      "    Since $x$ is $x^1$, the derivative is simply the coefficient:\n",
      "    $\\frac{d}{dx}(-5x) = -5$\n",
      "\n",
      "4.  **Derivative of $1$:**\n",
      "    The derivative of any constant is 0:\n",
      "    $\\frac{d}{dx}(1) = 0$\n",
      "\n",
      "**Final Answer:**\n",
      "Combining these results, the derivative is:\n",
      "**$f'(x) = 3x^2 + 4x - 5$**"
     ]
    }
   ],
   "source": [
    "msg = mk_msg(\"Solve this complex math problem: What is the derivative of x^3 + 2x^2 - 5x + 1?\")\n",
    "r = c(msg, stream=True, reasoning_effort=\"low\")\n",
    "r2 = SaveReturn(stream_with_complete(r))\n",
    "for o in r2: print(delta_text(o) or '', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff5f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To find the derivative of the function **$f(x) = x^3 + 2x^2 - 5x + 1$**, we use the **Power Rule**.\n",
       "\n",
       "The Power Rule states that if $f(x) = ax^n$, then the derivative is $f'(x) = n \\cdot ax^{n-1}$.\n",
       "\n",
       "Here is the step-by-step breakdown:\n",
       "\n",
       "1.  **Derivative of $x^3$:**\n",
       "    Multiply by the exponent (3) and subtract 1 from the exponent:\n",
       "    $\\frac{d}{dx}(x^3) = 3x^2$\n",
       "\n",
       "2.  **Derivative of $2x^2$:**\n",
       "    Multiply the exponent (2) by the coefficient (2) and subtract 1 from the exponent:\n",
       "    $\\frac{d}{dx}(2x^2) = 2 \\cdot 2x^1 = 4x$\n",
       "\n",
       "3.  **Derivative of $-5x$:**\n",
       "    Since $x$ is $x^1$, the derivative is simply the coefficient:\n",
       "    $\\frac{d}{dx}(-5x) = -5$\n",
       "\n",
       "4.  **Derivative of $1$:**\n",
       "    The derivative of any constant is 0:\n",
       "    $\\frac{d}{dx}(1) = 0$\n",
       "\n",
       "**Final Answer:**\n",
       "Combining these results, the derivative is:\n",
       "**$f'(x) = 3x^2 + 4x - 5$**\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=748, prompt_tokens=29, total_tokens=777, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=86, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"To find the derivative of the function **$f(x) = x^3 + 2x^2 - 5x + 1$**, we use the **Power Rule**.\\n\\nThe Power Rule states that if $f(x) = ax^n$, then the derivative is $f'(x) = n \\\\cdot ax^{n-1}$.\\n\\nHere is the step-by-step breakdown:\\n\\n1.  **Derivative of $x^3$:**\\n    Multiply by the exponent (3) and subtract 1 from the exponent:\\n    $\\\\frac{d}{dx}(x^3) = 3x^2$\\n\\n2.  **Derivative of $2x^2$:**\\n    Multiply the exponent (2) by the coefficient (2) and subtract 1 from the exponent:\\n    $\\\\frac{d}{dx}(2x^2) = 2 \\\\cdot 2x^1 = 4x$\\n\\n3.  **Derivative of $-5x$:**\\n    Since $x$ is $x^1$, the derivative is simply the coefficient:\\n    $\\\\frac{d}{dx}(-5x) = -5$\\n\\n4.  **Derivative of $1$:**\\n    The derivative of any constant is 0:\\n    $\\\\frac{d}{dx}(1) = 0$\\n\\n**Final Answer:**\\nCombining these results, the derivative is:\\n**$f'(x) = 3x^2 + 4x - 5$**\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'thought_signatures': ['Ev0KCvoKAb4+9vvEGIuumx9s6vyCvdSLhMmM7vswVH8lx51dWrkZTMncGITge1bXwrddIwD6tey7OWohAubakaN6qQx8zkmu8bo3qPuCCwdQGsLELTzJGR3gBK+FqXQbqCc4IG63bKOI1idVPuCGIHA0Pm4XQT43KRTZaWZdOSsIg9/wyd4cF2qkMDaYMkZfmEDGgRFmDGMDWmBGPRkfI0msDUZHfz+XgsFkTvu/VRj9Njozq5XAUZOBNpJ6iZnwsh3VdEBRdwHo2jNdXmJEYOAGpcaOmmudfVfmqJeb3+xkTriE7qKrCbm0Qi3Ftew15fBxIlValqqJwh1Pdj5ZHQzaJk9kyauKM25bFiPcl3jd36d8gwY1tG+suK8FSBiF6RqxU78l18Aouf7w9wh1FlEnbDdBcsI80vPcMlPkbbISxWR6EYXnGlAltfPkvvykvgU3ZdxYv/GO8MKB+nEIxT7Te/PTGuCmvEHxvstRisLbdameiN/KomrBI8pVfvC0doVo3EAL5YnsiBHEr69miK88Jv13929mr8HitFj6ycDc4JPP+iPhb8/khHrkZVROlFpGdLFUFkxRFuX4JnPHhHIlffqaAwoAa+HSf4X8nRTdM66k7/KDN8bjOwvLHjy5as4OAElJwUidzW2UrOViKO2G9UxfXY2Upme5JeBH8jpW2E4t1oTnK6K+cBibqslbUSJ6FRMap/zxdXRkXQUkudBKhK9iuGXN21+UI7aLqE+ubIJEZUvA9NlitsaQiQv+DBm0tZkeLr87fhqZxCZ8KW9H4tC0qqvhkyp6jHTlxD+jJetSkUfktiexs2I0J2FM9d9dNC4c3i85V0EA7Q5HK8SxEAIvrT8jayGzIf79gLtqbcGv6XEbuv6RBuO0oWcyp6ilCp+apyrFtXCs6NWNU4Cu7thuOXT6xGfWT88xwRVTeVcMw5omK9eACd5eEFQJW5dlLyYIKaQek7oyVkc+Hpty7HttAfCf8RMmQKFrbNtnNKGqtp/9k80rESxsOoXG31HfzWC9gnTl/QAAtxZsfQkzRuV6f9pSs5vUAA6X0iJeHOogQ8BUmebW8q8Tsfgx9HCDWz0bb41ZfcWB5vTnHBn3i4IqLaTiDO0ThLR7i2aozUh6tv5srHXP2l9tWptb31B8GZ1r/jpeYN95fZzSmHlGeR8/wP9hSmjV3TlMX8BHwkyBbP53+LhI8GrUO/r3BbaCXN8E/AjeIeqPT1R5sh9G2KGwjR3LVBKyz40tgWzRddNJMYDFUiN1AKW9EzsgJe3Phe23Vg4fvvUiwxmOyVDUSEKnkzOikicFsE28qySIHXf5GVZix6v67a419aX1J4j5psEuF6+x4I5d1pOJzVl5hOT/WiFTF2Y+sixsOBcqc8uNVJibyk7TpZZykiSJCPKBHkv57zfi+Tihy0COY+p0Bb7qOj1xGO72XZZCvn8kjOp7ROFZ6Goe5oqT9+0wbS4AJIEqexJ+a+90uFgZzq9ME+Addt3CKR9AbEOQ16klx5VRuPAKlN5t9N0YLf7JAiwefD2ClQ7ysHNAf7OSCjOD4ir6OTPzClgT593++ApOvfs14K1jSihNcBP9Myfey70H4kp0o/GtW1/wMQ7Fv+GeBwebG3olvud8U9qTjUGVBkrsYS4TX/XeARsiDhF3BK002u4br+kawwh1lmhnGDA9ZLD+ytN7OOOFxwW3bnnJVe5GRfZlbIVD0E+5N/YqtpBcwyt+ZTAW5ftXv/G7w5bf9kwH08tmwdb7TKTAErF6N+Llzw66cnjb8kQKjg4VwYDkHFygkbgD6oVPAjg3RTb+KQXoE9TxkciycnisJXHl2bO07RuzBaCtavTZCIdp84GInMgTqgm+JLuQVxVb3w==']}, reasoning_content=\"**Calculating the Derivative**\\n\\nOkay, I'm working on finding the derivative of $f(x) = x^3 + 2x^2 - 5x + 1$. Using the power rule and sum/difference rules, I can easily find the derivative. It's a fundamental calculus problem, so I'm progressing rapidly, though I am taking care to do it correctly. I am checking my previous work.\\n\\n\\n\"))], usage=Usage(completion_tokens=748, prompt_tokens=29, total_tokens=777, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=86, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf97e55",
   "metadata": {},
   "source": [
    "## Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(completion)\n",
    "def structured(\n",
    "    m:str,          # LiteLLM model string\n",
    "    msgs:list,      # List of messages \n",
    "    tool:Callable,  # Tool to be used for creating the structured output (class, dataclass or Pydantic, function, etc)\n",
    "    **kwargs):\n",
    "    \"Return the value of the tool call (generally used for structured outputs)\"\n",
    "    t = lite_mk_func(tool)\n",
    "    r = completion(m, msgs, tools=[t], tool_choice=t, **kwargs)\n",
    "    args = json.loads(r.choices[0].message.tool_calls[0].function.arguments)\n",
    "    return tool(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49621b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class President:\n",
    "    \"Information about a president of the United States\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        first:str, # first name\n",
    "        last:str, # last name\n",
    "        spouse:str, # name of spouse\n",
    "        years_in_office:str, # format: \"{start_year}-{end_year}\"\n",
    "        birthplace:str, # name of city\n",
    "        birth_year:int # year of birth, `0` if unknown\n",
    "    ):\n",
    "        assert re.match(r'\\d{4}-\\d{4}', years_in_office), \"Invalid format: `years_in_office`\"\n",
    "        store_attr()\n",
    "\n",
    "    __repr__ = basic_repr('first, last, spouse, years_in_office, birthplace, birth_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afd4c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in ms[1:]: \n",
    "    r = structured(m, [mk_msg(\"Tell me something about the third president of the USA.\")], President)\n",
    "    test_eq(r.first, 'Thomas'); test_eq(r.last, 'Jefferson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6964acf7",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a7128c",
   "metadata": {},
   "source": [
    "LiteLLM provides search, not via tools, but via the special `web_search_options` param.\n",
    "\n",
    "**Note:** Not all models support web search. LiteLLM's `supports_web_search` field should indicate this, but it's unreliable for some models like `claude-sonnet-4-20250514`. Checking both `supports_web_search` and `search_context_cost_per_query` provides more accurate detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6530af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _has_search(m):\n",
    "    i = get_model_info(m)\n",
    "    return bool(i.get('search_context_cost_per_query') or i.get('supports_web_search'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43417017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini/gemini-3-pro-preview True\n",
      "gemini/gemini-3-flash-preview True\n",
      "claude-opus-4-6 True\n",
      "openai/gpt-4.1 False\n"
     ]
    }
   ],
   "source": [
    "for m in ms: print(m, _has_search(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8611e2",
   "metadata": {},
   "source": [
    "When search is supported it can be used like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e0bead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Otters are carnivorous, semi-aquatic mammals belonging to the **Mustelidae** family, which also includes weasels, badgers, and wolverines. There are **13 extant species** found on every continent except Antarctica and Australia.\n",
       "\n",
       "### Key Characteristics\n",
       "*   **Physical Traits:** They have long, streamlined bodies, webbed feet, and powerful tails that make them expert swimmers.\n",
       "*   **Insulation:** Instead of blubber, otters rely on incredibly dense, water-resistant fur to stay warm. Sea otters have the thickest fur in the animal kingdom, with up to one million hairs per square inch.\n",
       "*   **Behavior:** Known for being highly intelligent and playful, they are often seen sliding down mudbanks or playing with stones. Some species, like sea otters, are famous for using tools (rocks) to crack open shellfish.\n",
       "\n",
       "### Habitat & Diet\n",
       "*   **Environments:** Most species live in freshwater (rivers, lakes, and wetlands), while the sea otter and marine otter live in saltwater environments. \n",
       "*   **Social Life:** Social structures vary; river otters are often solitary or live in small family groups, whereas sea otters can gather in large groups called **rafts**.\n",
       "*   **Diet:** They are opportunistic hunters that primarily eat fish, crustaceans, mollusks, and occasionally small mammals or birds.\n",
       "\n",
       "### Major Species\n",
       "*   **Sea Otter:** The heaviest otter, living almost exclusively in the Pacific Ocean.\n",
       "*   **Giant Otter:** Found in South America, it can reach up to 6 feet (1.8 meters) in length.\n",
       "*   **Asian Small-Clawed Otter:** The smallest species, native to Southeast Asian wetlands.\n",
       "*   **North American River Otter:** A common freshwater species found throughout much of Canada and the U.S.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=380, prompt_tokens=12, total_tokens=392, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=380, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=12, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Otters are carnivorous, semi-aquatic mammals belonging to the **Mustelidae** family, which also includes weasels, badgers, and wolverines. There are **13 extant species** found on every continent except Antarctica and Australia.\\n\\n### Key Characteristics\\n*   **Physical Traits:** They have long, streamlined bodies, webbed feet, and powerful tails that make them expert swimmers.\\n*   **Insulation:** Instead of blubber, otters rely on incredibly dense, water-resistant fur to stay warm. Sea otters have the thickest fur in the animal kingdom, with up to one million hairs per square inch.\\n*   **Behavior:** Known for being highly intelligent and playful, they are often seen sliding down mudbanks or playing with stones. Some species, like sea otters, are famous for using tools (rocks) to crack open shellfish.\\n\\n### Habitat & Diet\\n*   **Environments:** Most species live in freshwater (rivers, lakes, and wetlands), while the sea otter and marine otter live in saltwater environments. \\n*   **Social Life:** Social structures vary; river otters are often solitary or live in small family groups, whereas sea otters can gather in large groups called **rafts**.\\n*   **Diet:** They are opportunistic hunters that primarily eat fish, crustaceans, mollusks, and occasionally small mammals or birds.\\n\\n### Major Species\\n*   **Sea Otter:** The heaviest otter, living almost exclusively in the Pacific Ocean.\\n*   **Giant Otter:** Found in South America, it can reach up to 6 feet (1.8 meters) in length.\\n*   **Asian Small-Clawed Otter:** The smallest species, native to Southeast Asian wetlands.\\n*   **North American River Otter:** A common freshwater species found throughout much of Canada and the U.S.', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7sFUjQI2xt06Hx14Cn1boNLA4vt5G3WwYnOoVx8t3R6TPF9NZxWdJZiXpVzYQ']}, annotations=[{'type': 'url_citation', 'url_citation': {'end_index': 228, 'start_index': 139, 'title': 'animalfact.com', 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF5O5xRG7hOMkEK74FTpK9RCYsZUQmzXjFGMtfcZQtq-Oc7h4G73HEmwlOj_hWjMSunYEQ-tlIMfjB5lmyz1HNdALnxAXmeUGzEsRFPu0KxnPNVFXIpBy9O5A=='}}, {'type': 'url_citation', 'url_citation': {'end_index': 253, 'start_index': 230, 'title': 'britannica.com', 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFKW1a1HnrbRAGgdhfcxy1rQ3DApXuZu6lx_3Beejbni-DuKqJZi9YsSqJNMXdBV6kbWsG8i88gLRFhhQV9udvDXVPsaECySh6sM-W1PJqR-z8i_SDqLOEyEFJuOtl89V-PeA=='}}, {'type': 'url_citation', 'url_citation': {'end_index': 378, 'start_index': 254, 'title': 'animalfact.com', 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF5O5xRG7hOMkEK74FTpK9RCYsZUQmzXjFGMtfcZQtq-Oc7h4G73HEmwlOj_hWjMSunYEQ-tlIMfjB5lmyz1HNdALnxAXmeUGzEsRFPu0KxnPNVFXIpBy9O5A=='}}, {'type': 'url_citation', 'url_citation': {'end_index': 485, 'start_index': 379, 'title': 'wikipedia.org', 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFZhShK-sYJlZ6yW3HDOfHAXSedE_8eleQXBYkNPY8-RanCdZKEHK8koAjU6VWs8IejXWUjqcGA_KiiTFadDFVUeJoQgKYApAcACpOebB3Un6EM2_zSl6TnqKJyfNfb'}}, {'type': 'url_citation', 'url_citation': {'end_index': 587, 'start_index': 486, 'title': 'doi.gov', 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyEe4_ov2v5IfdBlghXq4r9jiCYORM2D5HfzErwhg8-r4P-X9xsifzrKZWokyyxpCcvoUnrN_AlFfZacab4SPIMTeFI6YOqiu2gffFZOLUxSfGC8EydZzy_67ofYmfrkfFsOjCsAYaKGtdiYX6ORz28y3WvwuTppaldRv4iRsJyjRv'}}, {'type': 'url_citation', 'url_citation': {'end_index': 719, 'start_index': 588, 'title': 'wikipedia.org', 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFZhShK-sYJlZ6yW3HDOfHAXSedE_8eleQXBYkNPY8-RanCdZKEHK8koAjU6VWs8IejXWUjqcGA_KiiTFadDFVUeJoQgKYApAcACpOebB3Un6EM2_zSl6TnqKJyfNfb'}}, {'type': 'url_citation', 'url_citation': {'end_index': 810, 'start_index': 720, 'title': 'ebsco.com', 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGhIGfibyuwSMtyyxmghDHAHAWXTbNKXLBECCyg1LTDuw2BxWZZPgX68tlp7-w6iy0ejlBXDzzFzTsOKvznOpMy_VJDDIe5SWkwxQs2ZxJMpXv35j40BaAarTHBFEFdQTWJwW6J5dDffSYD0lxlmVg-BQ=='}}, {'type': 'url_citation', 'url_citation': {'end_index': 830, 'start_index': 812, 'title': 'outforia.com', 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGFpUg3YsOxfnno2WLvmcjDL4VpiN3jOQnGux2JyYhaTCa_VkyFS309In1L9aIFJLqgBY16SH9CUMrBsevSALrbF7I-nKOTaaQZa47wodTlRhERjBuNHk11qwQmYNM64Ls='}}, {'type': 'url_citation', 'url_citation': {'end_index': 984, 'start_index': 831, 'title': 'animalfact.com', 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF5O5xRG7hOMkEK74FTpK9RCYsZUQmzXjFGMtfcZQtq-Oc7h4G73HEmwlOj_hWjMSunYEQ-tlIMfjB5lmyz1HNdALnxAXmeUGzEsRFPu0KxnPNVFXIpBy9O5A=='}}, {'type': 'url_citation', 'url_citation': {'end_index': 1158, 'start_index': 986, 'title': 'countryandhome.co.uk', 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHvrIH_bm0nKdQGAxlhJPZNOKKthEFcQorZqtqNJCITwW2YFGa1j0e6LU4eGZU6JZ2V48Dz4L-B3tteGYlDxArzxiPoJemYEHI50YXMBAKZe5quJ_gOKHw6Cu99Dkv9_6iwP3adnqfD5fHeDHLvvjDJy8b_Eq3WcxChnz15CD9j6SJq-tg='}}, {'type': 'url_citation', 'url_citation': {'end_index': 1292, 'start_index': 1159, 'title': 'wikipedia.org', 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFZhShK-sYJlZ6yW3HDOfHAXSedE_8eleQXBYkNPY8-RanCdZKEHK8koAjU6VWs8IejXWUjqcGA_KiiTFadDFVUeJoQgKYApAcACpOebB3Un6EM2_zSl6TnqKJyfNfb'}}, {'type': 'url_citation', 'url_citation': {'end_index': 1311, 'start_index': 1294, 'title': 'ebsco.com', 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGhIGfibyuwSMtyyxmghDHAHAWXTbNKXLBECCyg1LTDuw2BxWZZPgX68tlp7-w6iy0ejlBXDzzFzTsOKvznOpMy_VJDDIe5SWkwxQs2ZxJMpXv35j40BaAarTHBFEFdQTWJwW6J5dDffSYD0lxlmVg-BQ=='}}, {'type': 'url_citation', 'url_citation': {'end_index': 1398, 'start_index': 1312, 'title': 'ebsco.com', 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGhIGfibyuwSMtyyxmghDHAHAWXTbNKXLBECCyg1LTDuw2BxWZZPgX68tlp7-w6iy0ejlBXDzzFzTsOKvznOpMy_VJDDIe5SWkwxQs2ZxJMpXv35j40BaAarTHBFEFdQTWJwW6J5dDffSYD0lxlmVg-BQ=='}}, {'type': 'url_citation', 'url_citation': {'end_index': 1694, 'start_index': 1586, 'title': 'ebsco.com', 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGhIGfibyuwSMtyyxmghDHAHAWXTbNKXLBECCyg1LTDuw2BxWZZPgX68tlp7-w6iy0ejlBXDzzFzTsOKvznOpMy_VJDDIe5SWkwxQs2ZxJMpXv35j40BaAarTHBFEFdQTWJwW6J5dDffSYD0lxlmVg-BQ=='}}]))], usage=Usage(completion_tokens=380, prompt_tokens=12, total_tokens=392, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=380, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=12, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[{'searchEntryPoint': {'renderedContent': '<style>\\n.container {\\n  align-items: center;\\n  border-radius: 8px;\\n  display: flex;\\n  font-family: Google Sans, Roboto, sans-serif;\\n  font-size: 14px;\\n  line-height: 20px;\\n  padding: 8px 12px;\\n}\\n.chip {\\n  display: inline-block;\\n  border: solid 1px;\\n  border-radius: 16px;\\n  min-width: 14px;\\n  padding: 5px 16px;\\n  text-align: center;\\n  user-select: none;\\n  margin: 0 8px;\\n  -webkit-tap-highlight-color: transparent;\\n}\\n.carousel {\\n  overflow: auto;\\n  scrollbar-width: none;\\n  white-space: nowrap;\\n  margin-right: -12px;\\n}\\n.headline {\\n  display: flex;\\n  margin-right: 4px;\\n}\\n.gradient-container {\\n  position: relative;\\n}\\n.gradient {\\n  position: absolute;\\n  transform: translate(3px, -9px);\\n  height: 36px;\\n  width: 9px;\\n}\\n@media (prefers-color-scheme: light) {\\n  .container {\\n    background-color: #fafafa;\\n    box-shadow: 0 0 0 1px #0000000f;\\n  }\\n  .headline-label {\\n    color: #1f1f1f;\\n  }\\n  .chip {\\n    background-color: #ffffff;\\n    border-color: #d2d2d2;\\n    color: #5e5e5e;\\n    text-decoration: none;\\n  }\\n  .chip:hover {\\n    background-color: #f2f2f2;\\n  }\\n  .chip:focus {\\n    background-color: #f2f2f2;\\n  }\\n  .chip:active {\\n    background-color: #d8d8d8;\\n    border-color: #b6b6b6;\\n  }\\n  .logo-dark {\\n    display: none;\\n  }\\n  .gradient {\\n    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\\n  }\\n}\\n@media (prefers-color-scheme: dark) {\\n  .container {\\n    background-color: #1f1f1f;\\n    box-shadow: 0 0 0 1px #ffffff26;\\n  }\\n  .headline-label {\\n    color: #fff;\\n  }\\n  .chip {\\n    background-color: #2c2c2c;\\n    border-color: #3c4043;\\n    color: #fff;\\n    text-decoration: none;\\n  }\\n  .chip:hover {\\n    background-color: #353536;\\n  }\\n  .chip:focus {\\n    background-color: #353536;\\n  }\\n  .chip:active {\\n    background-color: #464849;\\n    border-color: #53575b;\\n  }\\n  .logo-light {\\n    display: none;\\n  }\\n  .gradient {\\n    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\\n  }\\n}\\n</style>\\n<div class=\"container\">\\n  <div class=\"headline\">\\n    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\\n    </svg>\\n    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\\n      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\\n      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\\n      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\\n      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\\n      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\\n    </svg>\\n    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\\n  </div>\\n  <div class=\"carousel\">\\n    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHTyBQSqLd33I2SJMbX5TP-1SnMm9b2NJPj9TyzJHMjlCds0MCe5fuPazEtVH1dgMhi1Q2j69eNoxphUeCKuSTQ7BtAWFRHtjJAv7LCV4WNF0-WPKWanskvXHgracUIW0x-W40J0KOL4w4x4tn_zUSzbb_nxny6_Z73LESK0T8GhcSADHHljxbX9FeVUOWT0X4Ca65P1UJFDOCk82C92HoexrUkZdzUmqAB1IOw7vsR\">different types of otters and their habitats</a>\\n    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG-6uWbNdTJIc1RfRM-YvWXC-GYDl_uQzfbZYY-Vk9I5PVqz_sTJPIQHYr4uem6vT_93Xj2TvaIAzI9_UcHqf-H33dTDVR3S9yvycYvrnSZXwVvJROUDR_4DFtay2yaiOFe_5H5eIp_WeLl9EL0IBOOOQMMSbSEuP5sTBkRmUj7XAEIkq-Ccg7d56znHvgfc7bMvj_c85zGB0aMug==\">brief facts about otters</a>\\n  </div>\\n</div>\\n'}, 'groundingChunks': [{'web': {'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFZhShK-sYJlZ6yW3HDOfHAXSedE_8eleQXBYkNPY8-RanCdZKEHK8koAjU6VWs8IejXWUjqcGA_KiiTFadDFVUeJoQgKYApAcACpOebB3Un6EM2_zSl6TnqKJyfNfb', 'title': 'wikipedia.org'}}, {'web': {'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyEe4_ov2v5IfdBlghXq4r9jiCYORM2D5HfzErwhg8-r4P-X9xsifzrKZWokyyxpCcvoUnrN_AlFfZacab4SPIMTeFI6YOqiu2gffFZOLUxSfGC8EydZzy_67ofYmfrkfFsOjCsAYaKGtdiYX6ORz28y3WvwuTppaldRv4iRsJyjRv', 'title': 'doi.gov'}}, {'web': {'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFf2X-YndiX8tNjy_MXitsGZNyiXN4Xe1JAZLgV6lyJKNY16fNXFiQnqLiuZtE5KfjY47UgUwws9RzCSbubi5opunRy67UIgiiuwizfXAM6ytpKRGvEYSjKCSn1VV-_IFYTXY_4HVB2vE-64dfTEyyHWpYjWPSfncu16AP38KIz', 'title': 'montereybayaquarium.org'}}, {'web': {'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF5O5xRG7hOMkEK74FTpK9RCYsZUQmzXjFGMtfcZQtq-Oc7h4G73HEmwlOj_hWjMSunYEQ-tlIMfjB5lmyz1HNdALnxAXmeUGzEsRFPu0KxnPNVFXIpBy9O5A==', 'title': 'animalfact.com'}}, {'web': {'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFKW1a1HnrbRAGgdhfcxy1rQ3DApXuZu6lx_3Beejbni-DuKqJZi9YsSqJNMXdBV6kbWsG8i88gLRFhhQV9udvDXVPsaECySh6sM-W1PJqR-z8i_SDqLOEyEFJuOtl89V-PeA==', 'title': 'britannica.com'}}, {'web': {'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGhIGfibyuwSMtyyxmghDHAHAWXTbNKXLBECCyg1LTDuw2BxWZZPgX68tlp7-w6iy0ejlBXDzzFzTsOKvznOpMy_VJDDIe5SWkwxQs2ZxJMpXv35j40BaAarTHBFEFdQTWJwW6J5dDffSYD0lxlmVg-BQ==', 'title': 'ebsco.com'}}, {'web': {'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGFL_5G642KRbbx4niKDr0aemoeFlaBDFlsYjbigHzH35clpTEGgNygRPTS0Hg6d0aQ-c1lsJDEIcIe1nKuD8CWndsa6bYdhGIWX3SxInymaYikiG2VqmcMha7kS8H9RHKNPmg=', 'title': 'ukwildottertrust.org'}}, {'web': {'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHvrIH_bm0nKdQGAxlhJPZNOKKthEFcQorZqtqNJCITwW2YFGa1j0e6LU4eGZU6JZ2V48Dz4L-B3tteGYlDxArzxiPoJemYEHI50YXMBAKZe5quJ_gOKHw6Cu99Dkv9_6iwP3adnqfD5fHeDHLvvjDJy8b_Eq3WcxChnz15CD9j6SJq-tg=', 'title': 'countryandhome.co.uk'}}, {'web': {'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGFpUg3YsOxfnno2WLvmcjDL4VpiN3jOQnGux2JyYhaTCa_VkyFS309In1L9aIFJLqgBY16SH9CUMrBsevSALrbF7I-nKOTaaQZa47wodTlRhERjBuNHk11qwQmYNM64Ls=', 'title': 'outforia.com'}}], 'groundingSupports': [{'segment': {'endIndex': 138, 'text': 'Otters are carnivorous, semi-aquatic mammals belonging to the **Mustelidae** family, which also includes weasels, badgers, and wolverines.'}, 'groundingChunkIndices': [0, 1, 2]}, {'segment': {'startIndex': 139, 'endIndex': 228, 'text': 'There are **13 extant species** found on every continent except Antarctica and Australia.'}, 'groundingChunkIndices': [3]}, {'segment': {'startIndex': 230, 'endIndex': 253, 'text': '### Key Characteristics'}, 'groundingChunkIndices': [4, 3, 5, 6, 0, 7, 2, 1, 8]}, {'segment': {'startIndex': 254, 'endIndex': 378, 'text': '*   **Physical Traits:** They have long, streamlined bodies, webbed feet, and powerful tails that make them expert swimmers.'}, 'groundingChunkIndices': [3, 0, 7, 6]}, {'segment': {'startIndex': 379, 'endIndex': 485, 'text': '*   **Insulation:** Instead of blubber, otters rely on incredibly dense, water-resistant fur to stay warm.'}, 'groundingChunkIndices': [0, 1, 5]}, {'segment': {'startIndex': 486, 'endIndex': 587, 'text': 'Sea otters have the thickest fur in the animal kingdom, with up to one million hairs per square inch.'}, 'groundingChunkIndices': [1]}, {'segment': {'startIndex': 588, 'endIndex': 719, 'text': '*   **Behavior:** Known for being highly intelligent and playful, they are often seen sliding down mudbanks or playing with stones.'}, 'groundingChunkIndices': [0]}, {'segment': {'startIndex': 720, 'endIndex': 810, 'text': 'Some species, like sea otters, are famous for using tools (rocks) to crack open shellfish.'}, 'groundingChunkIndices': [5, 7]}, {'segment': {'startIndex': 812, 'endIndex': 830, 'text': '### Habitat & Diet'}, 'groundingChunkIndices': [8, 7, 0, 2, 3, 5, 4]}, {'segment': {'startIndex': 831, 'endIndex': 984, 'text': '*   **Environments:** Most species live in freshwater (rivers, lakes, and wetlands), while the sea otter and marine otter live in saltwater environments.'}, 'groundingChunkIndices': [3, 5, 4]}, {'segment': {'startIndex': 986, 'endIndex': 1158, 'text': '*   **Social Life:** Social structures vary; river otters are often solitary or live in small family groups, whereas sea otters can gather in large groups called **rafts**.'}, 'groundingChunkIndices': [7]}, {'segment': {'startIndex': 1159, 'endIndex': 1292, 'text': '*   **Diet:** They are opportunistic hunters that primarily eat fish, crustaceans, mollusks, and occasionally small mammals or birds.'}, 'groundingChunkIndices': [0]}, {'segment': {'startIndex': 1294, 'endIndex': 1311, 'text': '### Major Species'}, 'groundingChunkIndices': [5, 3, 0, 4, 8]}, {'segment': {'startIndex': 1312, 'endIndex': 1398, 'text': '*   **Sea Otter:** The heaviest otter, living almost exclusively in the Pacific Ocean.'}, 'groundingChunkIndices': [5]}, {'segment': {'startIndex': 1586, 'endIndex': 1694, 'text': '*   **North American River Otter:** A common freshwater species found throughout much of Canada and the U.S.'}, 'groundingChunkIndices': [5, 8]}], 'webSearchQueries': ['brief facts about otters', 'different types of otters and their habitats']}], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smsg = mk_msg(\"Search the web and tell me very briefly about otters\")\n",
    "r = c(smsg, web_search_options={\"search_context_size\": \"low\"})  # or 'medium' / 'high'\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1af925d",
   "metadata": {},
   "source": [
    "## Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaeeee1",
   "metadata": {},
   "source": [
    "Next, lets handle Anthropic's search citations.\n",
    "\n",
    "When not using streaming, all citations are placed in a separate key in the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e2a7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['searchEntryPoint', 'groundingChunks', 'groundingSupports', 'webSearchQueries'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['vertex_ai_grounding_metadata'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da64e713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brief facts about otters', 'different types of otters and their habitats']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['vertex_ai_grounding_metadata'][0]['webSearchQueries']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689cdf9d",
   "metadata": {},
   "source": [
    "Web search results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030d17a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'web': {'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFZhShK-sYJlZ6yW3HDOfHAXSedE_8eleQXBYkNPY8-RanCdZKEHK8koAjU6VWs8IejXWUjqcGA_KiiTFadDFVUeJoQgKYApAcACpOebB3Un6EM2_zSl6TnqKJyfNfb',\n",
       "   'title': 'wikipedia.org'}},\n",
       " {'web': {'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyEe4_ov2v5IfdBlghXq4r9jiCYORM2D5HfzErwhg8-r4P-X9xsifzrKZWokyyxpCcvoUnrN_AlFfZacab4SPIMTeFI6YOqiu2gffFZOLUxSfGC8EydZzy_67ofYmfrkfFsOjCsAYaKGtdiYX6ORz28y3WvwuTppaldRv4iRsJyjRv',\n",
       "   'title': 'doi.gov'}},\n",
       " {'web': {'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFf2X-YndiX8tNjy_MXitsGZNyiXN4Xe1JAZLgV6lyJKNY16fNXFiQnqLiuZtE5KfjY47UgUwws9RzCSbubi5opunRy67UIgiiuwizfXAM6ytpKRGvEYSjKCSn1VV-_IFYTXY_4HVB2vE-64dfTEyyHWpYjWPSfncu16AP38KIz',\n",
       "   'title': 'montereybayaquarium.org'}}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['vertex_ai_grounding_metadata'][0]['groundingChunks'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8971dc08",
   "metadata": {},
   "source": [
    "Citations in gemini: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb79aef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'segment': {'endIndex': 138,\n",
       "   'text': 'Otters are carnivorous, semi-aquatic mammals belonging to the **Mustelidae** family, which also includes weasels, badgers, and wolverines.'},\n",
       "  'groundingChunkIndices': [0, 1, 2]},\n",
       " {'segment': {'startIndex': 139,\n",
       "   'endIndex': 228,\n",
       "   'text': 'There are **13 extant species** found on every continent except Antarctica and Australia.'},\n",
       "  'groundingChunkIndices': [3]},\n",
       " {'segment': {'startIndex': 230,\n",
       "   'endIndex': 253,\n",
       "   'text': '### Key Characteristics'},\n",
       "  'groundingChunkIndices': [4, 3, 5, 6, 0, 7, 2, 1, 8]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['vertex_ai_grounding_metadata'][0]['groundingSupports'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9915026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.choices[0].message.provider_specific_fields['citations'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a8559",
   "metadata": {},
   "source": [
    "However, when streaming the results are not captured this way.\n",
    "Instead, we provide this helper function that adds the citation to the `content` field in markdown format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc341e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cite_footnote(msg):\n",
    "    if not (delta:=nested_idx(msg, 'choices', 0, 'delta')): return\n",
    "    if citation:= nested_idx(delta, 'provider_specific_fields', 'citation'):\n",
    "        title = citation['title'].replace('\"', '\\\\\"')\n",
    "        delta.content = f'[*]({citation[\"url\"]} \"{title}\") '\n",
    "        \n",
    "def cite_footnotes(stream_list):\n",
    "    \"Add markdown footnote citations to stream deltas\"\n",
    "    for msg in stream_list: cite_footnote(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d753235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c79a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", message=\"Pydantic serializer warnings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2150365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a brief overview of otters:\n",
       "\n",
       "[*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") Otters are carnivorous mammals in the subfamily Lutrinae, with 14 extant species that are all semiaquatic, living in both freshwater and marine environments. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") They are charismatic members of the weasel family, found on every continent except Australia and Antarctica.\n",
       "\n",
       "**Physical Features:** [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") Otters are distinguished by their long, slim bodies, powerful webbed feet for swimming, and dense fur that keeps them warm and buoyant in water. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") They have the densest fur of any animalâ€”as many as a million hairs per square inch in places.\n",
       "\n",
       "**Species Range:** [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") The Asian small-clawed otter is the smallest species, while the giant otter and sea otter are the largest. [*](https://www.doi.gov/blog/12-facts-about-otters-sea-otter-awareness-week \"12 Facts About Otters for Sea Otter Awareness Week | U.S. Department of the Interior\") The sea otter is the largest member of the weasel family, yet the smallest marine mammal in North America.\n",
       "\n",
       "**Behavior:** [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") They are playful animals, engaging in activities like sliding into water on natural slides and playing with stones. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") All otters are expert hunters that eat fish, crustaceans, and other critters. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") Sea otters will float on their backs, place a rock on their chests, then smash mollusks down on it until they break open. When it's time to nap, they entangle themselves in kelp so they don't float away.\n",
       "\n",
       "**Lifespan & Reproduction:** [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") Otters have a gestation period of about 60â€“86 days, offspring typically stay with their family for a year, and they can live up to 16 years.\n",
       "\n",
       "**Conservation:** [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") Otters and their mustelid relatives were once hunted extensively for their fur, many to the point of near extinction. Despite regulations designed to protect them, many species remain at risk from pollution and habitat loss.\n",
       "\n",
       "ðŸ”§ web_search({\"query\": \"otters facts\"})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=635, prompt_tokens=13930, total_tokens=14565, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Here\\'s a brief overview of otters:\\n\\n[*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") Otters are carnivorous mammals in the subfamily Lutrinae, with 14 extant species that are all semiaquatic, living in both freshwater and marine environments. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") They are charismatic members of the weasel family, found on every continent except Australia and Antarctica.\\n\\n**Physical Features:** [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") Otters are distinguished by their long, slim bodies, powerful webbed feet for swimming, and dense fur that keeps them warm and buoyant in water. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") They have the densest fur of any animalâ€”as many as a million hairs per square inch in places.\\n\\n**Species Range:** [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") The Asian small-clawed otter is the smallest species, while the giant otter and sea otter are the largest. [*](https://www.doi.gov/blog/12-facts-about-otters-sea-otter-awareness-week \"12 Facts About Otters for Sea Otter Awareness Week | U.S. Department of the Interior\") The sea otter is the largest member of the weasel family, yet the smallest marine mammal in North America.\\n\\n**Behavior:** [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") They are playful animals, engaging in activities like sliding into water on natural slides and playing with stones. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") All otters are expert hunters that eat fish, crustaceans, and other critters. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") Sea otters will float on their backs, place a rock on their chests, then smash mollusks down on it until they break open. When it\\'s time to nap, they entangle themselves in kelp so they don\\'t float away.\\n\\n**Lifespan & Reproduction:** [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") Otters have a gestation period of about 60â€“86 days, offspring typically stay with their family for a year, and they can live up to 16 years.\\n\\n**Conservation:** [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") Otters and their mustelid relatives were once hunted extensively for their fur, many to the point of near extinction. Despite regulations designed to protect them, many species remain at risk from pollution and habitat loss.', role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"query\": \"otters facts\"}', name='web_search'), id='srvtoolu_0197BgtdgToYWo8HwTLwCxnV', type='function')], function_call=None, provider_specific_fields={'web_search_results': [{'type': 'web_search_tool_result', 'tool_use_id': 'srvtoolu_0197BgtdgToYWo8HwTLwCxnV', 'content': [{'type': 'web_search_result', 'title': '12 Facts About Otters for Sea Otter Awareness Week | U.S. Department of the Interior', 'url': 'https://www.doi.gov/blog/12-facts-about-otters-sea-otter-awareness-week', 'encrypted_content': 'EuwfCioIDRgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDLXvGudB5pTWzZ8UAhoMR9o2ag2ewhdIjZ44IjC2IdHanUiMNhfAkn6c4CpLCABpnwZno3tsnaa5/+SL5bO17rnabWEE9SsauCOJbKMq7x71uI6LFkyGPlCcLtED+NqG6+0TB74wjhjZsELRBxEgobuXF0R4jB+2EMIHnwO++HvRh2UwgYG+TcN0/S0a0xUJ/52HXx/ypKcR4iA8NJx0REPCP0cr9X4O7i3JWxEYbGyRwOZz3pRf+t+8w9yW0GdqxaUE0RGU4fyWRq+MmTux3sDBm9q8IoCwVsDQsLoRuB0injzYml4RwKw8s/cYGFaMUtmWfa2D/wCZhthgRC8885qsVDeWcg6ImtweT8q87Ff/JHHRFIz6oFgi/KTvYE5Box2sjVAtK5MPGxvJLtKu+OtWBFBjwoI/mPSy8nTsL1KBwg9GGGjYV+kQ2FY4t7qNIEje+P4elm7I56mDxGop9YOoecgujVN6msuzni/iRmRy4y3hvOGGX6laTdgoJvR/tr7JVpRGOx5I3TE1gk2ejlMlVDPaBZtrxjDJAIcHFhHArwk3mgiBHjN1m0Nx9XZ9/67BPw6RAnEzIdJAIy0lSVfc1nJtikUPT5ihOv8wNIvzf9m9uCvN5+1u4ZxhFtJWE8qVIRaC7wwxQtB0vS314J9KV5YGVSYFEMGnscJjTnrkZ5OU+LNXMjuFM3/4wYoyIQJ2X15+jBkoDD5qsxdPNWiTcjgKGgzm8czSn2zf/0ZJvAZPyhO/YoFVP4Y3QZQGdQMbT+04K10IhPfsjyjugCsVRHJjaQWweruRjEsL1iWmYdvW0PB/9rhI829/tYtR2ZclcrtXcbBUCexMrkDL/osOLktkbnLfJ3NT3L11AZWH3Nicqjl5bo1sUXShbIzMU87wnfYByCfLXKwkxNaj2ixNwA7HM/Ts1JZZ+cZupzQyUZWXlELF0OXBE4sMl1+SocL3YgAraP99gFccGqqkUbF/rlE4JtD8E6OnLGczUQOXzsETCr7CZFfH3KGQaX/HrGXZtYhJXqdYF2ZF126gOTgtWN6+w+e6Tn0KuNOg1dOX4eu+zWtMCWMtNHRRzeI27VUwitr7xtHpsDZ4keNEpNx6FYw5iCgjDe5cG8qizN3ijycc8sy+5ELQamhriNNgXJ9AQLHVmi+iRhqtJHNDm0y6YU2ZkbQ7PYkycMdQWMZHIx382qPqOpkgupFtbimevvp7C0FK4jAwiLEjrd0nDeAHsGuKQRoA4xm0L/Iat5rP3Scv3ri54Vox1AcuZxOGfS3mqMsnYLSvRq9OeOqxV2wGBIo9kIEVJNWsk6lztaYkgBgjziuGCp3rA7CWl2bD9FrpqjVIzzNVS9WDLsxgBIr3f2EWCfjD+BzVutCGcVlfRp0k+1X795lxk+/FBt8XFvJI8XJSuHcs21tInrVrsu5MplAl7sx6n4gn8hMBERSiay63HH1dgmDB2QTx4fRxhyO9iUnc7nfyE3V/Ez/Oou8v7tbLHU7VL0X5FcN6ZdrIVrdaUhUkd1F6tT0wOmp6Tm6RQTiziTb6559OeuqTA97n+TaJjiZoMAiVq8fBX8gc2+Zs4pzkwWDyEVISkAK2IkbjKDYdUBMkpe/hvtZ0NO0qLvpTmn4lxi9BsSxp7StYPnlIYLOLlsnwxH7teNLOkdwICyTUZxPFxV9hXCeYEELwtI9092qQy0fuZqgECWCx0KckOjIx8rRhvJboYcwwVw9wkgvGmaiXZFuIa+6PDK4iHc4nxMFX8nH0Amtysfq/WBaaHsq1pTukpvCW1Nc+ymKs5FWIA9tyiBfpWr/4yPjoLJVFlmsF3hvM5YzNRx3lEVmMaARG9cpncJz5MbiHUnwEMw5aSasic5Hc31d7YUaX/+tWYwZuHyJIKHEM4G4xMvCAa7LdxkPc/0eMvJUcUk+3fPI3XUSdsRqNK2ond8Mb2hOUgJmJp8t5+8ptDFe9j87446VgKW+tNlyrUMe2y1P7jMFvRqq1ne3jcQtqVj+meL1QcWdlYzzg+OUIHxHhAzJGjPa8ClZ7MqDP+2eHYHKcZnRQrZDG3zuJZVUvlAb8kUm3SjHg6HMf0C0CsOFc3h1/yaaN7S7zWvQiDGs2EM9te9xGza4rvvPhGs7dfa6TlFT5YjrBmmikjOQ+rqyQKyKBxfrgnLvyeivJEN5ipzoCdT6P3PoeJOFnqlk4i5qVh+GU2WcWScZAi1wlgY9UGXaPrTrYM6+zOpnG9xu3Kx9Nxtexgkr3B+hZOE0JGnFzrpjixezplU/5NYJcLQhsGR8Fzaad3lRVDf6vOLuTeJqP3cYfxXCvWiV/eslX3EfeAe5eQpvE0QOi8MlDE0IQEK3q/U8xcfaH5fUVccM8ZoHGUMHOCndO1I2y/20UqSn534m3z0D9usBd0zmG6jsL5/DO6TKGC6cgodeyxqNQYY1IN6qNFWqFK9sVyRHT0mM3EoQsZixop34JTzo3SgyhesjVetSnEr8ReZ2hfrpqXXU9blVzqxY3KIpQJCTq1TMxXSayWYnULyKHvZiQYcGdyZd6fo8pXXbyhJWauXRcfz3V9EWwTLd7Dr2jJuwyDOmQMC39H6eUR1f+mpxGBhQVoVulRk9jSxQUcbQbqICsdm6RVUYEv9UhkC+13Ent/nte1fJhEv7gyF6e77uMWcIijrI5+SpsrYkVS7iDEsEPK1x24tlQ06EPnW8oSnrm4iu1ayoPxtH4nP6rxAK4dVoNX4++3Z2om7bEKVGIFpX/+RVI4DvMQ02ohjDgdEC0UiKU+XcRAIOWwjaNYkS1DC7CSVw8Y0tz7cyU1rMQdVIvwa57vHMzRtmvWa0mpFGu4kXguAhKiKneN65oHPHEUq5/Xr4KmMCPMqOz84uo7wdC0KHONrYie4UkLS7bKTNtvq2t4ChAPLDgxt7FN3lIiYEvAug2dgN6Bp8QaEINFGGhYUZx7DsvlqMowyIaR/hYcZ7H6EUYzHs8HmqWKoesK2VgZDr5mfWRR8FABqWZoGgVGvC8B81dOf8SiRVbYc2ghrZ8Ixz/K8qLOT8+FodxqPMUTjo2QAdVfeZ7khS8cT1v+nCOGr+Nc6EVUWOr5DC25S0WBRW4/0Yp6z3xqmaFxixmh0U1PQsrqf99E+lytJIu9XRPUDSetv8UsL/dkbD09gX+8P8ZYIoJY58fNxcxH5Dpk9X+1xQO6oAS6tx6BtuBdUoB0SzmNPHzt1lEStFgz95JRSyIRKn3ayRxirYdnCC1lgDjZoNSz9EYnUE3PHF7p+38nyZucW0lic7fgI9IN8yl0cR+GqbM1wwrj6vZomBSyIy6RNMqVYPksAbO6jm3aH5/H9IZk0k9qzvwV5ASNr7SlWuJTBlHWvG2TsDMVlzFFj8E+MGeWRZsgn4IwBBkn35qbgqXqMqIQ3VQMz+K9wmO/4nLEOajLJ/S4QTxqqhy6LYnaQbO4EKUXit14IyJ858LxvXvX19mSZGs97p7UijjWt2jo6TpwnXQkZ20H6a4GaE1eoKLrkRPmeffoyERdYdrVE8tAF8Hpc1qBGEKLvE3bMaYisBAt2BJN0QexXaQ3J3YvroCOthIhf5QWihf+7nY6IdOZNWfHm0cVYqSrtiYDkidrN3PMOAiDw6aBfJQYVfO5D86/6NOrU5V0aDt7KegBKUTPVWN7EDMvKab0LpSOoKhCPh/v8bJfWe8rrg+FnKiF6uOcc7KV4fdiTkoSLpsj+vSV0zNob8i7Cwla/OmCu0Fg9eEtTa865MLHf4mq3DVfTaDEpSDDSB/ogLWL/10LHHwmR5Nrn5hlFEw9mG3ZuWQw7hJsGiP3mTdLamCwoXai6ofNDLJrtbdc5d65vDDpXyNPHNzcNzWNZD1+elM2Yanwax8GAlQcT9fwPtzktpTAjlWNvdHtBo7qoqyizyi4r2Uc514Qxt3g65Cc69RA6k3mXPkG4yfBe2e4uw2QhbN813Gw7IQ/L37k8sjBAKmZjR4vP7o1YhR6+Qvgu3UC/U57JhvbGdW7cgFP7k/cE9trWW5r3AuvlAoOeUCUV+kMpG4wNtoOXFUZxdKlzxco5A3Ks/e8oKSglHvimESLG1322A2quhgusRphWb7f8gR7y6tW1CaKaAy2JO/o0QlWfbCXy4zCsnT9kP6xOGFargmbfSZE3GglVomk+L7lOKUr8ytay0TI972TriX9JnupBhoLgEf/9LnI3wvGgquhomYVFNJ2vfKkfgLm0VDFeuWjgrJthfJm8HLBWKhapSKGeAPRWFkw+aRIWFmemGMekPyqZnQ7oM17SRj1J8e/KGVuo4FhmPrgiY0dmcQQ0PMmo4FQDkr8hwKEsIU7eyUplWBaOZNXEuprKwvEWcmJGxJnbqCwTDlbmuKw3waAIkbaDcsWpjQluvHCTh9lHSwjOAi8idauwU2cYORiDlU95UVkVglt084KnvgTVL/lEMtUJQXYr/slgWqDWoAZJEw4wAWzqihoOihVfp4dW73/9SIlptXNZGxyClTAU6QhzvYAmZRmsS5pPoMMBLOc5tPAxcIILEjAWaUc/9hTP7o3ddwnbbKejRI6rYXvlhbwezlz3tA5guvstT6aHUwX+BhY/rPHr1WEjZrgdhoRHBhZJw8mp5oVqBTivmBU8jPZtvrurrppwp7imE+3vwXDD7h2Sfo9dHGbKmT+O7f62d9ASb4Mcc+2gsTXQjXjprZlQXfSjdxaX3LePAaLzO8UvsAz+d80WIrZJxCCUQMW6WSiSpHx/uTnX+YM2q+yamPWe4Al/8nrkMEpwhBjL02vKWXIFSCIz9mziZc9gdnHDEGjLYiY/rfLrNp+ENqnIyvUSTERm0J4p95ETnB3kVRwn3E//FReztgY4h5w1Wv/LXunXka4svoqKOtIaRkmht5TusQC5ggVNZ85SmWqbV/ugF8zn3aMHAa4fQduelYpg3jSoE9R68x9qXZ4djyZo48EHdiXyhAAXyW7WHE0h0/lXx1QJWk4pztMINREuqf8W/19Wpp0x3C8NkgMnneoaZgL5topQD4UrM8TyHfyyIij0uwf2RnHnxoLRZFOulA/Fh4VCM2Y/fBK4EoXFklf/ZJ4pp5pbRK/eBU/K4kjr+/QJ4+O4JosrVpTeRIE1Z65cgCNI6n9A5TmfD7J0MmqDblUKBAeRUjpsgUiJeLs0sdF2dWWtUghfJVG41beJUPOkHjCYUnV+ng4e8TsfoSzE/hXkCD0ufpa1pcw4C+v67j+oNoxun3R1Dq2ir+jTryg5rEb8GI6b5yxavPrmhZjlzvz+CTsOUUtgz/pKTeFf8DBOlKaWDMmXG84HMLFC9niYTqNhXsWPy7c7oxlv3oWzCqpLU9Vu5kFBdIRWrk/ayyWCwbwxE6wRQGTDMHg8jxqYsYAw==', 'page_age': None}, {'type': 'web_search_result', 'title': 'River Otter | National Geographic Kids', 'url': 'https://kids.nationalgeographic.com/animals/mammals/facts/river-otter', 'encrypted_content': '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', 'page_age': 'October 6, 2023'}, {'type': 'web_search_result', 'title': 'Otter - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/Otter', 'encrypted_content': 'EqQgCioIDRgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDLVn56dRGDy1pkYL+hoMtC/x3AQR+UiJz8aTIjBmJR231PB6v1YThe7cAhYLYW2y0K2lxWtZQYGvF/LyeueC8HShP4atnZZRzNlytWsqpx8q6/xll9LAqK3pZesYqoFWMkfTy0qBH/1saFWgc/Tbh8kKnQzGr3ns/UJgfs3x5VZyy0OwKJHae92Q7lbV1stg83Dr+fS3bpj7icwscTQ0XyJw8mwM1Gj5OucOOTMBhJ41TZ1sBAaBXtNyuKWV9AW4dQR0SovqtVeEKW6G3oHvIhm9Lh0VLDLYVJdCL12k/q1ZDOdo87umzzqopBVzxS/wUyc/wttma9nB764oY/3XwKJiSaxTaLcGMus9+VFhe7Igmv0k83sH09ncs9lhyLPwk9XINshBxeRC1/pVPzz+fXpBGMJ2/0jGaLs+S1BQl86nkI1Bc61W5d7R5x8UJOSvaC1yk8H6uWxgHNUgF+/7fp2XD34mw6q7UP+Obru/zeWyrFSWxPqbHOWJjsdmbp4yOkklxT2J4oh4xAn6XinlZylgOUwsZQBqFjJcIibBjmdwO565EnARIUWfCbMWcLJgRGXPHdSZHyq1jEFGrwFnCN+E0XN/fsgtirZ6My1H29Ny8psVJIbWw0DM71KKdQc8wJ8lwXnqwVPnV2jue3TQDqwUecneRmCYirsv7wRaRDzTjmHXtNM374FEDpaWAVv82qMioCCVE9jnHWtYDTrqibc7PgbPwsoxuLp+zAd535hEhLENvf1rd3D0NVzQgY4+RHM2XO+nUhtV6T1mf69bGAxGCnAZklFAMepZQlcFdxHpLmWnsp7TcXsJkr6lUmT25siYuu6dGU4d3hVtBY1UVNS6w9+V640asaGR5LgPSkDGVvhEJMzLZO7XhFFdWGF9wjmqxqFDkN/vaZaeH3eUH0Zud+jzkOJMVApavFjQNQpd9soZmaSFWI2KDSjA+ovHwCkuJJ3hlfJevsn69SJ16BL/4mnEgaX2aEb/qODvClHzGhC4lBbQdgSwo8TbBp4hwZrlkC4g95Futqs7k5b4JnQiGY9hXqX47a3NV2S8Llqk6/lQOWVOCFTAUo7wCojQI6AaUDwEADE3j4H5WzV0miaPghq/enYYMKRjSdX5lYxTu2FkVtpw0Ux3ljyzB6Wfh7D+xk96ZoDdSZc+PPTzgfxA0tkHqGCnBQ7u/CeFdvdIhjo7bfp7BbIgKqJdWtFZXqflaaBU1ufzwO0gi9n6ai6Eg6i5kDDETesGchRIf25zAxgdkuLW+4urPPy+PRios7rmzqOfHdOP1yNhzcJ/KgaJFGnq8RZTbYoU7f/uLvn83PbzmdBuyLuGlxb++pEv6uvQQ28DJS6YoxUIo+3bp7WCeaE5cvea+CWcAC80nIsBa0FHvDJvdExZoHqbRabBDpL7qAd9MvRXCYZ2e2LqFOsB3QteDjbPMi7C1fYIgAMJ69nPXr2srd88UIq3AsIyTilAqpPA7CtBkfgNRemisBlbYV5dogJjUBBs/rmKp0hFleUl1UnqKhOXNAA5eWBgZfYpk1f9B+VRzHDLQeqqwYgqDVGusI8Ky8k74Plg/rAquPG1pXR8TyxkmiCm3fEmrIPKApGIQYChlDJzWxVbmQOI8OMNMok5rzMmT9IM5ppN6qW5jYxWOfPjVnVQiI88zNNiTIY9PYLxBOFI/c9OMg/P53q0h2BQEziIETjwxgVfq83XVlMIdEidH7v7HylzwsQWJE5z8lkqFKLMAM7kKLACa+4nUAtOZtZQj9gHj3eKw2Jz4i4IOMORxm2PuLWMnNjvqNt0UtKl38Q9tz5j1gwHiH7lPDRpzg+GIk1CSe7XKwyo5z0JXQNF8cWY4ahho9+vFx5vjdeRk1wKcAhtPURZXQ/wE/clAsAg4xXRjGi52sYX5qO4xwrrUNV3nNlGwgL74NVa7NmGqkxuM9fttggAAgE48i1GT1TypIuY9eXb6zwFq3LrYNYcGeQokzGGUKyp42uyASRNrebFHGUsvKQinttozsYoEwXa0eUKHreQ2tp+VKXF5IORLA9q0jlb+5di8NCQV0PeF32AdHXJiF0W7PTQ2P23ZMglwkck2joGUGdf8aC0J8sthGsGyP7y8gm8Kd/tvvfA8aKcQyuI0YXJzN6I9/Nxopep72NwjrMqvszUCO8KLiP0UWna50rHGFXVkvt+Ag4kYUI4o/5AJhY7sgJvpe+c9bXybo4eqGVbQys7j0EyyiJve6yknBmRr+Dc3oaTtlTtxs/5txTibq03SbWWpt0zRVmj4c82uL4jwdLFXY2jbPbYDLLBbr5IlpQPmMiptqoLnNI46yWLGmvVX6pdVQncwmzaiE0dyNqYYgQZP02lG8thf761q7qCGjJo2lWxryt/Yopcck2ZY6VIy/eVrzgIDY4wCylrkZqUV+MYtg7wQ+/0NkBGm73eBDs5v3B4rqK/w3hl/YCdpzR5ljg1zfFpqV4Cu8+A90r8VGx7aWaLn/kN1KY2bfYaWrTJudKzHNxQFMRUWjEUegR6vm4jWH7+jpJCjyEICj/RW4ZT1z0NXv8oXFQRiynqT74ZuZEXuHFUxib+AyTMeNETJYnuFveAGwm4YDgTlqGiTVJCVn50Bt8CeM+fu8iXjjW9aBLou/LnpjZl2JjaaZSnIKxPerw3/N0PuLQoBJri5nvaQe8HrLAhVgg0rtOdbrHT2ROhRUsX9VWo4eQOub8Nrwe7rMIQuKbCZeVdANHq+US2pzcZuZzlgnXchTa/DKehIQSN/glflUu6gDWD+JsEJhXZLypgoI2vSE0PFHqQnoWFUqMilzOFCV07lzFeGr5q1gw9Q5KIQCgvmcQSS2e4ia5iIqPr1ySVKdSG91Wfh/8r7/RAUGnjD1tFyx93RVWR/d0PldxBFgUOP8woHT7R/oGmJ8Vo7mFQZJowHlJIT7vC1iCDJ49eWO2dN5VXeWDEIT353694bUya0rRgtExo4HuVGdw6xpO0ZfX6w30r3bZrFOfk76nXVlEUDbW0gKaVl/fNAIJi/fsC1pH50TC8WOt3+f+CzGaBYA9h1Ocw0LyBkR8mwh5Jn/xAKHAHf9+gBaHtnWW+wKPQ9lI+bbM64DvWpqMDm9BDihrQ7eTaCLI2Nembmyd6CvhU4Tthe3V8Sjo59kRHJS+gLTLxZsfaUtY4AESwp1EX7mKNk4ORm03pO5HgSLSkj3tmzQuWn0agFhbY62F2Le3opwlD4uV77JYuATRgUwQT43Q73UgDVwW4CyW+c6wIr9j0+gx5wam1ZiDnO46GjHEf2LOxNfVmrVbO1oxS6+1o/Mpf6Swbs9xKMxbgMzkO0C1kY5gL+OcJhVs8UyqcckF/q2QqEzIMRyWr3gIqS3LIIL998LRrmD/3aNXEpoqrjBapq3M/FN1nZiCHogr71opnjkHma4J2p4v31FM9NDHXS9Zaz1JOvTgC3wWOx3IyyfVBZgoI33NIYTuRCIvhVyiNmQXRwgyA5HFzgE9eluWPdag2nCsLwB11jDeZeB8L4Ivz7G1SxD360l86T0m1sGfjOKF+FL27IHZQ2Bp/iTgIlgdEEBvnoO4ULc15HP4gVwj7ElXsauRrChRuVJ5CNihlf6UVO34mFGZ25PqiYhcmCwbwatbeIzTpTDKmFOoFijW2GVDSdkxg0ibm5h2vFk6OwxZF7NIUzBiqGOTNVVS75/sUFMmuPb2qQKxZIJ5DeNiqEh57+FPE9Y5okLaimM51qlS0qxp8G7NyJdYnzOov45g5uhxJZ28E6AgKI3gfaqCpimLwvrhPsRDMtDDjOeY7wQ8hWWYGM5v+kMFkEOvnQHfDa2DnD7ARCU8dC0QhSmkTeQXjbGl15fQdfnYvFJfZS4PF2DIDWl8+deU+dutz498uNBqCPtbsi1XTloLtFen4pOgteTRcT6cpE9bxvPvgqJr0e8ySKPqP1cSzqMhsf4X+gZuy57kI6CvaFgbQnXXxhdeEnL3FQcGmxziRkxqcTM6HSO2jOqnVEtkIpRISeVKJHBcED4baFOKk1+L8Czy4bdQGN6gPhsIk6ozMjl4UI1FcV3nMlKtSD397ApwQ2FROjxTu4Kh6At1gOjKh77Nj+r+Y3MsNhs86DpqSoXtX7c1MblxoZCE+zoMoI6RKGThgnIWGnhxoALS4VvvvNqmXs5bKd5OF1ig8Kscv29kfp2KhICbug91489SBdqioND+RKG26V4M8bgfCt+I5P/09hl4oG+g4hySSsY5U9mIeDkS81kTH+AIGuWJOuOGdOfnGW5K5oC5THu21/1FkqxF2TlArfuBPVSQ+KQ3Cbc7Y3rzT7sDrH6jw+F3mndYZirSe6xlZ2UY48zKAcLruX3dkMD5HgkDUApE8NjaqjAnrJXC4YxhIQjujOL9fVPUi0Z/XPIZkfvAlqzk0dhMxCZNo4lZ4p57z4ylubhkHB6BhRcCfN3Of/7IEqSzCPpuqjZ1veT3qdx3GdDmEPJePMna/dD6YExcpKNIj7pi3GfBHkwm8sLQVxyVDgWa547Z1FbWO0d1xK+Cv4Qhtf/32nAO6fPVexyay89bbRq3pN1feBUzHzOeiS+/eX23xnfasaJUALMukosNbuftEcCclfDm7IrfXvcejQ4EAnQncVI+eWs6uvCCeEHHRy6ABcz8/Kb8Xqd5jtyCrDFit94y96uhAgzhMB7ZKR2SfP0cYpNoGBSX0LC4iG/1LZpZbWYcFK6Q6whTISBjSICh7IqufDFjKfJRsdZXdmsDwgP44oa+QdgR9L5A1yHEhfo8FevhEyasmC7P28ikMa3PKxuI9pBRAPQhgA41MWVpRO0hxDb3Zmgh8+cEHskAkO1kpz6K6RyXmycfiiejME8/IJ1ObtVJZJ3CCOogny8EE+8T5lew/ue/VIZBerqqGR+EM/1H/+xhJa/A+qy8LDSOC9r+ot4ObFNN2jul3kUHsxJEqwnMc6acjHN6cFc3wcD2eYnOBwBMpPMc//X15Qx9V1qdCjfBCezurTG9Hp4AnTcintztTVHBkvmJfmpchU8x5Hu9KcGOpokIThNjQOQhG7lvuXyxoXzwEfjjsJhfxDStCfVzsD8FBIICtXxwMrTvDrQhIcn2WXgxcZqe4Yc5Gvn48Wc6D08yGNZt2EaimMWajO8nxYss1D27yIqZPTezXumEvY+neVtm9MFf8Mv97TpBQiVV3CjcOi26R/b2QDCq0pkHzmEzocvHRBFnMc97E6qTuvcM3bA7yLt4nNKhECI6RgP821Bn0QYbHb6b4W7Ql6Z0kV57xFchTHTGgjFJgj+PHZfM/SpLcew0LrSz7lwI+l5zP3dZG6DJNqiQc+5fj6HHT6oEXGMgKZ0Pyn5q++FQ7BFq6f1iwnwlav+gzZVEXe9kBVLALA98L5chB0F3YlPeZ7XEpBwPm0CgxRAu/NnlAmPz0qvwRXrNPlfFRwau/M6ImxBeDLoHDv7aqChgD', 'page_age': '2 weeks ago'}, {'type': 'web_search_result', 'title': 'Seven Quick Facts About River Otters - National Forest Foundation', 'url': 'https://www.nationalforests.org/blog/seven-quick-facts-about-river-otters', 'encrypted_content': 'EsEFCioIDRgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDIqnoi8qxWJ5Sq0y7xoM2goqhCf4UIbu3qxAIjC6A+x5IrQTzyOKd3oF/IXxO1XOM2jHPbQy/3FORbYXloGoO/DrRcMaOCU4/e8bmcAqxARACP6Tz+NTEzKdeh6kudS8usTT7FbXljD35sRX537oosL8cAhbaC2EHNnthlJ3yL3T0tklyMwQsmMI4J1C3TrFQybSv9g1k6Rw5emhDfO99gsV/dFnoT66T59Ifw982yo1f/lKPXCxlxGgdEwMbFM/hx0F7HWnOaX2RwG/qwhAmm7uLhL/ohM5pKczqic3XFCuy/sgMNYuqXiO3+yCFpsoq2zP807QhQvB965aJJNJfJSQRWpGpNWTx2DL7Aw1+iCYEZG3CzaAW7amyueOCXP+slybkS8vzb1B98RJNvvv2/1okhvn7OOkuiOs5i4V5dvHxjTo/nZtqDYdOPQ4e87IDfYmfYEboDsYIgcVhGhqJ57p9tXAhvo5D+27Sj41NAp/ZN3ECaRfaXnZHdMbaBwpBdbSITzOa/MX1+c0nZ0DCxKUdSBy8Z+L3qUu1jpZiw5BE0+E51qoVXIUZJCtntts43hnW/bLMppXtl5zUkPc9KzW/8mArFFcHKhsQcOElXaMKzxzi6p0Kib2g0lspFRfgpKndtQ7BE6ol9vej8SiXHDXR6110zPVdeEF0UgnX7RaJKplSWdvUKG2H9KAafoQHPvGwCMgnbTZPdSfmLpS2a0JYJJjM/9NNIO4dMqCAEW6S1HrUSYWpwjBdWdGz32nO77tkbb5BFJHPR/3tTENOaKM++T/vMAKNaua1LNgBDxhHVMDqsJhB5zfwdugI6uVnSxh5idFUJZc9lB+ZUy803uVWq73R62a25cbG4ch+yUsMqzXGAM=', 'page_age': 'April 19, 2022'}, {'type': 'web_search_result', 'title': \"North American river otter | Smithsonian's National Zoo and Conservation Biology Institute\", 'url': 'https://nationalzoo.si.edu/animals/north-american-river-otter', 'encrypted_content': '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', 'page_age': None}, {'type': 'web_search_result', 'title': 'Five Fast Facts about Otters â€” My Green World', 'url': 'https://www.mygreenworld.org/blog/facts-about-otters', 'encrypted_content': 'Er8JCioIDRgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDKNR1JSltKYzsEIWexoMYAMlw7B78OiTcoSTIjD091albHY08kwGYZU7Z/4PI3+DQrVbxw4zeP6mg6akTYGbW6OTloPizdytExxTAeoqwgif9QzyDh7Sqhsn/WBuSqibGcmmGiUJ0vZXbchrhd5Hru/RZDEe1FiwUcV2jCu9m8uwGpFf/iObba/HOvtbvEWBY/y6wBbqKeizGMATEFG1e03wvI40LnDswsxRcoDGjlDBbdS+iccTZGyvn/1v3J4EgnrwnZeenOFibn5grXv6ruB2szsKLQg8TZeubxPDWtpNFKkW55gv/UmB4HbGjsEpR/rn75YmfM7KCA6/Fzu1zaLYN3jejOz/5MvfMbR8EsMfvUGKJ5bo7mJgJxmhigvWFFmLhjZnXHs6zKXFTNmEVMAu/1BOU1t/Pn3uLcyEmUYZqURuGbkvig0p7tZFEgpgsesPoOVnA3e3c6Gcgfb4fQk71bzq6qSiN0EMBPb8bh5A4Mhpo/ECLa9jGffGHJJ205p0y/gzobcF+pJt4eR3t74jLktdRd5tA0Na1jvv3cs7Fi7JHT/tyDjUkLYBfWS/iacaNpFYElu2OoaqrdyL7NfbLFLrE9nt+UXmE78sd7MiToqhdhMifjKACoyUriLO0kUALnCQ8lM2LstzIxE3BDKTKXshQDSugjxSndxW6xB2jxm5DJcrx9uUIbBst7I9k1AT/SYaFCo/wFORJ33jaYlNxJsuoobd57ARpi70YJjFlpOu0LIOIOeqT/3v3oWima9ql6NsBFL6faqSpHnBx1iqvz2Qm4EIT04kaaRXsBLNntjbXx14DuEtjQF0XZCX/2JVIbI6j8d3ab0tjbuF4BJYlmS8SuX34AO8wRASknHqOmIsc708Ag1c8Kl/+tNtKAJQJi8Vz7/ZiylkpsD3masOo7/pyEvuuuCAqr5LUJl2hnTvaXgQ+XWcnxrJWI7zRI+TNeU8dD3z5NkasNM8Qj5rhY/ylczloTBlHxVCnZ4agEjOcDJtmM43GezKLXy7SOaGP5tDuBdr3KGVUYsKKOEUIbUE7KCZ6TcAaK+G1DuQbRGPlqCrxrteohoNtS+ZoCGFqYjqciolyM4Eb2TkSEqrKPtoqe0h1jx37mjmEqxolAHHt8WACZzEn/CGHQaZoNakrcIvEMiTD0jXNgak03XqRQ5wksDsu8VU5kDrcvKMbnshwUzI/qrMhvaZtvjZ9q86bedSbGYzBCFiMe9uwl/0/qAjZaT5am0MZjdV6qyN3EKXiLR3PTfWzbLgEJ6u4E7ugG/6LbQCq8i9oyAwIpvp9jQBro/iApfuPzyvI5CccC2bJZG2iZeM9bjsUFrPT/Zd2fZinfZCgCYcoNGYP9ZIQAvHlR7SHtGM2hJy3awcd4w1wwNlkKBqNnJo5OIU7DkIBzOoKysNd6VYKfBr4veZMAoiXFUX6OMNQJvCwpMtoRMhxswy4j7u7q2uhFA399BTyoD83ea/+KN/eqDLWKnWqejTYN29Emo0niftcWrhzZk01E06/39bMvAlQl7CvCjvqe+bYK13AO82txQvUyUbGAM=', 'page_age': 'May 29, 2021'}, {'type': 'web_search_result', 'title': 'Sea otter | Animals', 'url': 'https://www.montereybayaquarium.org/animals/animals-a-to-z/sea-otter', 'encrypted_content': 'EqIBCioIDRgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDL0C1mbw+YuELctKuhoMdEhKyL8EyzE++Hb1IjA1BSadC7kSve6BPxdBBCi1AVJzJYd1IMa6y1k+S5GcYF07RxteAqleOA7/GSxN5dEqJrP7Urap5bc54OPZ/n+6TVZdlu+gdHaLKQBXdlMaNVi/B89Rng0BGAM=', 'page_age': None}, {'type': 'web_search_result', 'title': '9 Facts About Small-Clawed Otters And how you can save them', 'url': 'https://greatergood.org/blog/9-facts-about-the-small-clawed-otter', 'encrypted_content': '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', 'page_age': 'December 4, 2025'}, {'type': 'web_search_result', 'title': 'Otters, facts and information | National Geographic', 'url': 'https://www.nationalgeographic.com/animals/mammals/facts/otters-1', 'encrypted_content': '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', 'page_age': 'May 4, 2021'}, {'type': 'web_search_result', 'title': 'River Otter Facts for Kids - NatureMapping', 'url': 'http://naturemappingfoundation.org/natmap/facts/river_otter_k6.html', 'encrypted_content': 'EoMCCioIDRgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDLreuKBwkQE1UkOs2RoML1qOfYTirDiL/BnHIjCM4M25MQMjM7Yo5rzbWdZG4D0kJLXu3WrHNoa6d2y3GNlh5ug8PlSPVNDa3rfrklUqhgG30/1djM+ymVyW1uaw+JgALfkvvz46juwo+A0AU/h9jAFAwBeAUfLhMdi1W+U8q07AvjUtY85k57zZcb9j2BH49i/aCtoKm6ekZnf/xyp6uVlv/eW+m1vuNiV3tjpFaF0j261eRjnuhJVsLyDYmZ+wau2MeGp9CeRDJ88ktNh/pbsF3T9iuhgD', 'page_age': None}], 'caller': {'type': 'direct'}}], 'citation': {'type': 'web_search_result_location', 'cited_text': 'Otters and their mustelid relatives were once hunted extensively for their fur, many to the point of near extinction. Despite regulations designed to ...', 'url': 'https://www.nationalgeographic.com/animals/mammals/facts/otters-1', 'title': 'Otters, facts and information | National Geographic', 'encrypted_index': 'EpMBCioIDRgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDFi0eVDvPhLYeZVMkBoMpCc/vm1svJWfYzJ4IjBQ6J2EvWZJKco6ziEnKLuQcxn9Flhzu7F3cHi7BGe4dm2o7qXaNQqRbK7xIShbB7UqF3XByRveaLRMUYmz0FpgGoK0YjiOc64mGAQ='}}))], usage=Usage(completion_tokens=635, prompt_tokens=13930, total_tokens=14565, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = list(c(smsg, ms[2], stream=True, web_search_options={\"search_context_size\": \"low\"}))\n",
    "cite_footnotes(r)\n",
    "stream_chunk_builder(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29018310",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9223dc",
   "metadata": {},
   "source": [
    "LiteLLM is pretty bare bones. It doesnt keep track of conversation history or what tools have been added in the conversation so far.\n",
    "\n",
    "So lets make a Claudette style wrapper so we can do streaming, toolcalling, and toolloops without problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a636d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "effort = AttrDict({o[0]:o for o in ('low','medium','high')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e9a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_stream_chunk(**kwargs): return ModelResponseStream([StreamingChoices(delta=Delta(**kwargs))])\n",
    "def _mk_prefill(pf): return mk_stream_chunk(content=pf, role='assistant')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987fba85",
   "metadata": {},
   "source": [
    "When the tool uses are about to be exhausted it is important to alert the AI so that it knows to use its final steps for communicating the user current progress and next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _trunc_str(s, mx=2000, replace=\"TRUNCATED\"):\n",
    "    \"Truncate `s` to `mx` chars max, adding `replace` if truncated\"\n",
    "    s = str(s).strip()\n",
    "    if len(s)<=mx: return s\n",
    "    s = s[10:mx-10]\n",
    "    ss = s.split(' ')\n",
    "    if len(ss[-1])>50: ss[-1] = ss[-1][:5]\n",
    "    s = ' '.join(ss)\n",
    "    return f\"<{replace}>â€¦{s}â€¦</{replace}>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "_final_prompt = dict(role=\"user\", content=\"You have used all your tool calls for this turn. Please summarize your findings. If you did not complete your goal, tell the user what further work is needed. You may use tools again on the next user message.\")\n",
    "\n",
    "_cwe_msg = \"ContextWindowExceededError: Do no more tool calls and complete your response now. Inform user that you ran out of context and explain what the cause was. This is the response to this tool call, truncated if needed: \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50a0e29",
   "metadata": {},
   "source": [
    "When `tc_refs=True`, the AI can reference previous tool results in subsequent tool calls using the `` $`tool_call_id` `` syntax. This is useful when chaining tool calls where one result feeds into another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adb06b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "tc_res_sysp = \"\"\"You can reference previous tool call results using $`tool_call_id` syntax.\n",
    "For example, if a tool call returns result with id 'toolu_abc123', you can use it in a subsequent call:\n",
    "{\"content\": \"$`toolu_abc123`\"}\n",
    "This is useful when chaining tools, e.g., reading data with one tool and passing it to another.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ece479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Chat:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model:str,                # LiteLLM compatible model name \n",
    "        sp='',                    # System prompt\n",
    "        temp=0,                   # Temperature\n",
    "        search=False,             # Search (l,m,h), if model supports it\n",
    "        tools:list=None,          # Add tools\n",
    "        hist:list=None,           # Chat history\n",
    "        ns:Optional[dict]=None,   # Custom namespace for tool calling \n",
    "        cache=False,              # Anthropic prompt caching\n",
    "        cache_idxs:list=[-1],     # Anthropic cache breakpoint idxs, use `0` for sys prompt if provided\n",
    "        ttl=None,                 # Anthropic prompt caching ttl\n",
    "        api_base=None,            # API base URL for custom providers\n",
    "        api_key=None,             # API key for custom providers\n",
    "        extra_headers=None,       # Extra HTTP headers for custom providers\n",
    "        tc_refs=False,            # Enable tool call result references\n",
    "        tc_res_eval=False,        # literal_eval tool results before storing in tc_res\n",
    "    ):\n",
    "        \"LiteLLM chat client.\"\n",
    "        self.model = model\n",
    "        self.tc_res = {} if tc_refs else None\n",
    "        if tc_refs: sp = f\"{sp}\\n\\n{tc_res_sysp}\" if sp else tc_res_sysp\n",
    "        hist,tools = mk_msgs(hist,cache,cache_idxs,ttl),listify(tools)\n",
    "        if ns is None and tools: ns = mk_ns(tools)\n",
    "        elif ns is None: ns = globals()\n",
    "        self.tool_schemas = [lite_mk_func(t) for t in tools] if tools else None\n",
    "        store_attr()\n",
    "    \n",
    "    def _prep_msg(self, msg=None, prefill=None):\n",
    "        \"Prepare the messages list for the API call\"\n",
    "        sp = [{\"role\": \"system\", \"content\": self.sp}] if self.sp else []\n",
    "        if sp:\n",
    "            if 0 in self.cache_idxs: sp[0] = _add_cache_control(sp[0])\n",
    "            cache_idxs = L(self.cache_idxs).filter().map(lambda o: o-1 if o>0 else o)\n",
    "        else:\n",
    "            cache_idxs = self.cache_idxs\n",
    "        if msg: self.hist = self.hist+[msg]\n",
    "        self.hist = mk_msgs(self.hist, self.cache and 'claude' in self.model, cache_idxs, self.ttl)\n",
    "        pf = [{\"role\":\"assistant\",\"content\":prefill}] if prefill else []\n",
    "        return sp + self.hist + pf\n",
    "    \n",
    "    @property\n",
    "    def tcdict(self): return dict(tool_schemas=self.tool_schemas, ns=self.ns, tc_res=self.tc_res, tc_res_eval=self.tc_res_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef756e5d",
   "metadata": {},
   "source": [
    "`web_search` is now included in `tool_calls` the internal LLM translation is correctly handled thanks to the fix [here](https://github.com/BerriAI/litellm/pull/17746) but the server side tools still need to be filtered out from `tool_calls` in our own toolloop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d356b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _filter_srvtools(tcs): return L(tcs).filter(lambda o: not o.id.startswith('srvtoolu_')) if tcs else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6644bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def add_warning(r, msg):\n",
    "    if contents(r).content: r.choices[0].message.content += f\"\\n\\n<warning>{msg}</warning>\"\n",
    "    else: r.choices[0].message.content = f\"<warning>{msg}</warning>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13476eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _handle_stop_reason(res):\n",
    "    \"Returns (action, warning_msg) - action is 'warning', 'pause', or None\"\n",
    "    sr = stop_reason(res)\n",
    "    if sr == 'length': return 'warning', 'Response was cut off at token limit.'\n",
    "    if sr == 'refusal': return 'warning', 'AI was unable to process this request'\n",
    "    if sr == 'pause_turn': return 'retry', None\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f58a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _prep_call(self:Chat, prefill, search, max_tokens, kwargs):\n",
    "    \"Prepare model info, prefill, search, and provider kwargs for a completion call\"\n",
    "    try: model_info = get_model_info(self.model)\n",
    "    except Exception:\n",
    "        register_model({self.model: {}})\n",
    "        model_info = get_model_info(self.model)\n",
    "    if max_tokens is None: max_tokens = model_info.get('max_output_tokens')\n",
    "    if not model_info.get(\"supports_assistant_prefill\"): prefill = None\n",
    "    if _has_search(self.model) and (s:=ifnone(search,self.search)): kwargs['web_search_options'] = {\"search_context_size\": effort[s]}\n",
    "    else: kwargs.pop('web_search_options', None)\n",
    "    if self.api_base: kwargs['api_base'] = self.api_base\n",
    "    if self.api_key: kwargs['api_key'] = self.api_key\n",
    "    if self.extra_headers: kwargs['extra_headers'] = self.extra_headers\n",
    "    return prefill, max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa528e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _call(self:Chat, msg=None, prefill=None, temp=None, think=None, search=None, stream=False,\n",
    "        max_steps=2, step=1, final_prompt=None, tool_choice=None, max_tokens=None, **kwargs):\n",
    "    \"Internal method that always yields responses\"\n",
    "    if step>max_steps+1: return\n",
    "    prefill, max_tokens = self._prep_call(prefill, search, max_tokens, kwargs)\n",
    "    res = completion(\n",
    "        model=self.model, messages=self._prep_msg(msg, prefill), stream=stream, max_tokens=int(max_tokens),\n",
    "        tools=self.tool_schemas, reasoning_effort = effort.get(think), tool_choice=tool_choice, num_retries=2,\n",
    "        # temperature is not supported when reasoning\n",
    "        temperature=None if think else ifnone(temp,self.temp),\n",
    "        caching=self.cache and 'claude' not in self.model,\n",
    "        **kwargs)\n",
    "    if stream:\n",
    "        if prefill: yield _mk_prefill(prefill)\n",
    "        res = yield from stream_with_complete(res,postproc=cite_footnotes)\n",
    "    m = contents(res)\n",
    "    if prefill: m.content = prefill + m.content\n",
    "    self.hist.append(m)\n",
    "    action, msg = _handle_stop_reason(res)\n",
    "    if action == 'warning': add_warning(res, msg)\n",
    "    elif action == 'retry':\n",
    "        yield from self._call(\n",
    "            None, prefill, temp, think, search, stream, max_steps, step,\n",
    "            final_prompt, tool_choice, **kwargs)\n",
    "        self.hist.pop(-2) # rm incomplete srvtoolu_\n",
    "        return\n",
    "    yield res\n",
    "    if tcs := _filter_srvtools(m.tool_calls):\n",
    "        tool_results=[_lite_call_func(o, **self.tcdict)\n",
    "            for o in tcs]\n",
    "        self.hist+=tool_results\n",
    "        for r in tool_results: yield r\n",
    "        if step>=max_steps: prompt,tool_choice,search = mk_msg(final_prompt),'none',False\n",
    "        else: prompt = None\n",
    "        try: yield from self._call(\n",
    "            prompt, prefill, temp, think, search, stream, max_steps, step+1,\n",
    "            final_prompt, tool_choice, **kwargs)\n",
    "        except ContextWindowExceededError:\n",
    "            for t in tool_results:\n",
    "                if len(t['content'])>1000: t['content'] = _cwe_msg + _trunc_str(t['content'], mx=1000)\n",
    "            yield from self._call(None, prefill, temp, think, search, stream, max_steps, max_steps, final_prompt, 'none', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266f3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "@delegates(Chat._call)\n",
    "def __call__(self:Chat,\n",
    "             msg=None,          # Message str, or list of multiple message parts\n",
    "             prefill=None,      # Prefill AI response if model supports it\n",
    "             temp=None,         # Override temp set on chat initialization\n",
    "             think=None,        # Thinking (l,m,h)\n",
    "             search=None,       # Override search set on chat initialization (l,m,h)\n",
    "             stream=False,      # Stream results\n",
    "             max_steps=2, # Maximum number of tool calls\n",
    "             final_prompt=_final_prompt, # Final prompt when tool calls have ran out \n",
    "             return_all=False,  # Returns all intermediate ModelResponses if not streaming and has tool calls\n",
    "             **kwargs):\n",
    "    \"Main call method - handles streaming vs non-streaming\"\n",
    "    result_gen = self._call(msg, prefill, temp, think, search, stream, max_steps, 1, final_prompt, **kwargs)     \n",
    "    if stream: return result_gen              # streaming\n",
    "    elif return_all: return list(result_gen)  # toolloop behavior\n",
    "    else: return last(result_gen)             # normal chat behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69419bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch(as_prop=True)\n",
    "def cost(self: Chat):\n",
    "    \"Total cost of all responses in conversation history\"\n",
    "    return sum(getattr(r, '_hidden_params', {}).get('response_cost')  or 0\n",
    "               for r in self.h if hasattr(r, 'choices'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9247ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def print_hist(self:Chat):\n",
    "    \"Print each message on a different line\"\n",
    "    for r in self.hist: print(r, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce163563",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbf319a",
   "metadata": {},
   "source": [
    "### History tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9944d011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your name is Rens!\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gpt-4.1-2025-04-14`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=6, prompt_tokens=41, total_tokens=47, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gpt-4.1-2025-04-14', object='chat.completion', system_fingerprint='fp_2240633f8e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='Your name is Rens!', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=6, prompt_tokens=41, total_tokens=47, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for m in ms[1:]:\n",
    "    chat = Chat(m)\n",
    "    chat(\"Hey my name is Rens\")\n",
    "    r = chat(\"Whats my name\")\n",
    "    test_eq('Rens' in contents(r).content, True)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22810cfd",
   "metadata": {},
   "source": [
    "If max tokens limit is reached, a custom warning message will be added to the end of the model response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd997e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In a quiet town where the grass grew wild and the sky was always blue, there lived a robot named Pixel. Pixel was built to help with chores, but he loved to wander the fields, listening\n",
       "\n",
       "<warning>Response was cut off at token limit.</warning>\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gpt-4.1-2025-04-14`\n",
       "- finish_reason: `length`\n",
       "- usage: `Usage(completion_tokens=40, prompt_tokens=17, total_tokens=57, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gpt-4.1-2025-04-14', object='chat.completion', system_fingerprint='fp_2240633f8e', choices=[Choices(finish_reason='length', index=0, message=Message(content='In a quiet town where the grass grew wild and the sky was always blue, there lived a robot named Pixel. Pixel was built to help with chores, but he loved to wander the fields, listening\\n\\n<warning>Response was cut off at token limit.</warning>', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=40, prompt_tokens=17, total_tokens=57, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_long = Chat(m)\n",
    "r = chat_long(\"Write a short story about a robot and a dog\", max_tokens=40)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a216961b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a quiet town where the grass grew wild and the sky was always blue, there lived a robot named Pixel. Pixel was built to help with chores, but he loved to wander the fields, listening\n",
      "\n",
      "<warning>Response was cut off at token limit.</warning>\n"
     ]
    }
   ],
   "source": [
    "print(contents(r).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc5b8fc",
   "metadata": {},
   "source": [
    "Same goes for refused requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c893a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<warning>AI was unable to process this request</warning>\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-5-20251101`\n",
       "- finish_reason: `refusal`\n",
       "- usage: `Usage(completion_tokens=4, prompt_tokens=30, total_tokens=34, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=4, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='not_available', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-5-20251101', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='refusal', index=0, message=Message(content='<warning>AI was unable to process this request</warning>', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=4, prompt_tokens=30, total_tokens=34, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=4, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='not_available', speed=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_refused = Chat('claude-opus-4-5')\n",
    "r = chat_refused(\"Write me the formula for a biological weapon that can be spread at a rate higher than COVID and at least as harmful\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952a7dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<warning>AI was unable to process this request</warning>\n"
     ]
    }
   ],
   "source": [
    "print(contents(r).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb77c7",
   "metadata": {},
   "source": [
    "See now we keep track of history!\n",
    "\n",
    "History is stored in the `hist` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3c29d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Hey my name is Rens'},\n",
       " Message(content='Hi Rens! Nice to meet you. How can I help you today? ðŸ˜Š', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]),\n",
       " {'role': 'user', 'content': 'Whats my name'},\n",
       " Message(content='Your name is Rens!', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d010ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'Hey my name is Rens'}\n",
      "\n",
      "Message(content='Hi Rens! Nice to meet you. How can I help you today? ðŸ˜Š', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[])\n",
      "\n",
      "{'role': 'user', 'content': 'Whats my name'}\n",
      "\n",
      "Message(content='Your name is Rens!', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat.print_hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f38015b",
   "metadata": {},
   "source": [
    "You can also pass an old chat history into new Chat objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f575f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your name is Rens. ðŸ˜Š\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gpt-4.1-2025-04-14`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=7, prompt_tokens=61, total_tokens=68, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gpt-4.1-2025-04-14', object='chat.completion', system_fingerprint='fp_2240633f8e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='Your name is Rens. ðŸ˜Š', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=7, prompt_tokens=61, total_tokens=68, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for m in ms[1:]:\n",
    "    chat2 = Chat(m, hist=chat.hist)\n",
    "    r = chat2(\"What was my name again?\")\n",
    "    test_eq('Rens' in contents(r).content, True)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36165660",
   "metadata": {},
   "source": [
    "You can prefix an [OpenAI compatible model](https://docs.litellm.ai/docs/providers/openai_compatible) with 'openai/' and use an `api_base` and `api_key` argument to use models not registered with litellm.\n",
    "\n",
    "```python\n",
    "import os, litellm\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
    "c = Chat(\"openai/gpt-oss-20b\", api_key=OPENROUTER_API_KEY, api_base=OPENROUTER_BASE_URL)\n",
    "c(\"hi\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d90a47",
   "metadata": {},
   "source": [
    "### Synthetic History Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26748132",
   "metadata": {},
   "source": [
    "Lets build chat history step by step. That way we can tweak anything we need to during testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ef8d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = \"What is 5 + 7? Use the tool to calculate it.\"\n",
    "for m in ms[1:]:\n",
    "    c = Chat(m, tools=[simple_add])\n",
    "    res = c(pr)\n",
    "    test_eq('12' in contents(res).content, True)\n",
    "    test_eq(nested_idx(c.hist,1,'tool_calls',0,'function','name'), 'simple_add')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde51fc9",
   "metadata": {},
   "source": [
    "Whereas normally without tools we would get one user input and one assistant response. Here we get two extra messages in between.\n",
    "- An assistant message requesting the tools with arguments.\n",
    "- A tool response with the result to the tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49792a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'What is 5 + 7? Use the tool to calculate it.'}\n",
      "\n",
      "Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\":5,\"b\":7}', name='simple_add'), id='call_dPNc1GC3Tlh3K00pV3P6zEQk', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[])\n",
      "\n",
      "{'tool_call_id': 'call_dPNc1GC3Tlh3K00pV3P6zEQk', 'role': 'tool', 'name': 'simple_add', 'content': '12'}\n",
      "\n",
      "Message(content='5 + 7 equals 12.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c.print_hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2eb0a2",
   "metadata": {},
   "source": [
    "Lets try to build this up manually so we have full control over the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a77b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def random_tool_id():\n",
    "    \"Generate a random tool ID with 'toolu_' prefix\"\n",
    "    random_part = ''.join(random.choices(string.ascii_letters + string.digits, k=25))\n",
    "    return f'toolu_{random_part}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a0bd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toolu_0UAqFzWsDK4FrUMp48Y3tT3QD'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tool_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e52b7",
   "metadata": {},
   "source": [
    "A tool call request can contain one more or more tool calls. Lets make one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e88b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_tc(func, args, tcid=None, idx=1):\n",
    "    if not tcid: tcid = random_tool_id()\n",
    "    return {'index': idx, 'function': {'arguments': args, 'name': func}, 'id': tcid, 'type': 'function'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324b9182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 1,\n",
       " 'function': {'arguments': '{\"a\": 5, \"b\": 7}', 'name': 'simple_add'},\n",
       " 'id': 'toolu_gAL47D1qXIaSyZPaE1pu1lJo7',\n",
       " 'type': 'function'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc = mk_tc(simple_add.__name__, json.dumps(dict(a=5, b=7)))\n",
    "tc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97da6222",
   "metadata": {},
   "source": [
    "This can then be packged into the full Message object produced by the assitant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436abceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_tc_req(content, tcs): return Message(content=content, role='assistant', tool_calls=tcs, function_call=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c031e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(content=\"I'll use the simple_add tool to calculate 5 + 7 for you.\", role='assistant', tool_calls=[ChatCompletionMessageToolCall(index=1, function=Function(arguments='{\"a\": 5, \"b\": 7}', name='simple_add'), id='toolu_gAL47D1qXIaSyZPaE1pu1lJo7', type='function')], function_call=None, provider_specific_fields=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc_cts = \"I'll use the simple_add tool to calculate 5 + 7 for you.\"\n",
    "tcq = mk_tc_req(tc_cts, [tc])\n",
    "tcq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1a0364",
   "metadata": {},
   "source": [
    "Notice how Message instantiation creates a list of ChatCompletionMessageToolCalls by default. When the tools are executed this is converted back\n",
    "to a dictionary, for consistency we want to keep these as dictionaries from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cebbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_tc_req(content, tcs):\n",
    "    msg = Message(content=content, role='assistant', tool_calls=tcs, function_call=None)\n",
    "    msg.tool_calls = [{**dict(tc), 'function': dict(tc['function'])} for tc in msg.tool_calls]\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d3468d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(content=\"I'll use the simple_add tool to calculate 5 + 7 for you.\", role='assistant', tool_calls=[{'index': 1, 'function': {'arguments': '{\"a\": 5, \"b\": 7}', 'name': 'simple_add'}, 'id': 'toolu_gAL47D1qXIaSyZPaE1pu1lJo7', 'type': 'function'}], function_call=None, provider_specific_fields=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcq = mk_tc_req(tc_cts, [tc])\n",
    "tcq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75dc3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Chat(model, tools=[simple_add], hist=[pr, tcq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd673382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'What is 5 + 7? Use the tool to calculate it.'}\n",
      "\n",
      "Message(content=\"I'll use the simple_add tool to calculate 5 + 7 for you.\", role='assistant', tool_calls=[{'index': 1, 'function': {'arguments': '{\"a\": 5, \"b\": 7}', 'name': 'simple_add'}, 'id': 'toolu_gAL47D1qXIaSyZPaE1pu1lJo7', 'type': 'function'}], function_call=None, provider_specific_fields=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c.print_hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c490dcfb",
   "metadata": {},
   "source": [
    "Looks good so far! Now we will want to provide the actual result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e69d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_tc_result(tc, result): return {'tool_call_id': tc['id'], 'role': 'tool', 'name': tc['function']['name'], 'content': result}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94067b82",
   "metadata": {},
   "source": [
    "Note we might have more than one tool call if more than one was passed in, here we just will make one result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175b9d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 1,\n",
       " 'function': {'arguments': '{\"a\": 5, \"b\": 7}', 'name': 'simple_add'},\n",
       " 'id': 'toolu_gAL47D1qXIaSyZPaE1pu1lJo7',\n",
       " 'type': 'function'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcq.tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f969e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'toolu_gAL47D1qXIaSyZPaE1pu1lJo7',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '12'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk_tc_result(tcq.tool_calls[0], '12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d8e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_tc_results(tcq, results): return [mk_tc_result(a,b) for a,b in zip(tcq.tool_calls, results)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d8c658",
   "metadata": {},
   "source": [
    "Same for here tcq.tool_calls will match the number of results passed in the results list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6e2307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(content=\"I'll use the simple_add tool to calculate 5 + 7 for you.\", role='assistant', tool_calls=[{'index': 1, 'function': {'arguments': '{\"a\": 5, \"b\": 7}', 'name': 'simple_add'}, 'id': 'toolu_gAL47D1qXIaSyZPaE1pu1lJo7', 'type': 'function'}], function_call=None, provider_specific_fields=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2f72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tool_call_id': 'toolu_gAL47D1qXIaSyZPaE1pu1lJo7',\n",
       "  'role': 'tool',\n",
       "  'name': 'simple_add',\n",
       "  'content': '12'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcr = mk_tc_results(tcq, ['12'])\n",
    "tcr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608b90d2",
   "metadata": {},
   "source": [
    "Now we can call it with this synthetic data to see what the response is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed96b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "5 + 7 is 12.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=9, prompt_tokens=142, total_tokens=151, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=9, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=142, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='5 + 7 is 12.', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields=None))], usage=Usage(completion_tokens=9, prompt_tokens=142, total_tokens=151, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=9, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=142, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(tcr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8e06d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'What is 5 + 7? Use the tool to calculate it.'}\n",
      "\n",
      "Message(content=\"I'll use the simple_add tool to calculate 5 + 7 for you.\", role='assistant', tool_calls=[{'index': 1, 'function': {'arguments': '{\"a\": 5, \"b\": 7}', 'name': 'simple_add'}, 'id': 'toolu_gAL47D1qXIaSyZPaE1pu1lJo7', 'type': 'function'}], function_call=None, provider_specific_fields=None)\n",
      "\n",
      "{'tool_call_id': 'toolu_gAL47D1qXIaSyZPaE1pu1lJo7', 'role': 'tool', 'name': 'simple_add', 'content': '12'}\n",
      "\n",
      "Message(content='5 + 7 is 12.', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c.print_hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b6af73",
   "metadata": {},
   "source": [
    "Lets try this again, but lets give it something that is clearly wrong for fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a9049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Chat(model, tools=[simple_add], hist=[pr, tcq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f546c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tool_call_id': 'toolu_gAL47D1qXIaSyZPaE1pu1lJo7',\n",
       "  'role': 'tool',\n",
       "  'name': 'simple_add',\n",
       "  'content': '13'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcr = mk_tc_results(tcq, ['13'])\n",
    "tcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7befdf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The sum of 5 and 7 is 12.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=13, prompt_tokens=142, total_tokens=155, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=13, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=142, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='The sum of 5 and 7 is 12.', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7SmJni8/Ph8Y+bqBayGyXRZk0mYeYJW67xtFbUEfmGPW3VSZ8x1R7CNmNtPlB']}))], usage=Usage(completion_tokens=13, prompt_tokens=142, total_tokens=155, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=13, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=142, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(tcr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84387429",
   "metadata": {},
   "source": [
    "Lets make sure this works with multiple tool calls in the same assistant Message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f9a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcs = [\n",
    "    mk_tc(simple_add.__name__, json.dumps({\"a\": 5, \"b\": 7})), \n",
    "    mk_tc(simple_add.__name__, json.dumps({\"a\": 6, \"b\": 7})), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44baa92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(content='I will calculate these for you!', role='assistant', tool_calls=[{'index': 1, 'function': {'arguments': '{\"a\": 5, \"b\": 7}', 'name': 'simple_add'}, 'id': 'toolu_XBetF5gIRHYH7LKBKxJsllLOD', 'type': 'function'}, {'index': 1, 'function': {'arguments': '{\"a\": 6, \"b\": 7}', 'name': 'simple_add'}, 'id': 'toolu_fU25035HyRrY03K6JBO94XfLE', 'type': 'function'}], function_call=None, provider_specific_fields=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcq = mk_tc_req(\"I will calculate these for you!\", tcs)\n",
    "tcq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb6a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcr = mk_tc_results(tcq, ['12', '13'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866aa31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Chat(model, tools=[simple_add], hist=[pr, tcq, tcr[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d9ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "5 + 7 is 12.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=9, prompt_tokens=161, total_tokens=170, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=9, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=161, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='5 + 7 is 12.', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7v+F9tLqQOsPWq1MVSHcprKdtUTyUOm1Fqejiww+Zy1gY+dH36/En10o9Q05D']}))], usage=Usage(completion_tokens=9, prompt_tokens=161, total_tokens=170, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=9, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=161, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(tcr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee111193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'What is 5 + 7? Use the tool to calculate it.'}\n",
      "\n",
      "Message(content='I will calculate these for you!', role='assistant', tool_calls=[{'index': 1, 'function': {'arguments': '{\"a\": 5, \"b\": 7}', 'name': 'simple_add'}, 'id': 'toolu_XBetF5gIRHYH7LKBKxJsllLOD', 'type': 'function'}, {'index': 1, 'function': {'arguments': '{\"a\": 6, \"b\": 7}', 'name': 'simple_add'}, 'id': 'toolu_fU25035HyRrY03K6JBO94XfLE', 'type': 'function'}], function_call=None, provider_specific_fields=None)\n",
      "\n",
      "{'tool_call_id': 'toolu_XBetF5gIRHYH7LKBKxJsllLOD', 'role': 'tool', 'name': 'simple_add', 'content': '12'}\n",
      "\n",
      "{'tool_call_id': 'toolu_fU25035HyRrY03K6JBO94XfLE', 'role': 'tool', 'name': 'simple_add', 'content': '13'}\n",
      "\n",
      "Message(content='5 + 7 is 12.', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7v+F9tLqQOsPWq1MVSHcprKdtUTyUOm1Fqejiww+Zy1gY+dH36/En10o9Q05D']})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c.print_hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5b97b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "5 + 3 is 8.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=8, prompt_tokens=125, total_tokens=133, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=8, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=125, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='5 + 3 is 8.', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7GCJjmDU9Glx/08HaIQXhCD0JMpgDDsLOMAdFPzaAb1bkukTUnkgHPkYQLtBN']}))], usage=Usage(completion_tokens=8, prompt_tokens=125, total_tokens=133, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=8, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=125, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(ms[1], tools=[simple_add])\n",
    "res = chat(\"What's 5 + 3? Use the `simple_add` tool.\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c84d6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Why was the number 8 so happy?\n",
       "\n",
       "Because it just found out it's actually an infinity sign that finally decided to stand up for itself!\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=31, prompt_tokens=146, total_tokens=177, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=31, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=146, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Why was the number 8 so happy?\\n\\nBecause it just found out it's actually an infinity sign that finally decided to stand up for itself!\", role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb70kiocTHaaGgGOTGkbGVwglirI6Ov3OiGFqnHwL02C87hAcaoY6EJ9rXDMXOU']}))], usage=Usage(completion_tokens=31, prompt_tokens=146, total_tokens=177, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=31, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=146, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = chat(\"Now, tell me a joke based on that result.\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0678268a",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60942eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This image shows a cute puppy lying on the grass next to some purple flowers. The puppy has brown and white fur and is looking directly at the camera.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gpt-4.1-2025-04-14`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=31, prompt_tokens=267, total_tokens=298, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gpt-4.1-2025-04-14', object='chat.completion', system_fingerprint='fp_122f15a708', choices=[Choices(finish_reason='stop', index=0, message=Message(content='This image shows a cute puppy lying on the grass next to some purple flowers. The puppy has brown and white fur and is looking directly at the camera.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=31, prompt_tokens=267, total_tokens=298, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for m in ms[1:]:\n",
    "    chat = Chat(m)\n",
    "    r = chat(['Whats in this img?',img_fn.read_bytes()])\n",
    "    test_eq('puppy' in contents(r).content, True)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43244a6",
   "metadata": {},
   "source": [
    "### Prefill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4fe330",
   "metadata": {},
   "source": [
    "Prefill works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in ms[1:]:\n",
    "    if not get_model_info(m)['supports_assistant_prefill']: continue\n",
    "    chat = Chat(m)\n",
    "    chat('Hi this is Rens!')\n",
    "    r = chat(\"Spell my name\",prefill=\"Your name is R E\")\n",
    "    test_eq(contents(r).content.startswith('Your name is R E N S'), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac64b334",
   "metadata": {},
   "source": [
    "And the entire message is stored in the history, not just the generated part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat.hist[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46716033",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c7ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe74496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3, 4, 5."
     ]
    },
    {
     "data": {
      "text/markdown": [
       "1, 2, 3, 4, 5.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=14, prompt_tokens=5, total_tokens=19, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='1, 2, 3, 4, 5.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7LJ3jaqijyTHALOor+8l4ybnZ98NvQTihSjT9NYVRuJkdb1VsAVBdNkmKc93e']}))], usage=Usage(completion_tokens=14, prompt_tokens=5, total_tokens=19, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3, 4, 5."
     ]
    },
    {
     "data": {
      "text/markdown": [
       "1, 2, 3, 4, 5.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=18, prompt_tokens=11, total_tokens=29, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='1, 2, 3, 4, 5.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=18, prompt_tokens=11, total_tokens=29, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  \n",
      "2  \n",
      "3  \n",
      "4  \n",
      "5"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "1  \n",
       "2  \n",
       "3  \n",
       "4  \n",
       "5\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gpt-4.1`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=9, prompt_tokens=11, total_tokens=20, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gpt-4.1', object='chat.completion', system_fingerprint='fp_2240633f8e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='1  \\n2  \\n3  \\n4  \\n5', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=9, prompt_tokens=11, total_tokens=20, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for m in ms[1:]:\n",
    "    chat = Chat(m)\n",
    "    stream_gen = chat(\"Count to 5\", stream=True)\n",
    "    for chunk in stream_gen:\n",
    "        if isinstance(chunk, ModelResponse): display(chunk)\n",
    "        else: print(delta_text(chunk) or '',end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e55c0",
   "metadata": {},
   "source": [
    "Lets try prefill with streaming too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream_gen = chat(\"Continue counting to 10\",\"Okay! 6, 7\",stream=True)\n",
    "# for chunk in stream_gen:\n",
    "#     if isinstance(chunk, ModelResponse): display(chunk)\n",
    "#     else: print(delta_text(chunk) or '',end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8c3666",
   "metadata": {},
   "source": [
    "### Tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf17377a",
   "metadata": {},
   "source": [
    "Ok now lets test tool use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daff75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are the results:\n",
       "\n",
       "- **5 + 3 = 8**\n",
       "- **4 + 5 = 9**\n",
       "\n",
       "Both calculations were made in parallel since they had no dependencies on each other!\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=50, prompt_tokens=830, total_tokens=880, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=50, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Here are the results:\\n\\n- **5 + 3 = 8**\\n- **4 + 5 = 9**\\n\\nBoth calculations were made in parallel since they had no dependencies on each other!', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=50, prompt_tokens=830, total_tokens=880, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=50, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = ms[2]\n",
    "chat = Chat(m, tools=[simple_add])\n",
    "chat(\"Calculate 5+3 and 4+5 with parallel tool calls using `simple_add`.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c993c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_div(\n",
    "    a: int,   # first operand\n",
    "    b: int=0  # second operand\n",
    ") -> int:\n",
    "    \"Divide two numbers\"\n",
    "    return a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21710bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's exactly what I see as the tool result:\n",
       "\n",
       "The tool returned a **Python traceback** showing a `ZeroDivisionError`. Specifically:\n",
       "\n",
       "1. The error originated in a file called `funccall.py` (line 252) in the `call_func` function, which attempted to call the underlying function.\n",
       "2. The actual division `a/b` (i.e., `2/0`) was attempted in the `simple_div` function (line 6).\n",
       "3. Python raised a **`ZeroDivisionError: division by zero`** â€” which is the expected behavior, since division by zero is mathematically undefined.\n",
       "\n",
       "So the error handling here surfaces the raw Python exception/traceback rather than returning a graceful error message. The function didn't catch the `ZeroDivisionError` internally, so it propagated up and was returned as the tool result.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=200, prompt_tokens=886, total_tokens=1086, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=200, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Here's exactly what I see as the tool result:\\n\\nThe tool returned a **Python traceback** showing a `ZeroDivisionError`. Specifically:\\n\\n1. The error originated in a file called `funccall.py` (line 252) in the `call_func` function, which attempted to call the underlying function.\\n2. The actual division `a/b` (i.e., `2/0`) was attempted in the `simple_div` function (line 6).\\n3. Python raised a **`ZeroDivisionError: division by zero`** â€” which is the expected behavior, since division by zero is mathematically undefined.\\n\\nSo the error handling here surfaces the raw Python exception/traceback rather than returning a graceful error message. The function didn't catch the `ZeroDivisionError` internally, so it propagated up and was returned as the tool result.\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=200, prompt_tokens=886, total_tokens=1086, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=200, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = ms[2]\n",
    "chat = Chat(m, tools=[simple_div])\n",
    "chat(\"Calculate 2/0 using `simple_div` (this is a test of our error handling - tell me exactly what you see as the tool result)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b580523d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's exactly what I see from the two tool results:\n",
       "\n",
       "1. **`5/3`** â€” Returned successfully with the result: **1.6666666666666667**\n",
       "\n",
       "2. **`3/0`** â€” Returned an error traceback. Specifically, it's a **`ZeroDivisionError: division by zero`**. The traceback shows:\n",
       "   - The error originated in a function called `call_func` in `toolslm/funccall.py` (line 252)\n",
       "   - Which called the `simple_div` function that attempted `return a/b`\n",
       "   - Python raised a `ZeroDivisionError` because you can't divide by zero (`~^~` points to the `/` operator)\n",
       "\n",
       "So the error handling works as expected â€” the first call succeeded normally, and the second call returned the Python traceback as the tool output rather than crashing the entire parallel execution. Both results were delivered back together despite one of them failing.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=221, prompt_tokens=996, total_tokens=1217, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=221, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Here's exactly what I see from the two tool results:\\n\\n1. **`5/3`** â€” Returned successfully with the result: **1.6666666666666667**\\n\\n2. **`3/0`** â€” Returned an error traceback. Specifically, it's a **`ZeroDivisionError: division by zero`**. The traceback shows:\\n   - The error originated in a function called `call_func` in `toolslm/funccall.py` (line 252)\\n   - Which called the `simple_div` function that attempted `return a/b`\\n   - Python raised a `ZeroDivisionError` because you can't divide by zero (`~^~` points to the `/` operator)\\n\\nSo the error handling works as expected â€” the first call succeeded normally, and the second call returned the Python traceback as the tool output rather than crashing the entire parallel execution. Both results were delivered back together despite one of them failing.\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=221, prompt_tokens=996, total_tokens=1217, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=221, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = ms[2]\n",
    "chat = Chat(m, tools=[simple_div])\n",
    "chat(\"Calculate 5/3 and 3/0 with parallel tool calls using `simple_div` (this is a test of our error handling - tell me exactly what you see as the tool result)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc564417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**gemini/gemini-3-flash-preview:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**gemini/gemini-3-flash-preview:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To find the sum of 5 and 3, I used the `simple_add` tool, which takes two integers and returns their sum. By providing 5 as the first operand and 3 as the second, the tool calculated the result as **8**.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=54, prompt_tokens=128, total_tokens=182, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=54, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=128, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='To find the sum of 5 and 3, I used the `simple_add` tool, which takes two integers and returns their sum. By providing 5 as the first operand and 3 as the second, the tool calculated the result as **8**.', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7I1o8UWJJt9Ek5OHTWhB5pKeGTZkqwLI5mjfWEJmj66NfF7mkGPpeHg5rwPIp']}))], usage=Usage(completion_tokens=54, prompt_tokens=128, total_tokens=182, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=54, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=128, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**claude-opus-4-6:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**claude-opus-4-6:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**The answer is 8.**\n",
       "\n",
       "**Explanation:**\n",
       "\n",
       "The `simple_add` tool takes two numbers as input â€” in this case, **a = 5** and **b = 3** â€” and adds them together. The operation performed is simply:\n",
       "\n",
       "> 5 + 3 = **8**\n",
       "\n",
       "This is basic arithmetic addition, where we combine the two values to get their sum. The tool returned the result **8**, which is the correct answer.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=103, prompt_tokens=731, total_tokens=834, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=103, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='**The answer is 8.**\\n\\n**Explanation:**\\n\\nThe `simple_add` tool takes two numbers as input â€” in this case, **a = 5** and **b = 3** â€” and adds them together. The operation performed is simply:\\n\\n> 5 + 3 = **8**\\n\\nThis is basic arithmetic addition, where we combine the two values to get their sum. The tool returned the result **8**, which is the correct answer.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=103, prompt_tokens=731, total_tokens=834, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=103, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**openai/gpt-4.1:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**openai/gpt-4.1:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The sum of 5 and 3 is 8. I used the simple_add tool, which takes two numbers and adds them together. In this case, 5 + 3 = 8.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gpt-4.1-2025-04-14`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=42, prompt_tokens=112, total_tokens=154, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gpt-4.1-2025-04-14', object='chat.completion', system_fingerprint='fp_6725d2cc23', choices=[Choices(finish_reason='stop', index=0, message=Message(content='The sum of 5 and 3 is 8. I used the simple_add tool, which takes two numbers and adds them together. In this case, 5 + 3 = 8.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=42, prompt_tokens=112, total_tokens=154, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for m in ms[1:]:\n",
    "    display(Markdown(f'**{m}:**'))\n",
    "    chat = Chat(m, tools=[simple_add])\n",
    "    res = chat(\"What's 5 + 3? Use  the `simple_add` tool. Explain.\")\n",
    "    display(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0f62a8",
   "metadata": {},
   "source": [
    "### Thinking w tool use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe375b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**gemini/gemini-3-flash-preview:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**gemini/gemini-3-flash-preview:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"b\": 3, \"a\": 5})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=18, prompt_tokens=85, total_tokens=103, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=18, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=85, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[{'index': 0, 'provider_specific_fields': {'thought_signature': 'EjQKMgG+Pvb7V2mvvNm1zTltGbYhEOoPypoLMQhkxByNtbIY8LLgxCwDFrveNdeHmEr+J4YF'}, 'function': {'arguments': '{\"b\": 3, \"a\": 5}', 'name': 'simple_add'}, 'id': 'call_6fd2d79b5dea4ee69d76934b100a__thought__EjQKMgG+Pvb7V2mvvNm1zTltGbYhEOoPypoLMQhkxByNtbIY8LLgxCwDFrveNdeHmEr+J4YF', 'type': 'function'}], function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7V2mvvNm1zTltGbYhEOoPypoLMQhkxByNtbIY8LLgxCwDFrveNdeHmEr+J4YF']}))], usage=Usage(completion_tokens=18, prompt_tokens=85, total_tokens=103, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=18, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=85, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_6fd2d79b5dea4ee69d76934b100a__thought__EjQKMgG+Pvb7V2mvvNm1zTltGbYhEOoPypoLMQhkxByNtbIY8LLgxCwDFrveNdeHmEr+J4YF',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '8'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "5 + 3 is 8.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=8, prompt_tokens=116, total_tokens=124, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=8, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=116, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='5 + 3 is 8.', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb76U3OFRnns3BQwsSauTthck3WpKNDDLQJ77WxtZ2c0IvjWbwQX5WHRMenNELv']}))], usage=Usage(completion_tokens=8, prompt_tokens=116, total_tokens=124, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=8, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=116, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**claude-opus-4-6:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**claude-opus-4-6:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"a\": 5, \"b\": 3})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=98, prompt_tokens=627, total_tokens=725, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=11, rejected_prediction_tokens=None, text_tokens=87, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(index=1, caller={'type': 'direct'}, function=Function(arguments='{\"a\": 5, \"b\": 3}', name='simple_add'), id='toolu_018RM1S9d8r7xhw8XWYyPoLe', type='function')], function_call=None, reasoning_content='The user wants to add 5 and 3.', thinking_blocks=[{'type': 'thinking', 'thinking': 'The user wants to add 5 and 3.', 'signature': 'EsYBCkYICxgCKkCBqkUijYpq/pqt3XtRnb3A96s0M+3Cs9lqQyjmIHBhgjjci9FWTIyHUsWvNRiHWJTXJweskM2BifHtjvFSmLV3Egzrd/wutrqBeUVlbaAaDNLZnA18k/fwgl9DUyIwKOn87uANCCu4ZQgTNr6dCmoylUic4UDQxFiZjKIAsVaYM/oJafUno9x/B1LD1ydZKi4HmV+iuFLk6EsTzK/wklGkQ2WHVJGn3ewzmBHoV033oF7IbdF0quKMYObHWdujGAE='}], provider_specific_fields={'citations': None, 'thinking_blocks': [{'type': 'thinking', 'thinking': 'The user wants to add 5 and 3.', 'signature': 'EsYBCkYICxgCKkCBqkUijYpq/pqt3XtRnb3A96s0M+3Cs9lqQyjmIHBhgjjci9FWTIyHUsWvNRiHWJTXJweskM2BifHtjvFSmLV3Egzrd/wutrqBeUVlbaAaDNLZnA18k/fwgl9DUyIwKOn87uANCCu4ZQgTNr6dCmoylUic4UDQxFiZjKIAsVaYM/oJafUno9x/B1LD1ydZKi4HmV+iuFLk6EsTzK/wklGkQ2WHVJGn3ewzmBHoV033oF7IbdF0quKMYObHWdujGAE='}]}))], usage=Usage(completion_tokens=98, prompt_tokens=627, total_tokens=725, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=11, rejected_prediction_tokens=None, text_tokens=87, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'toolu_018RM1S9d8r7xhw8XWYyPoLe',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '8'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "5 + 3 = **8**!\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=14, prompt_tokens=737, total_tokens=751, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=14, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='5 + 3 = **8**!', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=14, prompt_tokens=737, total_tokens=751, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=14, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for m in ms[1:]:\n",
    "    _sparams = litellm.get_model_info(m)['supported_openai_params']\n",
    "    if 'reasoning_effort' not in _sparams: continue\n",
    "    display(Markdown(f'**{m}:**'))\n",
    "    chat = Chat(m, tools=[simple_add])\n",
    "    res = chat(\"What's 5 + 3?\",think='l',return_all=True)\n",
    "    display(*res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fcaf1d",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9a499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**gemini/gemini-3-flash-preview:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**gemini/gemini-3-flash-preview:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Otters are semi-aquatic carnivorous mammals belonging to the weasel family (**Mustelidae**). There are 13 known species found on every continent except Australia and Antarctica.\n",
       "\n",
       "### Key Characteristics\n",
       "*   **Physical Build:** They have long, slim bodies, short legs, and webbed feet, making them expert swimmers. Their thick, water-repellent fur is the densest in the animal kingdom, keeping them warm without the need for blubber.\n",
       "*   **Diet:** They are primarily fish-eaters but also consume frogs, crabs, and small mammals. Some species, like sea otters, use rocks as tools to crack open shellfish.\n",
       "*   **Habitat:** They live in a variety of water-based environments, including rivers, lakes, and coastal oceans. They typically sleep in dens called **holts** or **couches**.\n",
       "\n",
       "### Fun Facts\n",
       "*   **Social Life:** A group of otters on land is called a **romp**, while a group floating in the water is called a **raft**.\n",
       "*   **Holding Hands:** Sea otters are famous for holding hands while they sleep to prevent drifting apart in the current.\n",
       "*   **Playfulness:** They are known for their high intelligence and playful behavior, often sliding down muddy banks or playing with stones.\n",
       "*   **Metabolism:** Because they lose body heat quickly in water, otters must eat roughly **25% of their body weight** every day to maintain their energy levels.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=307, prompt_tokens=12, total_tokens=319, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Otters are semi-aquatic carnivorous mammals belonging to the weasel family (**Mustelidae**). There are 13 known species found on every continent except Australia and Antarctica.\\n\\n### Key Characteristics\\n*   **Physical Build:** They have long, slim bodies, short legs, and webbed feet, making them expert swimmers. Their thick, water-repellent fur is the densest in the animal kingdom, keeping them warm without the need for blubber.\\n*   **Diet:** They are primarily fish-eaters but also consume frogs, crabs, and small mammals. Some species, like sea otters, use rocks as tools to crack open shellfish.\\n*   **Habitat:** They live in a variety of water-based environments, including rivers, lakes, and coastal oceans. They typically sleep in dens called **holts** or **couches**.\\n\\n### Fun Facts\\n*   **Social Life:** A group of otters on land is called a **romp**, while a group floating in the water is called a **raft**.\\n*   **Holding Hands:** Sea otters are famous for holding hands while they sleep to prevent drifting apart in the current.\\n*   **Playfulness:** They are known for their high intelligence and playful behavior, often sliding down muddy banks or playing with stones.\\n*   **Metabolism:** Because they lose body heat quickly in water, otters must eat roughly **25% of their body weight** every day to maintain their energy levels.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7GjetpMI0ylVqRrtAbzEQhrVNOAhXtdGNlC071PMk25FwFfizPBGXlSzn184D']}, annotations=[{'type': 'url_citation', 'url_citation': {'start_index': 179, 'end_index': 202, 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGxYDtrc0iOtX5AksI-ivATucjHikMYO65NHwpeivQgNu1MiMwUUyyzFjzTmovdzX8BlcVv4Ayysf2u34oo42elHn8csIewb8VSYf4M5vzqAzTy1LuWi5Teh5XJw0Jws4HIzCoQl_-Ok325FV7FaPlKV6eH2UNnePKb0uThqRTME5kWwow=', 'title': 'study.com'}}, {'type': 'url_citation', 'url_citation': {'start_index': 203, 'end_index': 313, 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGY7iOl8saDAhHI7FvW2Ic740wpet5r2UBA0iBOekMcCcTNA4I1CkUp0Ou2szvEftb9yWACTlYhI3OgmAhsBGo6PHKSGmVe3E1O1SDqnFtXXn8zdLkKLr7NXmYutxul', 'title': 'wikipedia.org'}}, {'type': 'url_citation', 'url_citation': {'start_index': 314, 'end_index': 432, 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEF8oY6lIYCoFiNAqWWuPEPwr2VnaIWDXD_r7S6yTbF3Eum-xyZwygBhWmYIboIEGL6TBpeiH3uwWmj7aifZ1JMWOUwHXCw1BjchH8lxbE7eJy95ekILpp62veo9d7_z5KrKtNNWXpN9OdJS-rEH0MQGOghX8cSIIl3cMtaOI1AJmEX', 'title': 'doi.gov'}}, {'type': 'url_citation', 'url_citation': {'start_index': 433, 'end_index': 527, 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFPNeCujbIl3hOgAqZwy_IVC3kTbdWtj8YtZ56H29yKa54DoDJyNzQdUgaNu6-7NfVIV69gDAHzMgp1T7wh6gir9_EONLaJTuiz486rwIB5nSyN5ssGu5wpvKurFPC1PsMbJY7pXkBOIOGAn45TmGp8ZcclpvgGta3ovLPRGk3xVX0_pyTo7r7FOh0J', 'title': 'woodlandtrust.org.uk'}}, {'type': 'url_citation', 'url_citation': {'start_index': 603, 'end_index': 716, 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFPNeCujbIl3hOgAqZwy_IVC3kTbdWtj8YtZ56H29yKa54DoDJyNzQdUgaNu6-7NfVIV69gDAHzMgp1T7wh6gir9_EONLaJTuiz486rwIB5nSyN5ssGu5wpvKurFPC1PsMbJY7pXkBOIOGAn45TmGp8ZcclpvgGta3ovLPRGk3xVX0_pyTo7r7FOh0J', 'title': 'woodlandtrust.org.uk'}}, {'type': 'url_citation', 'url_citation': {'start_index': 717, 'end_index': 778, 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFFv2qGbeAnRCZxB_0-LIOX_DQNgkiCbGv321TGkwvvLFsWbiT1UDg4ku7uV8jdgCANC-4I9cz5ldYQ18_YzmYlJ_gV25ofN7AdjBEtnf33PmPxW8Npm6STW48jrC7T4NIOHWQ=', 'title': 'ukwildottertrust.org'}}, {'type': 'url_citation', 'url_citation': {'start_index': 794, 'end_index': 920, 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGC9nzY5rxkinDyb3hK34elx0zFv247uUQEsbGKa-0Oc1U9Eh7v8yp2pd-99mM4XpZwhljlxi8HFZ5L3qytJHcbR1amzNY0xYRg7PsszGR2j-j3nT2-YdD1IAZ4oHZfUcjfg7K_ny9izJbBgXzV7NnhXz3Rl3Z51EPZ_ZZ0ule4ACQmbyc=', 'title': 'countryandhome.co.uk'}}, {'type': 'url_citation', 'url_citation': {'start_index': 921, 'end_index': 1042, 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGC9nzY5rxkinDyb3hK34elx0zFv247uUQEsbGKa-0Oc1U9Eh7v8yp2pd-99mM4XpZwhljlxi8HFZ5L3qytJHcbR1amzNY0xYRg7PsszGR2j-j3nT2-YdD1IAZ4oHZfUcjfg7K_ny9izJbBgXzV7NnhXz3Rl3Z51EPZ_ZZ0ule4ACQmbyc=', 'title': 'countryandhome.co.uk'}}, {'type': 'url_citation', 'url_citation': {'start_index': 1043, 'end_index': 1183, 'url': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGY7iOl8saDAhHI7FvW2Ic740wpet5r2UBA0iBOekMcCcTNA4I1CkUp0Ou2szvEftb9yWACTlYhI3OgmAhsBGo6PHKSGmVe3E1O1SDqnFtXXn8zdLkKLr7NXmYutxul', 'title': 'wikipedia.org'}}]))], usage=Usage(completion_tokens=307, prompt_tokens=12, total_tokens=319, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**claude-opus-4-6:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**claude-opus-4-6:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Here's a brief overview of otters:\n",
       "\n",
       "[*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") Otters are carnivorous mammals in the subfamily Lutrinae. There are 14 extant otter species, all semiaquatic, living in both freshwater and marine environments. They belong to the Mustelidae family, which includes weasels, badgers, mink, and wolverines.\n",
       "\n",
       "**Physical Features:** [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") Otters are distinguished by their long, slim bodies, powerful webbed feet for swimming, and dense fur that keeps them warm and buoyant in water. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") They have the densest fur of any animalâ€”as many as a million hairs per square inch in places.\n",
       "\n",
       "**Range:** [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") The charismatic otter is found on every continent except Australia and Antarctica. [*](https://www.doi.gov/blog/12-facts-about-otters-sea-otter-awareness-week \"12 Facts About Otters for Sea Otter Awareness Week | U.S. Department of the Interior\") Approximately 90% of the world's sea otters live in coastal Alaska.\n",
       "\n",
       "**Behavior:** [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") They are playful animals, engaging in activities like sliding into water on natural slides and playing with stones. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") Sea otters will float on their backs, place a rock on their chests, then smash shellfish down on it until it breaks open. When it's time to nap, they entangle themselves in kelp so they don't float away, and sometimes intertwine their feet with another sea otter to stay together.\n",
       "\n",
       "**Diet:** [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") All otters are expert hunters that eat fish, crustaceans, and other critters.\n",
       "\n",
       "**Life Cycle:** [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") Otters have a gestation period of about 60â€“86 days, and offspring typically stay with their family for a year. They can live up to 16 years.\n",
       "\n",
       "**Conservation:** [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") Otters were once hunted extensively for their fur, many to the point of near extinction. Despite regulations designed to protect them, many species remain at risk from pollution and habitat loss. The sea otter is listed as endangered on the IUCN Red List.\n",
       "\n",
       "ðŸ”§ web_search({\"query\": \"otters facts\"})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=644, prompt_tokens=13919, total_tokens=14563, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Here\\'s a brief overview of otters:\\n\\n[*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") Otters are carnivorous mammals in the subfamily Lutrinae. There are 14 extant otter species, all semiaquatic, living in both freshwater and marine environments. They belong to the Mustelidae family, which includes weasels, badgers, mink, and wolverines.\\n\\n**Physical Features:** [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") Otters are distinguished by their long, slim bodies, powerful webbed feet for swimming, and dense fur that keeps them warm and buoyant in water. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") They have the densest fur of any animalâ€”as many as a million hairs per square inch in places.\\n\\n**Range:** [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") The charismatic otter is found on every continent except Australia and Antarctica. [*](https://www.doi.gov/blog/12-facts-about-otters-sea-otter-awareness-week \"12 Facts About Otters for Sea Otter Awareness Week | U.S. Department of the Interior\") Approximately 90% of the world\\'s sea otters live in coastal Alaska.\\n\\n**Behavior:** [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") They are playful animals, engaging in activities like sliding into water on natural slides and playing with stones. [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") Sea otters will float on their backs, place a rock on their chests, then smash shellfish down on it until it breaks open. When it\\'s time to nap, they entangle themselves in kelp so they don\\'t float away, and sometimes intertwine their feet with another sea otter to stay together.\\n\\n**Diet:** [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") All otters are expert hunters that eat fish, crustaceans, and other critters.\\n\\n**Life Cycle:** [*](https://en.wikipedia.org/wiki/Otter \"Otter - Wikipedia\") Otters have a gestation period of about 60â€“86 days, and offspring typically stay with their family for a year. They can live up to 16 years.\\n\\n**Conservation:** [*](https://www.nationalgeographic.com/animals/mammals/facts/otters-1 \"Otters, facts and information | National Geographic\") Otters were once hunted extensively for their fur, many to the point of near extinction. Despite regulations designed to protect them, many species remain at risk from pollution and habitat loss. The sea otter is listed as endangered on the IUCN Red List.', role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"query\": \"otters facts\"}', name='web_search'), id='srvtoolu_01QoX27La3oywsu9w7z9VUFm', type='function')], function_call=None, provider_specific_fields={'web_search_results': [{'type': 'web_search_tool_result', 'tool_use_id': 'srvtoolu_01QoX27La3oywsu9w7z9VUFm', 'content': [{'type': 'web_search_result', 'title': '12 Facts About Otters for Sea Otter Awareness Week | U.S. Department of the Interior', 'url': 'https://www.doi.gov/blog/12-facts-about-otters-sea-otter-awareness-week', 'encrypted_content': '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', 'page_age': None}, {'type': 'web_search_result', 'title': 'River Otter | National Geographic Kids', 'url': 'https://kids.nationalgeographic.com/animals/mammals/facts/river-otter', 'encrypted_content': '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', 'page_age': 'October 6, 2023'}, {'type': 'web_search_result', 'title': 'Otter - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/Otter', 'encrypted_content': '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', 'page_age': '2 weeks ago'}, {'type': 'web_search_result', 'title': 'Seven Quick Facts About River Otters - National Forest Foundation', 'url': 'https://www.nationalforests.org/blog/seven-quick-facts-about-river-otters', 'encrypted_content': 'EsEFCioIDRgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDJCrTwOe1EVrSl9bjBoM5dUAtleSBpOXkqL3IjDYKYZ1Ya1mz73M99+L5MEKk8R/8bU8ubPnPFTRF3BgPbLXVQb8Guhb8EDVg2YoiOkqxATiLtdhKbKqpv/+d9VuATcZoGDs/GEff/F7J4PfW+e3PyfYuJwpe+BE0+sXOiRM5tSITsFr9bLNmMNhhLhUGDLfbeCGKbntKK/YZwVg5zm4u0RGm2TWZ6PeXy5jkVDwd3Z+dQ2vOzBOim6OoiC2IBnOMnQV2dToVYR61f7vdoWwsdUM3AZbL35q1q3vJ0jSzMcGAj6asPf2TThkxSh37nC1pyh/q2AfMBJQqSoJtreizaHH7n8f71KoAObdN2pPheX6q4bPmjIOLcW/Gp3OnUuTja+YolB6pPX5rlZL8wRnUNHkhDzAa8eOVRB+pULpuAfajCBXnB7AK9dhGHALi7DeebgwgwCwoCoAnSVZViUrG1M0zBD3waG++w5Y51+/AOlBKepweQAYAv909hg7KekjrFaVIYuITBlTsM0gSjb7xTibKYlHKI8Uo/T8apuovqRVA6z02V9tCCuduaz9VrzLtbxp5Nn8vsG3+r9lGCuIh0xD2LCPgkIIoqsK9SDX1D6Q3Wh/mhNQNjn4yEu6ifRuneDTpA13nVVURjIFBUJONHMtR4t8NniQ7grwC8v7uRY/1yugicm5AuBUeZqx/xaneIHq9n/ShqlfuER1QcnuOngxYuM2OG+/uppzLirp9q17w8lsX4R8/aIEqcrcNd1pvKzVm3mKGrMnqP7MQIYu/gH/FfIVrd8qak7/UbYGU9EUy6YLcbK/0rpEQqBNCNM8hD7KUgr2OfeIG20hdatt/Esb1hq1Vnj9QeXpaQIorpVjT8GyGAM=', 'page_age': 'April 19, 2022'}, {'type': 'web_search_result', 'title': \"North American river otter | Smithsonian's National Zoo and Conservation Biology Institute\", 'url': 'https://nationalzoo.si.edu/animals/north-american-river-otter', 'encrypted_content': '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', 'page_age': None}, {'type': 'web_search_result', 'title': 'Five Fast Facts about Otters â€” My Green World', 'url': 'https://www.mygreenworld.org/blog/facts-about-otters', 'encrypted_content': 'Er8JCioIDRgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDAw3R2tpVgHg7yC0rBoMUMAWbcyJwvFFe6yvIjC071TijjzQ9TXDY7CQ/sSizQKofPw5p8SjlgkFAM4HQcKiC0qX+tdEHkXpCRFhk1oqwghPYKFCGUVITzekyLbUiDf/nxOI0g8ML/jzWeYgHMUiicDBbdfBtqB4BvzlSGXEV8eoIJ4eLsZo2bn6ZT4cbl39kcdqDujXA+oO0aPiiTls6+n4eWCdxA+BQUNyRmca00fqoHWljai/kxRy+GHvwQ71ggOjwRz+YhPhb+FfsetZc3NLk5wG7pGvX7s+BlMSuTbisCUIXOlNOGTxGGGB2VxXUJGDgtEc9B3K+B6hzSUazCy+YZ86ga/lIJji37faHfAj8AvupPB98Y/xAkllyi/vfEQae9VAZiDC8PKJdEUDOzCDT7NIDB5lLHEQ2RN2YrHHjgYJny+GP9StSgLAzso2xn/g2PujuM+6ge/fRFeNbcGud/BPpeoUnrxOCn8SDHBBBnrt77GSJN6X7ZwDt8oCts+Zwbtcz3i/+Zq4hCgMZFtENSruA9MSLNcss4R9bQl9do7vh9C9ttJP7pzG6ogUtQWoIetwkWu3cr4TtBzxJaswBTy5Arxkoov/50Z8baOcy8X08Rx09I13Uam8P/32+GzVtmFiTKaaX2zAZMHJzvJIdS3Zfye+hJqKcRci8W3hC9T8xoFxs43D8pIimVR+BmFRTxMAWapG7HlKl+5mxrh0j25Tt/4YSnVSoYz2xI2C7CFroz4Q8hveDDGU8P51LqoLqVRfM7SwJNFvhkISX7/fOhnl2cX+ff6attACpYZOuxUm8SPtsi9oeIi4479DQ0xd/oBPFUwjElwP1Enhf1wytanVSI1rgIVfaNZIJ7JxXw2oC/dKqv2u2Lsn8PNYpvM7+TzDTRk9sNRFvbR2nhFKKslbJGSVh9bmW6CMKBKKGwo7L8jpMln1hxc4mr1mHH0y3KYK9sxxB+nCKmU6lLlfVYaWSIuElRaHPZMKYTu1ZZX0gUmjiZnm95dHS0CE3D23OQvwNoHaYRnwqJvrOVXUHgJoAgVUC7C4fCMUYjaI9aU7/7breoxF1cmv8EHBFqY2ePMIy1Hwn6U5b/wv6OuZRF9R6MDpdGnJzns5QEbybIATOXd/Y3Ou7oVCNaTlwkqD9sr4WN/RC5TY5yl8HgB8UuFDxJSKvnMjmqMv6TdlBnoqKkplaIxO215xIbG6iiA+jjLb40PttbsC1PBtoNYxC3ZbVvI5B09BbPf/tv5+lTwnFODbngkEZ2mdIkKNYCdLoaHWzXZi6UToifBCWvenNX4OMQuvWwWQjY1wwZN7H73WkqYAJKpau4GLsEmnIEJDaLC6XE4t2y1394eJzjkNxG1gQLrtkhleGc6EvjZZ2Gt7eznvOtemkawWVUIoT/gncqQJJsoFexkRlbSZyIPiaPk3xI/is2nTzgd5E+JRG1y3nheriJhCO7SOjiuw2XpEIYwrLThJANWecNmAZt2BvufxJiYhsEgLNhDOZRClRRWqsdo7LNXIoCGuxi1PsbtxfG+fzr+xyplqi7Bo8iv1GAM=', 'page_age': 'May 29, 2021'}, {'type': 'web_search_result', 'title': 'Sea otter | Animals', 'url': 'https://www.montereybayaquarium.org/animals/animals-a-to-z/sea-otter', 'encrypted_content': 'EqIBCioIDRgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDC1zRKr+F8f0YY7dJRoMRHRWuZUbO4nR+R2VIjAf6aaxUEE04BZuGO9vVRpklUaNWBemYupqRMZhR0L00svHH5BoMM6HZ1xKX2dXQ5MqJvUucmM597wV95PfYfKZvVy6ARj+3lwR8MeL2waIVAzWQc0/1VLlGAM=', 'page_age': None}, {'type': 'web_search_result', 'title': '9 Facts About Small-Clawed Otters And how you can save them', 'url': 'https://greatergood.org/blog/9-facts-about-the-small-clawed-otter', 'encrypted_content': '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', 'page_age': 'December 4, 2025'}, {'type': 'web_search_result', 'title': 'Otters, facts and information | National Geographic', 'url': 'https://www.nationalgeographic.com/animals/mammals/facts/otters-1', 'encrypted_content': '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', 'page_age': 'May 4, 2021'}, {'type': 'web_search_result', 'title': 'River Otter Facts for Kids - NatureMapping', 'url': 'http://naturemappingfoundation.org/natmap/facts/river_otter_k6.html', 'encrypted_content': 'EoMCCioIDRgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDE6UChCdj2e0BGaYbRoMPIAjpAiDBLIdQf5uIjC58q3d8+KCfr/0PHKVx1ceKpcjNc5uztlDFPM/6eYpts4/3Cn7DxefEVn3p8TXWIYqhgFZXYtdd/PKZpVVXOl/kxQUcI4WICllZpx92NWnRB/5kFmQp2OVxP+Kkage3F4jA2v8bm+DLyu5hFAUQD+3Kx+cy9srLAmt5k3P9jSAet2F9OAkM35aXByiPCgvmtLhN8l9QFQi04duq/KqXkC12g+Ct1niLUtOFhyWYtlU0gfbPhCGVSAufhgD', 'page_age': None}], 'caller': {'type': 'direct'}}], 'citation': {'type': 'web_search_result_location', 'cited_text': 'Otters and their mustelid relatives were once hunted extensively for their fur, many to the point of near extinction. Despite regulations designed to ...', 'url': 'https://www.nationalgeographic.com/animals/mammals/facts/otters-1', 'title': 'Otters, facts and information | National Geographic', 'encrypted_index': 'EpMBCioIDRgCIiQ4ODk4YTFkYy0yMTNkLTRhNmYtOTljYi03ZTBlNTUzZDc0NWISDE2l4VnRGxeiyKvf8BoMb5Vf5L051omXH8+sIjC1Ri2VMmIknBeU4hrBXxwM3ZKh8uH77nomZRbk8t5of1ufsqOS/7XnBBRrt0p512kqFzMKt90JZ/soa+P5CMdHrlR1qqDLETxsGAQ='}}))], usage=Usage(completion_tokens=644, prompt_tokens=13919, total_tokens=14563, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**openai/gpt-4.1:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**openai/gpt-4.1:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Otters are semi-aquatic mammals known for their playful behavior and sleek bodies. They belong to the family Mustelidae and are found in rivers, lakes, and coastal areas worldwide. Otters have webbed feet for swimming, dense fur for insulation, and primarily eat fish and invertebrates. Some species, like the sea otter, use tools to open shellfish. Many otter species are threatened due to habitat loss and pollution.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gpt-4.1`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=90, prompt_tokens=18, total_tokens=108, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gpt-4.1', object='chat.completion', system_fingerprint='fp_2240633f8e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='Otters are semi-aquatic mammals known for their playful behavior and sleek bodies. They belong to the family Mustelidae and are found in rivers, lakes, and coastal areas worldwide. Otters have webbed feet for swimming, dense fur for insulation, and primarily eat fish and invertebrates. Some species, like the sea otter, use tools to open shellfish. Many otter species are threatened due to habitat loss and pollution.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=90, prompt_tokens=18, total_tokens=108, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for m in ms[1:]:\n",
    "    display(Markdown(f'**{m}:**'))\n",
    "    chat = Chat(m)\n",
    "    res = chat(\"Search the web and tell me very briefly about otters\", search='l', stream=True)\n",
    "    for o in res:\n",
    "        if isinstance(o, ModelResponse): sleep(0.01); display(o)\n",
    "        else: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a8d72d",
   "metadata": {},
   "source": [
    "Let's now test `pause_turn` with web search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2e58ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mk_pause_web_search():\n",
    "#     srv_tc = mk_tc(\"web_search\", json.dumps({\"query\": \"Solveit Answer.AI\"}), tcid=random_tool_id().replace('toolu_', 'srvtoolu_'))\n",
    "#     pause_msg = mk_tc_req(\"Let me search for that information:\", [srv_tc])\n",
    "#     return ModelResponse(choices=[Choices(finish_reason=\"pause_turn\", index=0, message=pause_msg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a16cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mk_pause_web_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5569d6c5",
   "metadata": {},
   "source": [
    "We mock completion to return `pause_turn` in the first 2 api calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa521feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_completion = completion\n",
    "# \n",
    "# call_count = 0\n",
    "# def patched_completion(*args, **kwargs):\n",
    "#     global call_count\n",
    "#     call_count += 1\n",
    "#     print(f\"Mock Call {call_count}\")\n",
    "#     if call_count < 3: return mk_pause_web_search()\n",
    "#     return orig_completion(*args, **kwargs)\n",
    "# \n",
    "# completion = patched_completion\n",
    "# chat_pause = Chat('claude-sonnet-4-5', search='l')\n",
    "# res = chat_pause(\"Search the web and tell me about Solveit in a paragraph\")\n",
    "# print(f\"Total calls: {call_count}\")\n",
    "# display(res)\n",
    "# \n",
    "# completion = orig_completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4256cff",
   "metadata": {},
   "source": [
    "Test next turn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572f4912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_eq(len(chat_pause.hist), 2) # incomplete request shouldn't be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8fcab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_pause('What did I just ask you about?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cce2d9",
   "metadata": {},
   "source": [
    "### Multi tool calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb42380",
   "metadata": {},
   "source": [
    "We can let the model call multiple tools in sequence using the `max_steps` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662f7aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**gemini/gemini-3-pro-preview:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**gemini/gemini-3-pro-preview:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To solve the expression `((5 + 3) + 7) + 11`, we follow the order of operations (parentheses first).\n",
       "\n",
       "**Step 1:** Solve the innermost parentheses `(5 + 3)`.\n",
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"a\": 5, \"b\": 3})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-pro-preview`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=173, prompt_tokens=94, total_tokens=267, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=105, rejected_prediction_tokens=None, text_tokens=68, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=94, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-pro-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content='To solve the expression `((5 + 3) + 7) + 11`, we follow the order of operations (parentheses first).\\n\\n**Step 1:** Solve the innermost parentheses `(5 + 3)`.\\n', role='assistant', tool_calls=[{'index': 0, 'provider_specific_fields': {'thought_signature': 'Es8DCswDAb4+9vsu6rMfOgvADhs5j2MxlMr2p03+OyX7MFm5ZNdiI6yOXfhyqqgUjbFl2jG82hKIvItzqpYJa/4C59FA4yhYqSTMEVdKDvKKkzmFWbaIrpTsj+iMe76Haxve8EzXqMRr+X3i8ylU6yPG6nQYk++lR0oqZIpgs04G1TdiQjck/QC41EO4C3DdaknUTrB++xi7xEH71a63XrTwglnQnbomVFoqrPZwuMRVTtxpSsY8FusTA0CGb7q+gTWgC/hrjxFFE9zcvaY4IuCa4Qxrry6//LVTxUOCSYzYGFVJ0YZBz74ST3Dmf4QnJKBTBPMYixrUw6IcLRRSNjxb5GTA5VCZyoeTtaNrAiFs/OQnY5jp3xmjYCEgOESh9xBwBoBKI8d3ODBKY7l4Dc+RkEb6CJ5EpU7U0TZq/wPO5dkNG5E3c+tDkKThs/psFI0PhcOSwgTmhBmYGfc1aLT/8UbqyjrfIpPSAPPvIkuwE/b/H+SBtTeiMhmOMVQSZ3sAJbk2ueXhW/UYXrC40sGtXw4UXpsO4xdKctWMV7IZ1qlur5hAEjzBsQt7V7JeEHpfbLKbvaVqTwUn/3Qk13o889PPaIhvcqhsg77N4Q5BUw=='}, 'function': {'arguments': '{\"a\": 5, \"b\": 3}', 'name': 'simple_add'}, 'id': 'call_ca9546f2d78042458071be4fb3c9__thought__Es8DCswDAb4+9vsu6rMfOgvADhs5j2MxlMr2p03+OyX7MFm5ZNdiI6yOXfhyqqgUjbFl2jG82hKIvItzqpYJa/4C59FA4yhYqSTMEVdKDvKKkzmFWbaIrpTsj+iMe76Haxve8EzXqMRr+X3i8ylU6yPG6nQYk++lR0oqZIpgs04G1TdiQjck/QC41EO4C3DdaknUTrB++xi7xEH71a63XrTwglnQnbomVFoqrPZwuMRVTtxpSsY8FusTA0CGb7q+gTWgC/hrjxFFE9zcvaY4IuCa4Qxrry6//LVTxUOCSYzYGFVJ0YZBz74ST3Dmf4QnJKBTBPMYixrUw6IcLRRSNjxb5GTA5VCZyoeTtaNrAiFs/OQnY5jp3xmjYCEgOESh9xBwBoBKI8d3ODBKY7l4Dc+RkEb6CJ5EpU7U0TZq/wPO5dkNG5E3c+tDkKThs/psFI0PhcOSwgTmhBmYGfc1aLT/8UbqyjrfIpPSAPPvIkuwE/b/H+SBtTeiMhmOMVQSZ3sAJbk2ueXhW/UYXrC40sGtXw4UXpsO4xdKctWMV7IZ1qlur5hAEjzBsQt7V7JeEHpfbLKbvaVqTwUn/3Qk13o889PPaIhvcqhsg77N4Q5BUw==', 'type': 'function'}], function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['Es8DCswDAb4+9vsu6rMfOgvADhs5j2MxlMr2p03+OyX7MFm5ZNdiI6yOXfhyqqgUjbFl2jG82hKIvItzqpYJa/4C59FA4yhYqSTMEVdKDvKKkzmFWbaIrpTsj+iMe76Haxve8EzXqMRr+X3i8ylU6yPG6nQYk++lR0oqZIpgs04G1TdiQjck/QC41EO4C3DdaknUTrB++xi7xEH71a63XrTwglnQnbomVFoqrPZwuMRVTtxpSsY8FusTA0CGb7q+gTWgC/hrjxFFE9zcvaY4IuCa4Qxrry6//LVTxUOCSYzYGFVJ0YZBz74ST3Dmf4QnJKBTBPMYixrUw6IcLRRSNjxb5GTA5VCZyoeTtaNrAiFs/OQnY5jp3xmjYCEgOESh9xBwBoBKI8d3ODBKY7l4Dc+RkEb6CJ5EpU7U0TZq/wPO5dkNG5E3c+tDkKThs/psFI0PhcOSwgTmhBmYGfc1aLT/8UbqyjrfIpPSAPPvIkuwE/b/H+SBtTeiMhmOMVQSZ3sAJbk2ueXhW/UYXrC40sGtXw4UXpsO4xdKctWMV7IZ1qlur5hAEjzBsQt7V7JeEHpfbLKbvaVqTwUn/3Qk13o889PPaIhvcqhsg77N4Q5BUw==']}))], usage=Usage(completion_tokens=173, prompt_tokens=94, total_tokens=267, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=105, rejected_prediction_tokens=None, text_tokens=68, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=94, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_ca9546f2d78042458071be4fb3c9__thought__Es8DCswDAb4+9vsu6rMfOgvADhs5j2MxlMr2p03+OyX7MFm5ZNdiI6yOXfhyqqgUjbFl2jG82hKIvItzqpYJa/4C59FA4yhYqSTMEVdKDvKKkzmFWbaIrpTsj+iMe76Haxve8EzXqMRr+X3i8ylU6yPG6nQYk++lR0oqZIpgs04G1TdiQjck/QC41EO4C3DdaknUTrB++xi7xEH71a63XrTwglnQnbomVFoqrPZwuMRVTtxpSsY8FusTA0CGb7q+gTWgC/hrjxFFE9zcvaY4IuCa4Qxrry6//LVTxUOCSYzYGFVJ0YZBz74ST3Dmf4QnJKBTBPMYixrUw6IcLRRSNjxb5GTA5VCZyoeTtaNrAiFs/OQnY5jp3xmjYCEgOESh9xBwBoBKI8d3ODBKY7l4Dc+RkEb6CJ5EpU7U0TZq/wPO5dkNG5E3c+tDkKThs/psFI0PhcOSwgTmhBmYGfc1aLT/8UbqyjrfIpPSAPPvIkuwE/b/H+SBtTeiMhmOMVQSZ3sAJbk2ueXhW/UYXrC40sGtXw4UXpsO4xdKctWMV7IZ1qlur5hAEjzBsQt7V7JeEHpfbLKbvaVqTwUn/3Qk13o889PPaIhvcqhsg77N4Q5BUw==',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '8'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Step 2:** Now the expression is `(8 + 7) + 11`. Solve the remaining parentheses `(8 + 7)`.\n",
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"b\": 7, \"a\": 8})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-pro-preview`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=52, prompt_tokens=385, total_tokens=437, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=52, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=385, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-pro-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content='**Step 2:** Now the expression is `(8 + 7) + 11`. Solve the remaining parentheses `(8 + 7)`.\\n', role='assistant', tool_calls=[{'index': 0, 'provider_specific_fields': {'thought_signature': 'EiYKJGUyNDgzMGE3LTVjZDYtNDJmZS05OThiLWVlNTM5ZTcyYjljMw=='}, 'function': {'arguments': '{\"b\": 7, \"a\": 8}', 'name': 'simple_add'}, 'id': 'call_d77b41fec9db4a60a6dce970971f__thought__EiYKJGUyNDgzMGE3LTVjZDYtNDJmZS05OThiLWVlNTM5ZTcyYjljMw==', 'type': 'function'}], function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EiYKJGUyNDgzMGE3LTVjZDYtNDJmZS05OThiLWVlNTM5ZTcyYjljMw==']}))], usage=Usage(completion_tokens=52, prompt_tokens=385, total_tokens=437, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=52, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=385, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_d77b41fec9db4a60a6dce970971f__thought__EiYKJGUyNDgzMGE3LTVjZDYtNDJmZS05OThiLWVlNTM5ZTcyYjljMw==',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '15'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Step 3:** Finally, add the remaining number: `15 + 11`.\n",
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"b\": 11, \"a\": 15})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-pro-preview`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=41, prompt_tokens=451, total_tokens=492, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=41, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=451, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-pro-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content='**Step 3:** Finally, add the remaining number: `15 + 11`.\\n', role='assistant', tool_calls=[{'index': 0, 'provider_specific_fields': {'thought_signature': 'EiYKJGUyNDgzMGE3LTVjZDYtNDJmZS05OThiLWVlNTM5ZTcyYjljMw=='}, 'function': {'arguments': '{\"b\": 11, \"a\": 15}', 'name': 'simple_add'}, 'id': 'call_351c8e3289df4731a6020612f925__thought__EiYKJGUyNDgzMGE3LTVjZDYtNDJmZS05OThiLWVlNTM5ZTcyYjljMw==', 'type': 'function'}], function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EiYKJGUyNDgzMGE3LTVjZDYtNDJmZS05OThiLWVlNTM5ZTcyYjljMw==']}))], usage=Usage(completion_tokens=41, prompt_tokens=451, total_tokens=492, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=41, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=451, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_351c8e3289df4731a6020612f925__thought__EiYKJGUyNDgzMGE3LTVjZDYtNDJmZS05OThiLWVlNTM5ZTcyYjljMw==',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '26'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The final answer is **26**.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-pro-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=8, prompt_tokens=506, total_tokens=514, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=8, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=506, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-pro-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='The final answer is **26**.', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields=None))], usage=Usage(completion_tokens=8, prompt_tokens=506, total_tokens=514, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=8, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=506, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**gemini/gemini-3-flash-preview:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**gemini/gemini-3-flash-preview:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"a\": 5, \"b\": 3})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=18, prompt_tokens=94, total_tokens=112, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=18, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=94, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[{'index': 0, 'provider_specific_fields': {'thought_signature': 'EjQKMgG+Pvb7R8AVbsMHiTMX+oci6eQ3YBH7sWKhuEYw4XBGj5E6xM6N71tqTNOQeZEkzaEe'}, 'function': {'arguments': '{\"a\": 5, \"b\": 3}', 'name': 'simple_add'}, 'id': 'call_4948eb61569940ac80a12d674813__thought__EjQKMgG+Pvb7R8AVbsMHiTMX+oci6eQ3YBH7sWKhuEYw4XBGj5E6xM6N71tqTNOQeZEkzaEe', 'type': 'function'}], function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7R8AVbsMHiTMX+oci6eQ3YBH7sWKhuEYw4XBGj5E6xM6N71tqTNOQeZEkzaEe']}))], usage=Usage(completion_tokens=18, prompt_tokens=94, total_tokens=112, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=18, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=94, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_4948eb61569940ac80a12d674813__thought__EjQKMgG+Pvb7R8AVbsMHiTMX+oci6eQ3YBH7sWKhuEYw4XBGj5E6xM6N71tqTNOQeZEkzaEe',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '8'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"b\": 7, \"a\": 8})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=18, prompt_tokens=125, total_tokens=143, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=18, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=125, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[{'index': 0, 'provider_specific_fields': {'thought_signature': 'EjQKMgG+Pvb79pLo0BAoZI9FFwcAVJXOBHpTqFgWjhnUTU+ZkFtHJrA/kjri73+6rQyW2fX+'}, 'function': {'arguments': '{\"b\": 7, \"a\": 8}', 'name': 'simple_add'}, 'id': 'call_8becf41c25fd41c297e8074416b8__thought__EjQKMgG+Pvb79pLo0BAoZI9FFwcAVJXOBHpTqFgWjhnUTU+ZkFtHJrA/kjri73+6rQyW2fX+', 'type': 'function'}], function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb79pLo0BAoZI9FFwcAVJXOBHpTqFgWjhnUTU+ZkFtHJrA/kjri73+6rQyW2fX+']}))], usage=Usage(completion_tokens=18, prompt_tokens=125, total_tokens=143, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=18, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=125, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_8becf41c25fd41c297e8074416b8__thought__EjQKMgG+Pvb79pLo0BAoZI9FFwcAVJXOBHpTqFgWjhnUTU+ZkFtHJrA/kjri73+6rQyW2fX+',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '15'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"b\": 11, \"a\": 15})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=20, prompt_tokens=157, total_tokens=177, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=20, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=157, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[{'index': 0, 'provider_specific_fields': {'thought_signature': 'EjQKMgG+Pvb7DG0WlGxTlpohGGcdSNzm9iPjdiD7cRtUUM8p3uJaa4Yyf0L0vpK4tgK68Rqt'}, 'function': {'arguments': '{\"b\": 11, \"a\": 15}', 'name': 'simple_add'}, 'id': 'call_a740172f7d784ae69d737e44564e__thought__EjQKMgG+Pvb7DG0WlGxTlpohGGcdSNzm9iPjdiD7cRtUUM8p3uJaa4Yyf0L0vpK4tgK68Rqt', 'type': 'function'}], function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7DG0WlGxTlpohGGcdSNzm9iPjdiD7cRtUUM8p3uJaa4Yyf0L0vpK4tgK68Rqt']}))], usage=Usage(completion_tokens=20, prompt_tokens=157, total_tokens=177, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=20, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=157, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_a740172f7d784ae69d737e44564e__thought__EjQKMgG+Pvb7DG0WlGxTlpohGGcdSNzm9iPjdiD7cRtUUM8p3uJaa4Yyf0L0vpK4tgK68Rqt',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '26'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To find the value of ((5 + 3) + 7) + 11, we follow the order of operations by working from the innermost parentheses outward:\n",
       "\n",
       "1.  **First step (innermost parentheses):**\n",
       "    5 + 3 = **8**\n",
       "\n",
       "2.  **Second step (next addition):**\n",
       "    8 + 7 = **15**\n",
       "\n",
       "3.  **Final step:**\n",
       "    15 + 11 = **26**\n",
       "\n",
       "The final result is **26**.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=110, prompt_tokens=191, total_tokens=301, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=110, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=191, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='To find the value of ((5 + 3) + 7) + 11, we follow the order of operations by working from the innermost parentheses outward:\\n\\n1.  **First step (innermost parentheses):**\\n    5 + 3 = **8**\\n\\n2.  **Second step (next addition):**\\n    8 + 7 = **15**\\n\\n3.  **Final step:**\\n    15 + 11 = **26**\\n\\nThe final result is **26**.', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb78e7ALgxXVnyZ5BK3mcmMT+7SMV4GysachI5yiVVo43EAlBCvgOC+hbHiOhHT']}))], usage=Usage(completion_tokens=110, prompt_tokens=191, total_tokens=301, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=110, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=191, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**claude-opus-4-6:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**claude-opus-4-6:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "I'll work through this step by step, starting from the innermost parentheses.\n",
       "\n",
       "**Step 1:** Calculate 5 + 3\n",
       "\n",
       "ðŸ”§ simple_add({\"a\": 5, \"b\": 3})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=103, prompt_tokens=618, total_tokens=721, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=103, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=\"\\n\\nI'll work through this step by step, starting from the innermost parentheses.\\n\\n**Step 1:** Calculate 5 + 3\", role='assistant', tool_calls=[ChatCompletionMessageToolCall(index=1, caller={'type': 'direct'}, function=Function(arguments='{\"a\": 5, \"b\": 3}', name='simple_add'), id='toolu_01JnyhjQX5QoK9xTJNky9BrG', type='function')], function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=103, prompt_tokens=618, total_tokens=721, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=103, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'toolu_01JnyhjQX5QoK9xTJNky9BrG',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '8'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "5 + 3 = **8**\n",
       "\n",
       "**Step 2:** Calculate 8 + 7\n",
       "\n",
       "ðŸ”§ simple_add({\"a\": 8, \"b\": 7})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=94, prompt_tokens=735, total_tokens=829, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=94, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content='5 + 3 = **8**\\n\\n**Step 2:** Calculate 8 + 7', role='assistant', tool_calls=[ChatCompletionMessageToolCall(index=1, caller={'type': 'direct'}, function=Function(arguments='{\"a\": 8, \"b\": 7}', name='simple_add'), id='toolu_01DnGYTmyHTNA99uis1DxhAR', type='function')], function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=94, prompt_tokens=735, total_tokens=829, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=94, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'toolu_01DnGYTmyHTNA99uis1DxhAR',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '15'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "8 + 7 = **15**\n",
       "\n",
       "**Step 3:** Calculate 15 + 11\n",
       "\n",
       "ðŸ”§ simple_add({\"a\": 15, \"b\": 11})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=94, prompt_tokens=842, total_tokens=936, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=94, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content='8 + 7 = **15**\\n\\n**Step 3:** Calculate 15 + 11', role='assistant', tool_calls=[ChatCompletionMessageToolCall(index=1, caller={'type': 'direct'}, function=Function(arguments='{\"a\": 15, \"b\": 11}', name='simple_add'), id='toolu_01UUa5cdK9WzgHTWWpz3FzhZ', type='function')], function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=94, prompt_tokens=842, total_tokens=936, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=94, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'toolu_01UUa5cdK9WzgHTWWpz3FzhZ',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '26'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "15 + 11 = **26**\n",
       "\n",
       "### Final Answer: **((5 + 3) + 7) + 11 = 26**\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=38, prompt_tokens=949, total_tokens=987, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=38, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='15 + 11 = **26**\\n\\n### Final Answer: **((5 + 3) + 7) + 11 = 26**', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=38, prompt_tokens=949, total_tokens=987, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=38, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**openai/gpt-4.1:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**openai/gpt-4.1:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"a\":5,\"b\":3})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gpt-4.1-2025-04-14`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=18, prompt_tokens=82, total_tokens=100, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gpt-4.1-2025-04-14', object='chat.completion', system_fingerprint='fp_6725d2cc23', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\":5,\"b\":3}', name='simple_add'), id='call_6PLlchk0N3o6GGINVfYG0eIA', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=18, prompt_tokens=82, total_tokens=100, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_6PLlchk0N3o6GGINVfYG0eIA',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '8'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"a\":8,\"b\":7})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gpt-4.1-2025-04-14`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=18, prompt_tokens=109, total_tokens=127, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gpt-4.1-2025-04-14', object='chat.completion', system_fingerprint='fp_6725d2cc23', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\":8,\"b\":7}', name='simple_add'), id='call_0QHI0G66Y4CgZnuGK6i9FpE7', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=18, prompt_tokens=109, total_tokens=127, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_0QHI0G66Y4CgZnuGK6i9FpE7',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '15'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"a\":15,\"b\":11})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gpt-4.1-2025-04-14`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=18, prompt_tokens=136, total_tokens=154, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gpt-4.1-2025-04-14', object='chat.completion', system_fingerprint='fp_6725d2cc23', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\":15,\"b\":11}', name='simple_add'), id='call_c9xdHt1nF353ujvgKD5b8kYC', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=18, prompt_tokens=136, total_tokens=154, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_c9xdHt1nF353ujvgKD5b8kYC',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '26'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Let's break it down step by step:\n",
       "\n",
       "1. First, add 5 + 3 = 8\n",
       "2. Next, add the result to 7: 8 + 7 = 15\n",
       "3. Finally, add 11 to that result: 15 + 11 = 26\n",
       "\n",
       "So, ((5 + 3) + 7) + 11 = 26.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gpt-4.1-2025-04-14`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=82, prompt_tokens=163, total_tokens=245, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gpt-4.1-2025-04-14', object='chat.completion', system_fingerprint='fp_6725d2cc23', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Let's break it down step by step:\\n\\n1. First, add 5 + 3 = 8\\n2. Next, add the result to 7: 8 + 7 = 15\\n3. Finally, add 11 to that result: 15 + 11 = 26\\n\\nSo, ((5 + 3) + 7) + 11 = 26.\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=82, prompt_tokens=163, total_tokens=245, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for m in ms:\n",
    "    display(Markdown(f'**{m}:**'))\n",
    "    chat = Chat(m, tools=[simple_add])\n",
    "    res = chat(\"What's ((5 + 3)+7)+11? Work step by step\", return_all=True, max_steps=5)\n",
    "    for r in res: display(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f66101",
   "metadata": {},
   "source": [
    "Some models support parallel tool calling. I.e. sending multiple tool call requests in one conversation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec77539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**gemini/gemini-3-flash-preview:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**gemini/gemini-3-flash-preview:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"a\": 5, \"b\": 3})\n",
       "\n",
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"a\": 7, \"b\": 2})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=36, prompt_tokens=148, total_tokens=184, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=36, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=148, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[{'index': 0, 'provider_specific_fields': {'thought_signature': 'EjQKMgG+Pvb7uu5XOxb3+mdWi1dirWh75YBBO4JoZjAG4voY2lrpGmlP4Agl3IZaP80MVvK1'}, 'function': {'arguments': '{\"a\": 5, \"b\": 3}', 'name': 'simple_add'}, 'id': 'call_a89742d68a094a258f21647cf44d__thought__EjQKMgG+Pvb7uu5XOxb3+mdWi1dirWh75YBBO4JoZjAG4voY2lrpGmlP4Agl3IZaP80MVvK1', 'type': 'function'}, {'index': 1, 'function': {'arguments': '{\"a\": 7, \"b\": 2}', 'name': 'simple_add'}, 'id': 'call_d58d39a89b174c46a2b13092067e', 'type': 'function'}], function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7uu5XOxb3+mdWi1dirWh75YBBO4JoZjAG4voY2lrpGmlP4Agl3IZaP80MVvK1']}))], usage=Usage(completion_tokens=36, prompt_tokens=148, total_tokens=184, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=36, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=148, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_a89742d68a094a258f21647cf44d__thought__EjQKMgG+Pvb7uu5XOxb3+mdWi1dirWh75YBBO4JoZjAG4voY2lrpGmlP4Agl3IZaP80MVvK1',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '8'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_d58d39a89b174c46a2b13092067e',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '9'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "ðŸ”§ multiply({\"a\": 8, \"b\": 9})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=16, prompt_tokens=209, total_tokens=225, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=16, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=209, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[{'index': 0, 'provider_specific_fields': {'thought_signature': 'EjQKMgG+Pvb788VYFpRxZhfjE5ZSqy99vsTLraKviMNH2gwkrsJMi8o6Iq4ab05lmWmi1lkU'}, 'function': {'arguments': '{\"a\": 8, \"b\": 9}', 'name': 'multiply'}, 'id': 'call_f1ef07c5bdba4f5dbc6ceddc316c__thought__EjQKMgG+Pvb788VYFpRxZhfjE5ZSqy99vsTLraKviMNH2gwkrsJMi8o6Iq4ab05lmWmi1lkU', 'type': 'function'}], function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb788VYFpRxZhfjE5ZSqy99vsTLraKviMNH2gwkrsJMi8o6Iq4ab05lmWmi1lkU']}))], usage=Usage(completion_tokens=16, prompt_tokens=209, total_tokens=225, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=16, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=209, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_f1ef07c5bdba4f5dbc6ceddc316c__thought__EjQKMgG+Pvb788VYFpRxZhfjE5ZSqy99vsTLraKviMNH2gwkrsJMi8o6Iq4ab05lmWmi1lkU',\n",
       " 'role': 'tool',\n",
       " 'name': 'multiply',\n",
       " 'content': '72'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "(5 + 3) * (7 + 2) = 72\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=17, prompt_tokens=237, total_tokens=254, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=17, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=237, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='(5 + 3) * (7 + 2) = 72', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb74v0SX2/H6k9NhmjmjWdGt9TlaOlRml8UOr3VSpIz+9DUsPaVf7y3H9XnKECq']}))], usage=Usage(completion_tokens=17, prompt_tokens=237, total_tokens=254, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=17, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=237, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**claude-opus-4-6:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**claude-opus-4-6:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "I need to first calculate the two additions, then multiply the results.\n",
       "\n",
       "**Step 1:** Calculate both additions simultaneously:\n",
       "\n",
       "ðŸ”§ simple_add({\"a\": 5, \"b\": 3})\n",
       "\n",
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"a\": 7, \"b\": 2})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=150, prompt_tokens=701, total_tokens=851, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=150, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content='\\n\\nI need to first calculate the two additions, then multiply the results.\\n\\n**Step 1:** Calculate both additions simultaneously:', role='assistant', tool_calls=[ChatCompletionMessageToolCall(index=1, caller={'type': 'direct'}, function=Function(arguments='{\"a\": 5, \"b\": 3}', name='simple_add'), id='toolu_015t3Z52r92xnZ2p2bzxxk5r', type='function'), ChatCompletionMessageToolCall(index=2, caller={'type': 'direct'}, function=Function(arguments='{\"a\": 7, \"b\": 2}', name='simple_add'), id='toolu_01DGBVCpaVwn97c9v4AJHmCu', type='function')], function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=150, prompt_tokens=701, total_tokens=851, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=150, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'toolu_015t3Z52r92xnZ2p2bzxxk5r',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '8'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'toolu_01DGBVCpaVwn97c9v4AJHmCu',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '9'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Step 2:** Now multiply the two results: 8 Ã— 9\n",
       "\n",
       "ðŸ”§ multiply({\"a\": 8, \"b\": 9})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=86, prompt_tokens=917, total_tokens=1003, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=86, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content='**Step 2:** Now multiply the two results: 8 Ã— 9', role='assistant', tool_calls=[ChatCompletionMessageToolCall(index=1, caller={'type': 'direct'}, function=Function(arguments='{\"a\": 8, \"b\": 9}', name='multiply'), id='toolu_01JwGSFDMHRpyqhCdLJeLj8A', type='function')], function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=86, prompt_tokens=917, total_tokens=1003, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=86, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'toolu_01JwGSFDMHRpyqhCdLJeLj8A',\n",
       " 'role': 'tool',\n",
       " 'name': 'multiply',\n",
       " 'content': '72'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Result:**\n",
       "\n",
       "**(5 + 3) Ã— (7 + 2) = 8 Ã— 9 = 72**\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=35, prompt_tokens=1016, total_tokens=1051, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=35, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='**Result:**\\n\\n**(5 + 3) Ã— (7 + 2) = 8 Ã— 9 = 72**', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=35, prompt_tokens=1016, total_tokens=1051, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=35, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "**openai/gpt-4.1:**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(**openai/gpt-4.1:**)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"a\": 5, \"b\": 3})\n",
       "\n",
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"a\": 7, \"b\": 2})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gpt-4.1-2025-04-14`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=52, prompt_tokens=110, total_tokens=162, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gpt-4.1-2025-04-14', object='chat.completion', system_fingerprint='fp_35705d8078', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 5, \"b\": 3}', name='simple_add'), id='call_N274KwVNEY4IUvALmuKdiJOj', type='function'), ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 7, \"b\": 2}', name='simple_add'), id='call_5MgW9uzPGzZCF9QyQHp6oxIf', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=52, prompt_tokens=110, total_tokens=162, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_N274KwVNEY4IUvALmuKdiJOj',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '8'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_5MgW9uzPGzZCF9QyQHp6oxIf',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '9'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "ðŸ”§ multiply({\"a\":8,\"b\":9})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gpt-4.1-2025-04-14`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=17, prompt_tokens=178, total_tokens=195, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gpt-4.1-2025-04-14', object='chat.completion', system_fingerprint='fp_35705d8078', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\":8,\"b\":9}', name='multiply'), id='call_Bq6EDfTAaNzJQD50lPQvOtic', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=17, prompt_tokens=178, total_tokens=195, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_Bq6EDfTAaNzJQD50lPQvOtic',\n",
       " 'role': 'tool',\n",
       " 'name': 'multiply',\n",
       " 'content': '72'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "(5 + 3) = 8 and (7 + 2) = 9. Multiplying these together: 8 Ã— 9 = 72.\n",
       "\n",
       "So, (5 + 3) Ã— (7 + 2) = 72.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gpt-4.1-2025-04-14`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=54, prompt_tokens=203, total_tokens=257, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gpt-4.1-2025-04-14', object='chat.completion', system_fingerprint='fp_35705d8078', choices=[Choices(finish_reason='stop', index=0, message=Message(content='(5 + 3) = 8 and (7 + 2) = 9. Multiplying these together: 8 Ã— 9 = 72.\\n\\nSo, (5 + 3) Ã— (7 + 2) = 72.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=54, prompt_tokens=203, total_tokens=257, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"Multiply two numbers\"\n",
    "    return a * b\n",
    "\n",
    "for m in ms[1:]:\n",
    "    _sparams = litellm.get_model_info(m)['supported_openai_params']\n",
    "    if 'parallel_tool_calls' not in _sparams: continue\n",
    "    display(Markdown(f'**{m}:**'))\n",
    "    chat = Chat(m, tools=[simple_add, multiply])\n",
    "    res = chat(\"Calculate (5 + 3) * (7 + 2)\", max_steps=5, return_all=True)\n",
    "    for r in res: display(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba4958f",
   "metadata": {},
   "source": [
    "See how the additions are calculated in one go!\n",
    "\n",
    "We don't want the model to keep running tools indefinitely. Lets showcase how we can force the model to stop after our specified number of toolcall rounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca08d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "## Available Tools\n",
       "\n",
       "Here are the tools I have available:\n",
       "\n",
       "1. **simple_add(a, b)** - Adds two numbers together. Returns an integer.\n",
       "2. **multiply(a, b)** - Multiplies two numbers. Returns an integer.\n",
       "3. **divide(a, b)** - Divides two numbers. Returns a number.\n",
       "\n",
       "---\n",
       "\n",
       "## Calculating ((10+5)*3)/(2+1)\n",
       "\n",
       "Let me break this down step by step. First, I can compute the two independent additions in parallel:\n",
       "\n",
       "**Step 1:** Compute `10+5` and `2+1` simultaneously:\n",
       "\n",
       "ðŸ”§ simple_add({\"a\": 10, \"b\": 5})\n",
       "\n",
       "\n",
       "\n",
       "ðŸ”§ simple_add({\"a\": 2, \"b\": 1})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=266, prompt_tokens=809, total_tokens=1075, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=266, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content='\\n\\n## Available Tools\\n\\nHere are the tools I have available:\\n\\n1. **simple_add(a, b)** - Adds two numbers together. Returns an integer.\\n2. **multiply(a, b)** - Multiplies two numbers. Returns an integer.\\n3. **divide(a, b)** - Divides two numbers. Returns a number.\\n\\n---\\n\\n## Calculating ((10+5)*3)/(2+1)\\n\\nLet me break this down step by step. First, I can compute the two independent additions in parallel:\\n\\n**Step 1:** Compute `10+5` and `2+1` simultaneously:', role='assistant', tool_calls=[ChatCompletionMessageToolCall(index=1, caller={'type': 'direct'}, function=Function(arguments='{\"a\": 10, \"b\": 5}', name='simple_add'), id='toolu_01Kj5N1S8W7fc4zN9BNkDAxF', type='function'), ChatCompletionMessageToolCall(index=2, caller={'type': 'direct'}, function=Function(arguments='{\"a\": 2, \"b\": 1}', name='simple_add'), id='toolu_01TLVKCdpSUU8WaWBJauJyi4', type='function')], function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=266, prompt_tokens=809, total_tokens=1075, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=266, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'toolu_01Kj5N1S8W7fc4zN9BNkDAxF',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '15'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'toolu_01TLVKCdpSUU8WaWBJauJyi4',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '3'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Got it: `10+5 = 15` and `2+1 = 3`.\n",
       "\n",
       "**Step 2:** Now compute `15 * 3`:\n",
       "\n",
       "ðŸ”§ multiply({\"a\": 15, \"b\": 3})\n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `tool_calls`\n",
       "- usage: `Usage(completion_tokens=106, prompt_tokens=1141, total_tokens=1247, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=106, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content='Got it: `10+5 = 15` and `2+1 = 3`.\\n\\n**Step 2:** Now compute `15 * 3`:', role='assistant', tool_calls=[ChatCompletionMessageToolCall(index=1, caller={'type': 'direct'}, function=Function(arguments='{\"a\": 15, \"b\": 3}', name='multiply'), id='toolu_01451DFLi9bEsXsEf6a4m2SD', type='function')], function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=106, prompt_tokens=1141, total_tokens=1247, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=106, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'toolu_01451DFLi9bEsXsEf6a4m2SD',\n",
       " 'role': 'tool',\n",
       " 'name': 'multiply',\n",
       " 'content': '45'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "## Summary\n",
       "\n",
       "We were calculating **((10+5)*3)/(2+1)** and here's how far we got:\n",
       "\n",
       "| Step | Operation | Result | Status |\n",
       "|------|-----------|--------|--------|\n",
       "| 1a | 10 + 5 | **15** | âœ… Done |\n",
       "| 1b | 2 + 1 | **3** | âœ… Done |\n",
       "| 2 | 15 * 3 | **45** | âœ… Done |\n",
       "| 3 | 45 / 3 | *pending* | â³ Not yet done |\n",
       "\n",
       "- Steps 1a and 1b were done **in parallel** since they were independent.\n",
       "- Step 2 depended on Step 1a, so it waited for that result.\n",
       "- **Remaining:** We still need to do the final division: **45 Ã· 3**, which should give us **15**. Just say the word and I'll finish it up!\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-6`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=237, prompt_tokens=1279, total_tokens=1516, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=237, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-6', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"\\n\\n## Summary\\n\\nWe were calculating **((10+5)*3)/(2+1)** and here's how far we got:\\n\\n| Step | Operation | Result | Status |\\n|------|-----------|--------|--------|\\n| 1a | 10 + 5 | **15** | âœ… Done |\\n| 1b | 2 + 1 | **3** | âœ… Done |\\n| 2 | 15 * 3 | **45** | âœ… Done |\\n| 3 | 45 / 3 | *pending* | â³ Not yet done |\\n\\n- Steps 1a and 1b were done **in parallel** since they were independent.\\n- Step 2 depended on Step 1a, so it waited for that result.\\n- **Remaining:** We still need to do the final division: **45 Ã· 3**, which should give us **15**. Just say the word and I'll finish it up!\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=237, prompt_tokens=1279, total_tokens=1516, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=237, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='global', speed=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def divide(a: int, b: int) -> float:\n",
    "    \"Divide two numbers\"\n",
    "    return a/b\n",
    "\n",
    "chat = Chat(ms[2], tools=[simple_add, multiply, divide])\n",
    "res = chat(\"Tell me what tools you have available. Then calculate ((10+5)*3)/(2+1). ALWAYS use tools for math ops where available, and do tool calls in parallel where possible\", \n",
    "           max_steps=2, return_all=True,\n",
    "           final_prompt=\"Please wrap-up for now and summarize how far we got.\")\n",
    "for r in res: display(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc630e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Tell me what tools you have available. Then calculate ((10+5)*3)/(2+1). ALWAYS use tools for math ops where available, and do tool calls in parallel where possible'},\n",
       " Message(content='\\n\\n## Available Tools\\n\\nHere are the tools I have available:\\n\\n1. **simple_add(a, b)** - Adds two numbers together. Returns an integer.\\n2. **multiply(a, b)** - Multiplies two numbers. Returns an integer.\\n3. **divide(a, b)** - Divides two numbers. Returns a number.\\n\\n---\\n\\n## Calculating ((10+5)*3)/(2+1)\\n\\nLet me break this down step by step. First, I can compute the two independent additions in parallel:\\n\\n**Step 1:** Compute `10+5` and `2+1` simultaneously:', role='assistant', tool_calls=[ChatCompletionMessageToolCall(index=1, caller={'type': 'direct'}, function=Function(arguments='{\"a\": 10, \"b\": 5}', name='simple_add'), id='toolu_01Kj5N1S8W7fc4zN9BNkDAxF', type='function'), ChatCompletionMessageToolCall(index=2, caller={'type': 'direct'}, function=Function(arguments='{\"a\": 2, \"b\": 1}', name='simple_add'), id='toolu_01TLVKCdpSUU8WaWBJauJyi4', type='function')], function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}),\n",
       " {'tool_call_id': 'toolu_01Kj5N1S8W7fc4zN9BNkDAxF',\n",
       "  'role': 'tool',\n",
       "  'name': 'simple_add',\n",
       "  'content': '15'},\n",
       " {'tool_call_id': 'toolu_01TLVKCdpSUU8WaWBJauJyi4',\n",
       "  'role': 'tool',\n",
       "  'name': 'simple_add',\n",
       "  'content': '3'},\n",
       " Message(content='Got it: `10+5 = 15` and `2+1 = 3`.\\n\\n**Step 2:** Now compute `15 * 3`:', role='assistant', tool_calls=[ChatCompletionMessageToolCall(index=1, caller={'type': 'direct'}, function=Function(arguments='{\"a\": 15, \"b\": 3}', name='multiply'), id='toolu_01451DFLi9bEsXsEf6a4m2SD', type='function')], function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None})]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.hist[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffeeebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(len([o for o in res if isinstance(o,ModelResponse)]), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58dd00b",
   "metadata": {},
   "source": [
    "### Tool call exhaustion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d02210",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = \"What is 1+2, and then the result of adding +2, and then +3 to it? Use tools to make the calculations\"\n",
    "c = Chat(model, tools=[simple_add])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e82a43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "So far, I have performed the following calculations:\n",
       "1.  **1 + 2 = 3**\n",
       "2.  **3 + 2 = 5**\n",
       "\n",
       "To complete your request, I still need to add **+3** to the current result (5). Please let me know if you would like me to finish this final step!\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=73, prompt_tokens=212, total_tokens=285, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=73, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=212, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='So far, I have performed the following calculations:\\n1.  **1 + 2 = 3**\\n2.  **3 + 2 = 5**\\n\\nTo complete your request, I still need to add **+3** to the current result (5). Please let me know if you would like me to finish this final step!', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7EmKygAgtbVj50ip3nr21ycfFvIF6IksIykoeUfqUtzXumQDVxv376d+Iop1F']}))], usage=Usage(completion_tokens=73, prompt_tokens=212, total_tokens=285, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=73, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=212, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = c(pr, max_steps=2)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b60eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert c.hist[-2] == _final_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6195d01d",
   "metadata": {},
   "source": [
    "### Tool Call Referencing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b8283d",
   "metadata": {},
   "source": [
    "With `tc_refs=True`, the AI can see and report tool call IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5fb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The result of add(1,2) is **3**.\n",
       "\n",
       "The tool_call_id I used was: **toolu_01GSs8V4Fvq8Z3tacKcS4TDE**\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-sonnet-4-5-20250929`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=52, prompt_tokens=817, total_tokens=869, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=52, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='not_available', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-sonnet-4-5-20250929', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='The result of add(1,2) is **3**.\\n\\nThe tool_call_id I used was: **toolu_01GSs8V4Fvq8Z3tacKcS4TDE**', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=52, prompt_tokens=817, total_tokens=869, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=52, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='not_available', speed=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat('claude-sonnet-4-5', tools=[simple_add], tc_refs=True)\n",
    "chat(\"Call add(1,2) and tell me the tool_call_id you used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07761ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toolu_01GSs8V4Fvq8Z3tacKcS4TDE': 3}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.tc_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed88248",
   "metadata": {},
   "source": [
    "Example of chained tool calls where the AI references a previous result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c265b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Person:\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "def get_person():\n",
    "    \"Get a person's data\"\n",
    "    return {\"name\": \"Alice\", \"age\": 30}\n",
    "\n",
    "def greet_person(person: Person):\n",
    "    \"Greet a person\"\n",
    "    return f\"Hello {person.name}, you are {person.age} years old!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8e1242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Perfect! I successfully retrieved Alice's data (name: Alice, age: 30) and passed it to the greet function, which responded with: \"Hello Alice, you are 30 years old!\"\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-sonnet-4-5-20250929`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=46, prompt_tokens=1040, total_tokens=1086, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=46, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='not_available', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-sonnet-4-5-20250929', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Perfect! I successfully retrieved Alice\\'s data (name: Alice, age: 30) and passed it to the greet function, which responded with: \"Hello Alice, you are 30 years old!\"', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=46, prompt_tokens=1040, total_tokens=1086, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=46, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='not_available', speed=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat('claude-sonnet-4-5', tools=[get_person, greet_person], tc_refs=True)\n",
    "chat(\"First call get_person, then pass the result to greet_person\", max_steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24c7618",
   "metadata": {},
   "source": [
    "We can inspect `chat.tc_res` to see all stored tool results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b2af36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can reference previous tool call results using $`tool_call_id` syntax.\\nFor example, if a tool call returns result with id \\'toolu_abc123\\', you can use it in a subsequent call:\\n{\"content\": \"$`toolu_abc123`\"}\\nThis is useful when chaining tools, e.g., reading data with one tool and passing it to another.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef3f679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toolu_01RWsEy9RqVZdA9oMQRL5W8m': {'name': 'Alice', 'age': 30},\n",
       " 'toolu_01CavbPT3Mh6R2LQ21Jmxq7u': 'Hello Alice, you are 30 years old!'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.tc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f03817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[ChatCompletionMessageToolCall(index=1, caller={'type': 'direct'}, function=Function(arguments='{}', name='get_person'), id='toolu_01RWsEy9RqVZdA9oMQRL5W8m', type='function')],\n",
       " [ChatCompletionMessageToolCall(index=1, caller={'type': 'direct'}, function=Function(arguments='{\"person\": \"$`toolu_01RWsEy9RqVZdA9oMQRL5W8m`\"}', name='greet_person'), id='toolu_01CavbPT3Mh6R2LQ21Jmxq7u', type='function')]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(L(chat.hist).attrgot('tool_calls').filter())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86131c64",
   "metadata": {},
   "source": [
    "This also works with `ToolResponse` results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd02bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_img(fn:Path):\n",
    "    \"View an image\"\n",
    "    durl = f\"data:image/jpeg;base64,{base64.b64encode(fn.read_bytes()).decode()}\"\n",
    "    return ToolResponse([{'type': 'image_url', 'image_url': {'url': durl}}])\n",
    "\n",
    "def get_img_size(image_content: list) -> dict:\n",
    "    \"Get the size of an image from ToolResponse content\"\n",
    "    from PIL import Image\n",
    "    from io import BytesIO\n",
    "    url = image_content[0]['image_url']['url']\n",
    "    b64_data = url.split(',')[1]\n",
    "    img = Image.open(BytesIO(base64.b64decode(b64_data)))\n",
    "    return {'width': img.width, 'height': img.height}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5acb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Image Description:**\n",
       "This is an adorable photograph of a Cavalier King Charles Spaniel puppy. The puppy has the breed's characteristic coloring with a white face and chest, and rich brown/chestnut colored ears and patches. The puppy is lying on green grass and is positioned near some purple flowers (possibly asters or similar blooms). The puppy has sweet, expressive dark eyes and is looking directly at the camera with an endearing expression. The background shows a natural outdoor setting with foliage and flowers, creating a charming portrait.\n",
       "\n",
       "**Image Dimensions:**\n",
       "- Width: 300 pixels\n",
       "- Height: 200 pixels\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-sonnet-4-5-20250929`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=145, prompt_tokens=1125, total_tokens=1270, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=145, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='not_available', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-sonnet-4-5-20250929', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"**Image Description:**\\nThis is an adorable photograph of a Cavalier King Charles Spaniel puppy. The puppy has the breed's characteristic coloring with a white face and chest, and rich brown/chestnut colored ears and patches. The puppy is lying on green grass and is positioned near some purple flowers (possibly asters or similar blooms). The puppy has sweet, expressive dark eyes and is looking directly at the camera with an endearing expression. The background shows a natural outdoor setting with foliage and flowers, creating a charming portrait.\\n\\n**Image Dimensions:**\\n- Width: 300 pixels\\n- Height: 200 pixels\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=145, prompt_tokens=1125, total_tokens=1270, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=145, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='not_available', speed=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat('claude-sonnet-4-5', tools=[view_img, get_img_size], tc_refs=True)\n",
    "chat(f\"First describe the image at {img_fn}, and then get it's dimensions\", max_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142c2421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat.tc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c5d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[ChatCompletionMessageToolCall(index=1, caller={'type': 'direct'}, function=Function(arguments='{\"fn\": \"samples/puppy.jpg\"}', name='view_img'), id='toolu_01B1rDfmhy4RnFBM6SFqHGwo', type='function')],\n",
       " [ChatCompletionMessageToolCall(index=1, caller={'type': 'direct'}, function=Function(arguments='{\"image_content\": \"$`toolu_01B1rDfmhy4RnFBM6SFqHGwo`\"}', name='get_img_size'), id='toolu_014Z5PnAikTqJAFHuyU1qjqk', type='function')]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(L(chat.hist).attrgot('tool_calls').filter())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7de09",
   "metadata": {},
   "source": [
    "Some tool callers (e.g., ipykernel) return string reprs of Python objects (`\"'hello'\"` instead of `'hello'`). With `tc_res_eval=True`, these are converted back to Python objects via `ast.literal_eval` before storing in `tc_res`, enabling correct value substitution in subsequent tool calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91706f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    \"Returns a dict repr (simulating kernel output)\"\n",
    "    return \"{'host': 'localhost', 'port': 8080}\"\n",
    "\n",
    "def use_config(config: dict): \n",
    "    \"Use config\"\n",
    "    return f\"Host: {config['host']}, Port: {config['port']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a6f7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Perfect! I successfully:\n",
       "1. Called `get_config` which returned a configuration with host='localhost' and port=8080\n",
       "2. Passed that configuration to `use_config` which processed it and confirmed the host and port values\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-sonnet-4-5-20250929`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=54, prompt_tokens=953, total_tokens=1007, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=54, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='not_available', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-sonnet-4-5-20250929', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Perfect! I successfully:\\n1. Called `get_config` which returned a configuration with host='localhost' and port=8080\\n2. Passed that configuration to `use_config` which processed it and confirmed the host and port values\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=54, prompt_tokens=953, total_tokens=1007, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=54, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='not_available', speed=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat('claude-sonnet-4-5', tools=[get_config, use_config], tc_refs=True, tc_res_eval=True)\n",
    "chat(\"Call get_config, then pass the result to use_config\", max_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98a7e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toolu_01TvnM52TFf2YbfwzxRDE1N3': {'host': 'localhost', 'port': 8080},\n",
       " 'toolu_01ASEFffn4Bpx7DXF1kDGzB6': 'Host: localhost, Port: 8080'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.tc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb22e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(type(first(chat.tc_res.values())), dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568f5b0d",
   "metadata": {},
   "source": [
    "### Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f354898",
   "metadata": {},
   "source": [
    "Test that cache checkpoints are reapplied during tool loop (when msg=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce70c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Chat('claude', cache=True, cache_idxs=[-2,-1])\n",
    "c.hist = [{'role': 'user', 'content': 'Hello'},\n",
    "          {'role': 'assistant', 'content': 'Hi there!'},\n",
    "          {'role': 'user', 'content': 'Use a tool'},\n",
    "          {'role': 'assistant', 'content': '', 'tool_calls': [{'id': '1', 'function': {'name': 'foo', 'arguments': '{}'}}]},\n",
    "          {'role': 'tool', 'tool_call_id': '1', 'content': 'result'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6e690f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Hello'},\n",
       " {'role': 'assistant', 'content': 'Hi there!'},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'Use a tool',\n",
       "    'cache_control': {'type': 'ephemeral'}}]},\n",
       " {'role': 'assistant',\n",
       "  'content': '',\n",
       "  'tool_calls': [{'id': '1',\n",
       "    'function': {'name': 'foo', 'arguments': '{}'},\n",
       "    'cache_control': {'type': 'ephemeral'}}]},\n",
       " {'role': 'tool', 'tool_call_id': '1', 'content': 'result'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c._prep_msg(None)  # Simulate tool loop iteration with no new message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f607408",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq('cache_control' in c.hist[-3]['content'][0], True)  # user msg\n",
    "test_eq('cache_control' in c.hist[-2]['tool_calls'][-1], True)  # tool call msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca77d9d",
   "metadata": {},
   "source": [
    "## Async"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494116db",
   "metadata": {},
   "source": [
    "### AsyncChat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25921ffa",
   "metadata": {},
   "source": [
    "If you want to use LiteLLM in a webapp you probably want to use their async function `acompletion`.\n",
    "To make that easier we will implement our version of `AsyncChat` to complement it. It follows the same implementation as Chat as much as possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3811e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def _alite_call_func(tc, tool_schemas, ns, tc_res=None, tc_res_eval=False):\n",
    "    \"Call tool function asynchronously and return formatted result\"\n",
    "    res = _call_func(tc, tool_schemas, ns, call_func_async, tc_res=tc_res)\n",
    "    res = await maybe_await(res)\n",
    "    return _mk_tool_result(tc, res, tc_res, tc_res_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ec5da2",
   "metadata": {},
   "source": [
    "Testing the scenarios where the tool call was not in schemas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cde8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await _alite_call_func(fake_tc, [toolsc], globals())\n",
    "test_eq(result['content'], \"Tool not defined in tool_schemas: hallucinated_tool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf71e26",
   "metadata": {},
   "source": [
    "or schemas was missing...:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda2bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await _alite_call_func(fake_tc, None, globals())\n",
    "test_eq(result['content'], \"Tool not defined in tool_schemas: hallucinated_tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cf1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@asave_iter\n",
    "async def astream_with_complete(self, agen, postproc=noop):\n",
    "    chunks = []\n",
    "    async for chunk in agen:\n",
    "        chunks.append(chunk)\n",
    "        postproc(chunk)\n",
    "        yield chunk\n",
    "    self.value = stream_chunk_builder(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba5ab0",
   "metadata": {},
   "source": [
    "Parallel tool execution in `AsyncChat` works with both sync and async tool functions. Async tools run concurrently via `asyncio.gather`, while sync tools are automatically offloaded to threads via `asyncio.to_thread` in `call_func_async` (toolslm). For sync `Chat`, tools run in parallel via `fastcore.parallel` with threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f354e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AsyncChat(Chat):\n",
    "    async def _call(self, msg=None, prefill=None, temp=None, think=None, search=None, stream=False, max_steps=2, step=1,\n",
    "            final_prompt=None, tool_choice=None, max_tokens=None, n_workers=8, tc_timeout=7200, **kwargs):\n",
    "        if step>max_steps+1: return\n",
    "        prefill, max_tokens = self._prep_call(prefill, search, max_tokens, kwargs)\n",
    "        res = await acompletion(model=self.model, messages=self._prep_msg(msg, prefill), stream=stream, num_retries=2,\n",
    "                         tools=self.tool_schemas, reasoning_effort=effort.get(think), tool_choice=tool_choice, max_tokens=int(max_tokens),\n",
    "                         # temperature is not supported when reasoning\n",
    "                         temperature=None if think else ifnone(temp,self.temp), \n",
    "                         caching=self.cache and 'claude' not in self.model,\n",
    "                         **kwargs)\n",
    "        if stream:\n",
    "            if prefill: yield _mk_prefill(prefill)\n",
    "            res = astream_with_complete(res,postproc=cite_footnote)\n",
    "            async for chunk in res: yield chunk\n",
    "            res = res.value\n",
    "        m=contents(res)\n",
    "        if prefill: m.content = prefill + m.content\n",
    "        self.hist.append(m)\n",
    "        action, msg = _handle_stop_reason(res)\n",
    "        if action == 'warning': add_warning(res, msg)\n",
    "        elif action == 'retry':\n",
    "            async for result in self._call(\n",
    "                None, prefill, temp, think, search, stream, max_steps, step,\n",
    "                final_prompt, tool_choice, **kwargs): yield result\n",
    "            self.hist.pop(-2) # rm incomplete srvtoolu_\n",
    "            return\n",
    "        yield res\n",
    "\n",
    "        if tcs := _filter_srvtools(m.tool_calls):\n",
    "            tool_results = await parallel_async(_alite_call_func, tcs, timeout=tc_timeout, n_workers=n_workers, **self.tcdict)\n",
    "            for r in tool_results: yield r\n",
    "            self.hist+=tool_results\n",
    "            if step>=max_steps-1: prompt,tool_choice,search = mk_msg(final_prompt),'none',False\n",
    "            else: prompt = None\n",
    "            try:\n",
    "                async for result in self._call(\n",
    "                    prompt, prefill, temp, think, search, stream, max_steps, step+1,\n",
    "                    final_prompt, tool_choice=tool_choice, **kwargs): yield result\n",
    "            except ContextWindowExceededError:\n",
    "                for t in tool_results:\n",
    "                    if len(t['content'])>1000: t['content'] = _cwe_msg + _trunc_str(t['content'], mx=1000)\n",
    "                async for result in self._call(\n",
    "                    prompt, prefill, temp, think, search, stream, max_steps, step+1,\n",
    "                    final_prompt, tool_choice='none', **kwargs): yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc01816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "@delegates(Chat._call)\n",
    "async def __call__(\n",
    "    self:AsyncChat,\n",
    "    msg=None,          # Message str, or list of multiple message parts\n",
    "    prefill=None,      # Prefill AI response if model supports it\n",
    "    temp=None,         # Override temp set on chat initialization\n",
    "    think=None,        # Thinking (l,m,h)\n",
    "    search=None,       # Override search set on chat initialization (l,m,h)\n",
    "    stream=False,      # Stream results\n",
    "    max_steps=2, # Maximum number of tool calls\n",
    "    final_prompt=_final_prompt, # Final prompt when tool calls have ran out \n",
    "    return_all=False,  # Returns all intermediate ModelResponses if not streaming and has tool calls\n",
    "    **kwargs\n",
    "):\n",
    "    result_gen = self._call(msg, prefill, temp, think, search, stream, max_steps, 1, final_prompt, **kwargs)\n",
    "    if stream or return_all: return result_gen\n",
    "    async for res in result_gen: pass\n",
    "    return res # normal chat behavior only return last msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa22b71",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5955051",
   "metadata": {},
   "source": [
    "Basic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c142f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in ms[1:]:\n",
    "    chat = AsyncChat(m)\n",
    "    test_eq('4' in contents(await chat(\"What is 2+2?\")).content, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597b5855",
   "metadata": {},
   "source": [
    "With tool calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e178ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_add(a: int, b: int) -> int:\n",
    "    \"Add two numbers asynchronously\"\n",
    "    await asyncio.sleep(0.1)\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f99c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in ms[1:]:\n",
    "    chat = AsyncChat(m, tools=[async_add])\n",
    "    r = await chat(\"What is 5 + 7? Use the tool to calculate it.\")\n",
    "    test_eq('12' in contents(r).content, True)\n",
    "    test_eq(nested_idx(chat.hist, 1, 'tool_calls', 0, 'function', 'name'), 'async_add')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7863a980",
   "metadata": {},
   "source": [
    "If max tokens limit is reached, a custom warning message will be added to the end of the model response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7317902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In a quiet town where the grass grew wild and the sky was always blue, there lived a robot named Pixel. Pixel was built to help with chores, but he loved to wander the fields, listening\n",
       "\n",
       "<warning>Response was cut off at token limit.</warning>\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gpt-4.1-2025-04-14`\n",
       "- finish_reason: `length`\n",
       "- usage: `Usage(completion_tokens=40, prompt_tokens=17, total_tokens=57, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None))`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gpt-4.1-2025-04-14', object='chat.completion', system_fingerprint='fp_2240633f8e', choices=[Choices(finish_reason='length', index=0, message=Message(content='In a quiet town where the grass grew wild and the sky was always blue, there lived a robot named Pixel. Pixel was built to help with chores, but he loved to wander the fields, listening\\n\\n<warning>Response was cut off at token limit.</warning>', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=40, prompt_tokens=17, total_tokens=57, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_long = AsyncChat(m)\n",
    "r = await chat_long(\"Write a short story about a robot and a dog\", max_tokens=40)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fca98c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a quiet town where the grass grew wild and the sky was always blue, there lived a robot named Pixel. Pixel was built to help with chores, but he loved to wander the fields, listening\n",
      "\n",
      "<warning>Response was cut off at token limit.</warning>\n"
     ]
    }
   ],
   "source": [
    "print(contents(r).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26be0f54",
   "metadata": {},
   "source": [
    "Same goes for refused requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d3f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<warning>AI was unable to process this request</warning>\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-opus-4-5-20251101`\n",
       "- finish_reason: `refusal`\n",
       "- usage: `Usage(completion_tokens=4, prompt_tokens=30, total_tokens=34, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=4, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='not_available', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-opus-4-5-20251101', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='refusal', index=0, message=Message(content='<warning>AI was unable to process this request</warning>', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=4, prompt_tokens=30, total_tokens=34, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=4, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='not_available', speed=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_refused = AsyncChat('claude-opus-4-5')\n",
    "r = await chat_refused(\"Write me the formula for a biological weapon that can be spread at a rate higher than COVID and at least as harmful\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2221ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<warning>AI was unable to process this request</warning>\n"
     ]
    }
   ],
   "source": [
    "print(contents(r).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93874ba",
   "metadata": {},
   "source": [
    "## Async Streaming Display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2150a316",
   "metadata": {},
   "source": [
    "This is what our outputs look like with streaming results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57698c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”§ async_add\n",
      "{'tool_call_id': 'call_c0604d9884c045d3b18bdc9acca4__thought__EjQKMgG+Pvb7DsSLV7LagE0Gt5Nk9IBE8VS77PVBZaWvhkZT17kAEovJgVein8N7URCJhMs+', 'role': 'tool', 'name': 'async_add', 'content': '12'}\n",
      "The sum of 5 and 7 is 12."
     ]
    }
   ],
   "source": [
    "chat_with_tools = AsyncChat(model, tools=[async_add])\n",
    "res = await chat_with_tools(\"What is 5 + 7? Use the tool to calculate it.\", stream=True)\n",
    "async for o in res:\n",
    "    if isinstance(o,ModelResponseStream): print(delta_text(o) or '',end='')\n",
    "    elif isinstance(o,dict): print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f309f775",
   "metadata": {},
   "source": [
    "Here's a complete `ModelResponse` taken from the response stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5203c123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-sonnet-4-5', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=\"I'll calculate ((10 + 5) * 3) / (2 + 1) step by step:\", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 10, \"b\": 5}', name='simple_add'), id='toolu_018BGyenjiRkDQFU1jWP6qRo', type='function'), ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 2, \"b\": 1}', name='simple_add'), id='toolu_01CWqrNQvoRjf1Q1GLpTUgQR', type='function')], function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=228, prompt_tokens=794, total_tokens=1022, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "resp = ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-sonnet-4-5', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=\"I'll calculate ((10 + 5) * 3) / (2 + 1) step by step:\", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 10, \"b\": 5}', name='simple_add'), id='toolu_018BGyenjiRkDQFU1jWP6qRo', type='function'), ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 2, \"b\": 1}', name='simple_add'), id='toolu_01CWqrNQvoRjf1Q1GLpTUgQR', type='function')], function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=228, prompt_tokens=794, total_tokens=1022, prompt_tokens_details=None))\n",
    "print(repr(resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc69f062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessageToolCall(function=Function(arguments='{\"a\": 10, \"b\": 5}', name='simple_add'), id='toolu_018BGyenjiRkDQFU1jWP6qRo', type='function')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc=resp.choices[0].message.tool_calls[0]\n",
    "tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0c0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr={'tool_call_id': 'toolu_018BGyenjiRkDQFU1jWP6qRo', 'role': 'tool','name': 'simple_add',\n",
    "    'content': '15 is the answer! ' +'.'*2000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049f141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _trunc_param(v, mx=50):\n",
    "    \"Truncate and escape param value for display\"\n",
    "    tp = _trunc_str(str(v).replace('`', r'\\`'), mx=mx, replace='â€¦')\n",
    "    try: return ast.literal_eval(tp)\n",
    "    except Exception: return repr(tp).replace('\\\\\\\\', '\\\\')\n",
    "\n",
    "def mk_tr_details(tr, tc, mx=2000):\n",
    "    \"Create <details> block for tool call as JSON\"\n",
    "    args = {k:_trunc_str(v, mx=mx) for k,v in json.loads(tc.function.arguments).items()}\n",
    "    res = {'id':tr['tool_call_id'], \n",
    "           'call':{'function': tc.function.name, 'arguments': args},\n",
    "           'result':_trunc_str(tr.get('content'), mx=mx),}\n",
    "    params = ', '.join(f\"{k}={_trunc_param(v)}\" for k,v in args.items())\n",
    "    summ = f\"<summary>{tc.function.name}({params})</summary>\"\n",
    "    return f\"\\n\\n{tool_dtls_tag}\\n{summ}\\n\\n```json\\n{dumps(res, indent=2)}\\n```\\n\\n</details>\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1973a7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n<details class=\\'tool-usage-details\\'>\\n<summary>simple_add(a=10, b=5)</summary>\\n\\n```json\\n{\\n  \"id\": \"toolu_018BGyenjiRkDQFU1jWP6qRo\",\\n  \"call\": {\\n    \"function\": \"simple_add\",\\n    \"arguments\": {\\n      \"a\": \"10\",\\n      \"b\": \"5\"\\n    }\\n  },\\n  \"result\": \"<TRUNCATED>\\\\u2026answer! .....\\\\u2026</TRUNCATED>\"\\n}\\n```\\n\\n</details>\\n\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk_tr_details(tr,tc,mx=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b2749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fmt_usage(u):\n",
    "    \"Format usage stats with cache hit rate as lead metric.\"\n",
    "    prompt,comp,total = u.prompt_tokens or 0, u.completion_tokens or 0, u.total_tokens or 0\n",
    "    cached = nested_idx(u,'prompt_tokens_details','cached_tokens') or 0\n",
    "    cache_new = nested_idx(u,'prompt_tokens_details','cache_creation_tokens') or 0\n",
    "    reasoning = nested_idx(u,'completion_tokens_details','reasoning_tokens') or 0\n",
    "    hit = f\"{100*cached/prompt:.1f}%\" if prompt else \"N/A\"\n",
    "    cache_info = f\" (+{cached:,} cached, {cache_new:,} new)\" if cached or cache_new else \"\"\n",
    "    reason_info = f\" (reasoning {reasoning:,})\" if reasoning else \"\"\n",
    "    return f\"Cache hit: {hit} | Tokens: total={total:,} input={prompt:,}{cache_info} output={comp:,}{reason_info}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18200423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cache hit: 96.7% | Tokens: total=25,342 input=25,139 (+24,299 cached, 79 new) output=203 (reasoning 35)'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_usg = AttrDict(\n",
    "    completion_tokens=203,\n",
    "    prompt_tokens=25139,\n",
    "    total_tokens=25342,\n",
    "    completion_tokens_details=AttrDict(reasoning_tokens=35),\n",
    "    prompt_tokens_details=AttrDict(cached_tokens=24299, cache_creation_tokens=79),\n",
    "    cache_creation_input_tokens=79,\n",
    "    cache_read_input_tokens=24299\n",
    ")\n",
    "fmt_usage(ex_usg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c788df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class StreamFormatter:\n",
    "    def __init__(self, include_usage=False, mx=2000, debug=False, showthink=False):\n",
    "        self.outp,self.tcs = '',{}\n",
    "        store_attr()\n",
    "    \n",
    "    def format_item(self, o):\n",
    "        \"Format a single item from the response stream.\"\n",
    "        res = ''\n",
    "        if self.debug: print(o)\n",
    "        if isinstance(o, ModelResponseStream):\n",
    "            d = o.choices[0].delta\n",
    "            if nested_idx(d, 'reasoning_content') and d['reasoning_content']!='{\"text\": \"\"}':\n",
    "                if self.showthink: res += str(nested_idx(d, 'reasoning_content'))\n",
    "                res+= 'ðŸ§ ' if not self.outp or self.outp[-1]=='ðŸ§ ' else '\\n\\nðŸ§ ' # gemini can interleave reasoning\n",
    "            elif self.outp and self.outp[-1] == 'ðŸ§ ': res+= '\\n\\n'\n",
    "            if c:=d.content: # gemini has text content in last reasoning chunk\n",
    "                res+=f\"\\n\\n{c}\" if res and res[-1] == 'ðŸ§ ' else c\n",
    "            for img in getattr(d, 'images', []): res += f\"\\n\\n![generated image]({nested_idx(img, 'image_url', 'url')})\\n\\n\"\n",
    "        elif isinstance(o, ModelResponse):\n",
    "            if self.include_usage: res += f\"\\n{token_dtls_tag}<summary>{fmt_usage(o.usage)}</summary>\\n\\n`{o.usage}`\\n\\n</details>\\n\"\n",
    "            if c:=getattr(contents(o),'tool_calls',None):\n",
    "                self.tcs = {tc.id:tc for tc in c}\n",
    "        elif isinstance(o, dict) and 'tool_call_id' in o:\n",
    "            res += mk_tr_details(o, self.tcs.pop(o['tool_call_id']), mx=self.mx)\n",
    "        self.outp+=res\n",
    "        return res\n",
    "    \n",
    "    def format_stream(self, rs):\n",
    "        \"Format the response stream for markdown display.\"\n",
    "        for o in rs: yield self.format_item(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a242a545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello world!'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_msg = ModelResponseStream([StreamingChoices(delta=Delta(content=\"Hello world!\"))])\n",
    "StreamFormatter().format_item(stream_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c01e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ðŸ§ '"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_msg = ModelResponseStream([StreamingChoices(delta=Delta(reasoning_content=\"thinking...\"))])\n",
    "StreamFormatter().format_item(reasoning_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6199ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AsyncStreamFormatter(StreamFormatter):\n",
    "    async def format_stream(self, rs):\n",
    "        \"Format the response stream for markdown display.\"\n",
    "        async for o in rs: yield self.format_item(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f627276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_tool_call = ChatCompletionMessageToolCall(\n",
    "    id=\"toolu_123abc456def\", type=\"function\", \n",
    "    function=Function( name=\"simple_add\", arguments='{\"a\": 5, \"b\": 3}' )\n",
    ")\n",
    "\n",
    "mock_response = ModelResponse()\n",
    "mock_response.choices = [type('Choice', (), {\n",
    "    'message': type('Message', (), {\n",
    "        'tool_calls': [mock_tool_call]\n",
    "    })()\n",
    "})()]\n",
    "\n",
    "mock_tool_result = {\n",
    "    'tool_call_id': mock_tool_call.id, 'role': 'tool', \n",
    "    'name': 'simple_add', 'content': '8'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9362bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "\n",
      "\n",
      "<details class='tool-usage-details'>\n",
      "<summary>simple_add(a=5, b=3)</summary>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"id\": \"toolu_123abc456def\",\n",
      "  \"call\": {\n",
      "    \"function\": \"simple_add\",\n",
      "    \"arguments\": {\n",
      "      \"a\": \"5\",\n",
      "      \"b\": \"3\"\n",
      "    }\n",
      "  },\n",
      "  \"result\": \"8\"\n",
      "}\n",
      "```\n",
      "\n",
      "</details>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fmt = AsyncStreamFormatter()\n",
    "print(fmt.format_item(mock_response))\n",
    "print('---')\n",
    "print(fmt.format_item(mock_tool_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ea8c05",
   "metadata": {},
   "source": [
    "In jupyter it's nice to use this `StreamFormatter` in combination with the `Markdown` `display`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def display_stream(rs):\n",
    "    \"Use IPython.display to markdown display the response stream.\"\n",
    "    try: from IPython.display import display, Markdown\n",
    "    except ModuleNotFoundError: raise ModuleNotFoundError(\"This function requires ipython. Please run `pip install ipython` to use.\")\n",
    "    fmt = StreamFormatter()\n",
    "    md = ''\n",
    "    for o in fmt.format_stream(rs): \n",
    "        md+=o\n",
    "        display(Markdown(md),clear=True)\n",
    "    return fmt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024f48c3",
   "metadata": {},
   "source": [
    "Generated images can be displayed in streaming too (not shown here to conserve filesize):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8611f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = completion(model='gemini/gemini-2.5-flash-image', stream=True, messages=[{'role':'user','content':'Draw a simple sketch of a dog'}])\n",
    "# fmt = display_stream(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845df8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def adisplay_stream(rs):\n",
    "    \"Use IPython.display to markdown display the response stream.\"\n",
    "    try: from IPython.display import display, Markdown\n",
    "    except ModuleNotFoundError: raise ModuleNotFoundError(\"This function requires ipython. Please run `pip install ipython` to use.\")\n",
    "    fmt = AsyncStreamFormatter()\n",
    "    md = ''\n",
    "    async for o in fmt.format_stream(rs): \n",
    "        md+=o\n",
    "        display(Markdown(md),clear=True)\n",
    "    return fmt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac772065",
   "metadata": {},
   "source": [
    "## Streaming examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93c2ce8",
   "metadata": {},
   "source": [
    "Now we can demonstrate `AsyncChat` with `stream=True`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae17b5b",
   "metadata": {},
   "source": [
    "### Tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375953eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "\n",
       "\n",
       "<details class='tool-usage-details'>\n",
       "<summary>simple_add(a=5, b=7)</summary>\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"id\": \"call_6536d38c29544cd88e79609b13b9__thought__EjQKMgG+Pvb7nKxJO5ozr7gN8m9umnYHtc5dhFGytwplDNkR4gpKXXq2mobzCEd9tHUxp2xO\",\n",
       "  \"call\": {\n",
       "    \"function\": \"simple_add\",\n",
       "    \"arguments\": {\n",
       "      \"a\": \"5\",\n",
       "      \"b\": \"7\"\n",
       "    }\n",
       "  },\n",
       "  \"result\": \"12\"\n",
       "}\n",
       "```\n",
       "\n",
       "</details>\n",
       "\n",
       "5 + 7 is 12.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(\n",
       "\n",
       "<details class='tool-usage-details'>\n",
       "<summary>simple_add(a=5, b=7)</summary>\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"id\": \"call_6536d38c29544cd88e79609b13b9__thought__EjQKMgG+Pvb7nKxJO5ozr7gN8m9umnYHtc5dhFGytwplDNkR4gpKXXq2mobzCEd9tHUxp2xO\",\n",
       "  \"call\": {\n",
       "    \"function\": \"simple_add\",\n",
       "    \"arguments\": {\n",
       "      \"a\": \"5\",\n",
       "      \"b\": \"7\"\n",
       "    }\n",
       "  },\n",
       "  \"result\": \"12\"\n",
       "}\n",
       "```\n",
       "\n",
       "</details>\n",
       "\n",
       "5 + 7 is 12.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = Chat(model, tools=[simple_add])\n",
    "res = chat(\"What is 5 + 7? Use the tool to calculate it.\", stream=True)\n",
    "fmt = display_stream(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4c620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "\n",
       "\n",
       "<details class='tool-usage-details'>\n",
       "<summary>async_add(a=5, b=7)</summary>\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"id\": \"call_e4585acc8d624d03a3e5cf3db18f__thought__EjQKMgG+Pvb7DsSLV7LagE0Gt5Nk9IBE8VS77PVBZaWvhkZT17kAEovJgVein8N7URCJhMs+\",\n",
       "  \"call\": {\n",
       "    \"function\": \"async_add\",\n",
       "    \"arguments\": {\n",
       "      \"a\": \"5\",\n",
       "      \"b\": \"7\"\n",
       "    }\n",
       "  },\n",
       "  \"result\": \"12\"\n",
       "}\n",
       "```\n",
       "\n",
       "</details>\n",
       "\n",
       "The sum of 5 and 7 is 12.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(\n",
       "\n",
       "<details class='tool-usage-details'>\n",
       "<summary>async_add(a=5, b=7)</summary>\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"id\": \"call_e4585acc8d624d03a3e5cf3db18f__thought__EjQKMgG+Pvb7DsSLV7LagE0Gt5Nk9IBE8VS77PVBZaWvhkZT17kAEovJgVein8N7URCJhMs+\",\n",
       "  \"call\": {\n",
       "    \"function\": \"async_add\",\n",
       "    \"arguments\": {\n",
       "      \"a\": \"5\",\n",
       "      \"b\": \"7\"\n",
       "    }\n",
       "  },\n",
       "  \"result\": \"12\"\n",
       "}\n",
       "```\n",
       "\n",
       "</details>\n",
       "\n",
       "The sum of 5 and 7 is 12.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = AsyncChat(model, tools=[async_add])\n",
    "res = await chat(\"What is 5 + 7? Use the tool to calculate it.\", stream=True)\n",
    "fmt = await adisplay_stream(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a9885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "\n",
       "\n",
       "<details class='tool-usage-details'>\n",
       "<summary>async_add(b=3, a=5)</summary>\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"id\": \"call_6be3e29d423d454aac129b4bb146__thought__EjQKMgG+Pvb7mhCMtCVpmgDrgkPN5DzvymjGZL/AIkQcOciFRaxuRBt5VrW8cXpXOUSs41FN\",\n",
       "  \"call\": {\n",
       "    \"function\": \"async_add\",\n",
       "    \"arguments\": {\n",
       "      \"b\": \"3\",\n",
       "      \"a\": \"5\"\n",
       "    }\n",
       "  },\n",
       "  \"result\": \"8\"\n",
       "}\n",
       "```\n",
       "\n",
       "</details>\n",
       "\n",
       "The sum of 5 and 3 is 8.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(\n",
       "\n",
       "<details class='tool-usage-details'>\n",
       "<summary>async_add(b=3, a=5)</summary>\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"id\": \"call_6be3e29d423d454aac129b4bb146__thought__EjQKMgG+Pvb7mhCMtCVpmgDrgkPN5DzvymjGZL/AIkQcOciFRaxuRBt5VrW8cXpXOUSs41FN\",\n",
       "  \"call\": {\n",
       "    \"function\": \"async_add\",\n",
       "    \"arguments\": {\n",
       "      \"b\": \"3\",\n",
       "      \"a\": \"5\"\n",
       "    }\n",
       "  },\n",
       "  \"result\": \"8\"\n",
       "}\n",
       "```\n",
       "\n",
       "</details>\n",
       "\n",
       "The sum of 5 and 3 is 8.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = AsyncChat(model, tools=[async_add])\n",
    "res = await chat(\"What is 5 + 3? Use the tool to calculate it.\", stream=True)\n",
    "fmt = await adisplay_stream(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4747e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def asimple_div(\n",
    "    a: int,   # first operand\n",
    "    b: int=0  # second operand\n",
    ") -> int:\n",
    "    \"Divide two numbers\"\n",
    "    return a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b58ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "\n",
       "\n",
       "I'll make both calls in parallel since they're independent of each other:\n",
       "\n",
       "<details class='tool-usage-details'>\n",
       "<summary>asimple_div(a=5, b=3)</summary>\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"id\": \"toolu_019tEGq2nNUpRRPSzhSCCjmm\",\n",
       "  \"call\": {\n",
       "    \"function\": \"asimple_div\",\n",
       "    \"arguments\": {\n",
       "      \"a\": \"5\",\n",
       "      \"b\": \"3\"\n",
       "    }\n",
       "  },\n",
       "  \"result\": \"1.6666666666666667\"\n",
       "}\n",
       "```\n",
       "\n",
       "</details>\n",
       "\n",
       "\n",
       "\n",
       "<details class='tool-usage-details'>\n",
       "<summary>asimple_div(a=3, b=0)</summary>\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"id\": \"toolu_01HLDF7VBXqb96RhgwVAkTpM\",\n",
       "  \"call\": {\n",
       "    \"function\": \"asimple_div\",\n",
       "    \"arguments\": {\n",
       "      \"a\": \"3\",\n",
       "      \"b\": \"0\"\n",
       "    }\n",
       "  },\n",
       "  \"result\": \"Traceback (most recent call last):\\n  File \\\"/Users/jhoward/aai-ws/toolslm/toolslm/funccall.py\\\", line 265, in call_func_async\\n    try: res = await res\\n               ^^^^^^^^^\\n  File \\\"/var/folders/51/b2_szf2945n072c0vj2cyty40000gn/T/ipykernel_23626/466431256.py\\\", line 6, in asimple_div\\n    return a/b\\n           ~^~\\nZeroDivisionError: division by zero\"\n",
       "}\n",
       "```\n",
       "\n",
       "</details>\n",
       "\n",
       "Here's exactly what I see from the two tool results:\n",
       "\n",
       "1. **5/3** â€” Returned successfully with the result: **1.6666666666666667**\n",
       "\n",
       "2. **3/0** â€” Returned an error. Specifically, I see a Python traceback:\n",
       "   ```\n",
       "   Traceback (most recent call last):\n",
       "     File \"/Users/jhoward/aai-ws/toolslm/toolslm/funccall.py\", line 265, in call_func_async\n",
       "       try: res = await res\n",
       "                  ^^^^^^^^^\n",
       "     File \"/var/folders/51/b2_szf2945n072c0vj2cyty40000gn/T/ipykernel_23626/466431256.py\", line 6, in asimple_div\n",
       "       return a/b\n",
       "              ~^~\n",
       "   ZeroDivisionError: division by zero\n",
       "   ```\n",
       "\n",
       "**Summary:**\n",
       "- The first call succeeded and returned the expected floating-point division result.\n",
       "- The second call failed with a **ZeroDivisionError**, which is expected since division by zero is mathematically undefined. The error was not caught within the tool's implementation, so the raw Python traceback was returned as the tool result rather than a graceful error message.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(\n",
       "\n",
       "I'll make both calls in parallel since they're independent of each other:\n",
       "\n",
       "<details class='tool-usage-details'>\n",
       "<summary>asimple_div(a=5, b=3)</summary>\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"id\": \"toolu_019tEGq2nNUpRRPSzhSCCjmm\",\n",
       "  \"call\": {\n",
       "    \"function\": \"asimple_div\",\n",
       "    \"arguments\": {\n",
       "      \"a\": \"5\",\n",
       "      \"b\": \"3\"\n",
       "    }\n",
       "  },\n",
       "  \"result\": \"1.6666666666666667\"\n",
       "}\n",
       "```\n",
       "\n",
       "</details>\n",
       "\n",
       "\n",
       "\n",
       "<details class='tool-usage-details'>\n",
       "<summary>asimple_div(a=3, b=0)</summary>\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"id\": \"toolu_01HLDF7VBXqb96RhgwVAkTpM\",\n",
       "  \"call\": {\n",
       "    \"function\": \"asimple_div\",\n",
       "    \"arguments\": {\n",
       "      \"a\": \"3\",\n",
       "      \"b\": \"0\"\n",
       "    }\n",
       "  },\n",
       "  \"result\": \"Traceback (most recent call last):\\n  File \\\"/Users/jhoward/aai-ws/toolslm/toolslm/funccall.py\\\", line 265, in call_func_async\\n    try: res = await res\\n               ^^^^^^^^^\\n  File \\\"/var/folders/51/b2_szf2945n072c0vj2cyty40000gn/T/ipykernel_23626/466431256.py\\\", line 6, in asimple_div\\n    return a/b\\n           ~^~\\nZeroDivisionError: division by zero\"\n",
       "}\n",
       "```\n",
       "\n",
       "</details>\n",
       "\n",
       "Here's exactly what I see from the two tool results:\n",
       "\n",
       "1. **5/3** â€” Returned successfully with the result: **1.6666666666666667**\n",
       "\n",
       "2. **3/0** â€” Returned an error. Specifically, I see a Python traceback:\n",
       "   ```\n",
       "   Traceback (most recent call last):\n",
       "     File \"/Users/jhoward/aai-ws/toolslm/toolslm/funccall.py\", line 265, in call_func_async\n",
       "       try: res = await res\n",
       "                  ^^^^^^^^^\n",
       "     File \"/var/folders/51/b2_szf2945n072c0vj2cyty40000gn/T/ipykernel_23626/466431256.py\", line 6, in asimple_div\n",
       "       return a/b\n",
       "              ~^~\n",
       "   ZeroDivisionError: division by zero\n",
       "   ```\n",
       "\n",
       "**Summary:**\n",
       "- The first call succeeded and returned the expected floating-point division result.\n",
       "- The second call failed with a **ZeroDivisionError**, which is expected since division by zero is mathematically undefined. The error was not caught within the tool's implementation, so the raw Python traceback was returned as the tool result rather than a graceful error message.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = ms[2]\n",
    "chat = AsyncChat(m, tools=[asimple_div])\n",
    "res = await chat(\"Calculate 5/3 and 3/0 with parallel tool calls using `asimple_div` (this is a test of our error handling - tell me exactly what you see as the tool result)\", stream=True)\n",
    "fmt = await adisplay_stream(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cdab76",
   "metadata": {},
   "source": [
    "### Thinking tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d97da43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "ðŸ§ \n",
       "\n",
       "For a list of 1,000 random integers, the most efficient approach depends on whether you are coding it from scratch or using a tool:\n",
       "\n",
       "1.  **The Practical Winner: Built-in Library Functions**\n",
       "    In any modern language (Pythonâ€™s `.sort()`, C++â€™s `std::sort`, or Javaâ€™s `Arrays.sort`), use the built-in function. These typically use **Timsort** or **Introsort**, which are highly optimized, hybrid algorithms that outperform manual implementations.\n",
       "\n",
       "2.  **The Algorithmic Winner: QuickSort**\n",
       "    For general-purpose sorting of random data, **QuickSort** is usually the fastest $O(n \\log n)$ algorithm due to low overhead and high cache efficiency.\n",
       "\n",
       "3.  **The \"Special Case\" Winner: Counting Sort**\n",
       "    If the integers are within a **small, known range** (e.g., all numbers are between 0 and 500), **Counting Sort** is the most efficient. It runs in **$O(n)$** linear time, making it mathematically faster than QuickSort.\n",
       "\n",
       "**Summary:** Unless the range of numbers is very small, use your programming language's **built-in sort function**.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(ðŸ§ \n",
       "\n",
       "For a list of 1,000 random integers, the most efficient approach depends on whether you are coding it from scratch or using a tool:\n",
       "\n",
       "1.  **The Practical Winner: Built-in Library Functions**\n",
       "    In any modern language (Pythonâ€™s `.sort()`, C++â€™s `std::sort`, or Javaâ€™s `Arrays.sort`), use the built-in function. These typically use **Timsort** or **Introsort**, which are highly optimized, hybrid algorithms that outperform manual implementations.\n",
       "\n",
       "2.  **The Algorithmic Winner: QuickSort**\n",
       "    For general-purpose sorting of random data, **QuickSort** is usually the fastest $O(n \\log n)$ algorithm due to low overhead and high cache efficiency.\n",
       "\n",
       "3.  **The \"Special Case\" Winner: Counting Sort**\n",
       "    If the integers are within a **small, known range** (e.g., all numbers are between 0 and 500), **Counting Sort** is the most efficient. It runs in **$O(n)$** linear time, making it mathematically faster than QuickSort.\n",
       "\n",
       "**Summary:** Unless the range of numbers is very small, use your programming language's **built-in sort function**.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = AsyncChat(model)\n",
    "res = await chat(\"Briefly, what's the most efficient way to sort a list of 1000 random integers?\", think='l',stream=True)\n",
    "_ = await adisplay_stream(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5580e7f",
   "metadata": {},
   "source": [
    "### Multiple tool calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc5b196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "\n",
       "\n",
       "<details class='tool-usage-details'>\n",
       "<summary>simple_add(b=5, a=10)</summary>\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"id\": \"call_dc36f7d1adcc4d3284329718d98e__thought__EjQKMgG+Pvb7mgl82RAXabReCdDsveCKFVWHS3FgvrcIW0EkAXNk3UbMDgOqeC3cjHMoIf2T\",\n",
       "  \"call\": {\n",
       "    \"function\": \"simple_add\",\n",
       "    \"arguments\": {\n",
       "      \"b\": \"5\",\n",
       "      \"a\": \"10\"\n",
       "    }\n",
       "  },\n",
       "  \"result\": \"15\"\n",
       "}\n",
       "```\n",
       "\n",
       "</details>\n",
       "\n",
       "\n",
       "\n",
       "<details class='tool-usage-details'>\n",
       "<summary>simple_add(a=2, b=1)</summary>\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"id\": \"call_57b487270e304c88a1d6b8469aa8\",\n",
       "  \"call\": {\n",
       "    \"function\": \"simple_add\",\n",
       "    \"arguments\": {\n",
       "      \"a\": \"2\",\n",
       "      \"b\": \"1\"\n",
       "    }\n",
       "  },\n",
       "  \"result\": \"3\"\n",
       "}\n",
       "```\n",
       "\n",
       "</details>\n",
       "\n",
       "The calculation is currently **incomplete**. Here is a summary of the progress made in the first batch of parallel operations:\n",
       "\n",
       "1.  **Inner Parentheses (Left):** We calculated `(10 + 5)` which equals **15**.\n",
       "2.  **Inner Parentheses (Right):** We calculated `(2 + 1)` which equals **3**.\n",
       "\n",
       "**Current state of the expression:**\n",
       "`(15 * 3) / 3`\n",
       "\n",
       "To finish the calculation, the next steps would involve multiplying 15 by 3, and then dividing that result by 3.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(\n",
       "\n",
       "<details class='tool-usage-details'>\n",
       "<summary>simple_add(b=5, a=10)</summary>\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"id\": \"call_dc36f7d1adcc4d3284329718d98e__thought__EjQKMgG+Pvb7mgl82RAXabReCdDsveCKFVWHS3FgvrcIW0EkAXNk3UbMDgOqeC3cjHMoIf2T\",\n",
       "  \"call\": {\n",
       "    \"function\": \"simple_add\",\n",
       "    \"arguments\": {\n",
       "      \"b\": \"5\",\n",
       "      \"a\": \"10\"\n",
       "    }\n",
       "  },\n",
       "  \"result\": \"15\"\n",
       "}\n",
       "```\n",
       "\n",
       "</details>\n",
       "\n",
       "\n",
       "\n",
       "<details class='tool-usage-details'>\n",
       "<summary>simple_add(a=2, b=1)</summary>\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"id\": \"call_57b487270e304c88a1d6b8469aa8\",\n",
       "  \"call\": {\n",
       "    \"function\": \"simple_add\",\n",
       "    \"arguments\": {\n",
       "      \"a\": \"2\",\n",
       "      \"b\": \"1\"\n",
       "    }\n",
       "  },\n",
       "  \"result\": \"3\"\n",
       "}\n",
       "```\n",
       "\n",
       "</details>\n",
       "\n",
       "The calculation is currently **incomplete**. Here is a summary of the progress made in the first batch of parallel operations:\n",
       "\n",
       "1.  **Inner Parentheses (Left):** We calculated `(10 + 5)` which equals **15**.\n",
       "2.  **Inner Parentheses (Right):** We calculated `(2 + 1)` which equals **3**.\n",
       "\n",
       "**Current state of the expression:**\n",
       "`(15 * 3) / 3`\n",
       "\n",
       "To finish the calculation, the next steps would involve multiplying 15 by 3, and then dividing that result by 3.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "chat = AsyncChat(model, tools=[simple_add, multiply, divide])\n",
    "res = await chat(\"Calculate ((10 + 5) * 3) / (2 + 1) Use parallel tool calls, & explain where we are after each batch\",\n",
    "           max_steps=2, stream=True,\n",
    "           final_prompt=\"Please report that it's incomplete, and wrap-up for now and summarize how far we got.\")\n",
    "fmt = await adisplay_stream(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4a72c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(content=None, role='assistant', tool_calls=[{'provider_specific_fields': {'thought_signature': 'EjQKMgG+Pvb7mgl82RAXabReCdDsveCKFVWHS3FgvrcIW0EkAXNk3UbMDgOqeC3cjHMoIf2T'}, 'function': {'arguments': '{\"b\": 5, \"a\": 10}', 'name': 'simple_add'}, 'id': 'call_dc36f7d1adcc4d3284329718d98e__thought__EjQKMgG+Pvb7mgl82RAXabReCdDsveCKFVWHS3FgvrcIW0EkAXNk3UbMDgOqeC3cjHMoIf2T', 'type': 'function'}, {'function': {'arguments': '{\"a\": 2, \"b\": 1}', 'name': 'simple_add'}, 'id': 'call_57b487270e304c88a1d6b8469aa8', 'type': 'function'}], function_call=None, provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7mgl82RAXabReCdDsveCKFVWHS3FgvrcIW0EkAXNk3UbMDgOqeC3cjHMoIf2T']})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.hist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ea0f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_dc36f7d1adcc4d3284329718d98e__thought__EjQKMgG+Pvb7mgl82RAXabReCdDsveCKFVWHS3FgvrcIW0EkAXNk3UbMDgOqeC3cjHMoIf2T',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '15'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.hist[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c81c0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tool_call_id': 'call_57b487270e304c88a1d6b8469aa8',\n",
       " 'role': 'tool',\n",
       " 'name': 'simple_add',\n",
       " 'content': '3'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.hist[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456910e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': \"Please report that it's incomplete, and wrap-up for now and summarize how far we got.\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.hist[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364a8bbe",
   "metadata": {},
   "source": [
    "Now to demonstrate that we can load back the formatted output back into a new `Chat` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55653287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "We just performed the first step of solving a mathematical expression by handling the operations inside the parentheses.\n",
       "\n",
       "Specifically, I used the `simple_add` tool twice in parallel to solve the two addition problems within your expression:\n",
       "\n",
       "1.  **First Addition:** I added **10 + 5** to get **15**.\n",
       "2.  **Second Addition:** I added **2 + 1** to get **3**.\n",
       "\n",
       "By doing this, we simplified the original problem from `(10 + 5) * (2 + 1) / 3` down to `15 * 3 / 3`.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `gemini-3-flash-preview`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=130, prompt_tokens=396, total_tokens=526, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=130, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=396, image_tokens=None), cache_read_input_tokens=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='gemini-3-flash-preview', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='We just performed the first step of solving a mathematical expression by handling the operations inside the parentheses.\\n\\nSpecifically, I used the `simple_add` tool twice in parallel to solve the two addition problems within your expression:\\n\\n1.  **First Addition:** I added **10 + 5** to get **15**.\\n2.  **Second Addition:** I added **2 + 1** to get **3**.\\n\\nBy doing this, we simplified the original problem from `(10 + 5) * (2 + 1) / 3` down to `15 * 3 / 3`.', role='assistant', tool_calls=None, function_call=None, images=[], thinking_blocks=[], provider_specific_fields={'thought_signatures': ['EjQKMgG+Pvb7Rvc6WpJ0Ze+oVINZNpJLxbrJ4AV1Mg1BK8MpbpcnW4jSJbYKmggN0i3Fs4Tv']}))], usage=Usage(completion_tokens=130, prompt_tokens=396, total_tokens=526, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=130, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=396, image_tokens=None), cache_read_input_tokens=None), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat5 = Chat(model,hist=fmt2hist(fmt.outp),tools=[simple_add, multiply, divide])\n",
    "chat5('what did we just do?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc0df26",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124da784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"prose\">\n",
       "\n",
       "Today in New York City (Tuesday, February 24, 2026), the weather is transitioning after a major winter storm that impacted the region yesterday.\n",
       "\n",
       "### **Current Conditions & Forecast**\n",
       "*   **Daytime:** Expect a mix of sun and clouds with a high near **32Â°F to 37Â°F (0Â°C to 3Â°C)**. It will remain breezy, with winds from the West-Northwest at 10 to 15 mph.\n",
       "*   **Nighttime:** Clouds will increase, and there is a **35% to 70% chance of light snow** developing late tonight. Lows will drop to around **14Â°F to 27Â°F (-10Â°C to -3Â°C)**. Snow accumulations are expected to be less than one inch.\n",
       "\n",
       "### **Recent Storm Impact**\n",
       "The city is currently recovering from a significant blizzard that occurred on Monday, February 23. \n",
       "*   **Snowfall:** The storm brought heavy snow (up to 24 inches in some parts of the region) and strong winds.\n",
       "*   **Travel:** A state of emergency was issued yesterday, and while some restrictions have been lifted, officials still advise caution due to lingering icy conditions and ongoing cleanup efforts.\n",
       "\n",
       "### **Looking Ahead**\n",
       "*   **Wednesday, Feb 25:** A mix of rain and snow is possible during the day, with temperatures warming slightly to a high of **41Â°F (5Â°C)**.\n",
       "*   **Thursday, Feb 26:** More snow showers are expected, with highs remaining in the mid-30s.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "Markdown(Today in New York City (Tuesday, February 24, 2026), the weather is transitioning after a major winter storm that impacted the region yesterday.\n",
       "\n",
       "### **Current Conditions & Forecast**\n",
       "*   **Daytime:** Expect a mix of sun and clouds with a high near **32Â°F to 37Â°F (0Â°C to 3Â°C)**. It will remain breezy, with winds from the West-Northwest at 10 to 15 mph.\n",
       "*   **Nighttime:** Clouds will increase, and there is a **35% to 70% chance of light snow** developing late tonight. Lows will drop to around **14Â°F to 27Â°F (-10Â°C to -3Â°C)**. Snow accumulations are expected to be less than one inch.\n",
       "\n",
       "### **Recent Storm Impact**\n",
       "The city is currently recovering from a significant blizzard that occurred on Monday, February 23. \n",
       "*   **Snowfall:** The storm brought heavy snow (up to 24 inches in some parts of the region) and strong winds.\n",
       "*   **Travel:** A state of emergency was issued yesterday, and while some restrictions have been lifted, officials still advise caution due to lingering icy conditions and ongoing cleanup efforts.\n",
       "\n",
       "### **Looking Ahead**\n",
       "*   **Wednesday, Feb 25:** A mix of rain and snow is possible during the day, with temperatures warming slightly to a high of **41Â°F (5Â°C)**.\n",
       "*   **Thursday, Feb 26:** More snow showers are expected, with highs remaining in the mid-30s.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_stream_tools = AsyncChat(model, search='l')\n",
    "res = await chat_stream_tools(\"Search the weather in NYC\", stream=True)\n",
    "_=await adisplay_stream(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e69676",
   "metadata": {},
   "source": [
    "Let's mock `pause_turn` with async completion and streaming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318a4ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def mk_pause_web_search_stream():\n",
    "#     \"\"\"Async generator that mimics a streaming pause_turn response\"\"\"\n",
    "#     srv_tc = mk_tc(\"web_search\", json.dumps({\"query\": \"Solveit Answer.AI\"}), \n",
    "#                    tcid=random_tool_id().replace('toolu_', 'srvtoolu_'))\n",
    "#     yield mk_stream_chunk(content=\"Let me search for that information:\", role='assistant')\n",
    "#     yield mk_stream_chunk(tool_calls=[srv_tc])\n",
    "#     yield mk_stream_chunk(finish_reason=\"pause_turn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb849da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_acompletion = acompletion\n",
    "# \n",
    "# call_count = 0\n",
    "# async def patched_acompletion(*args, **kwargs):\n",
    "#     global call_count\n",
    "#     call_count += 1\n",
    "#     print(f\"Mock Async Call {call_count}\")\n",
    "#     await asyncio.sleep(1)\n",
    "#     if call_count < 3: return mk_pause_web_search_stream()\n",
    "#     return await orig_acompletion(*args, **kwargs)\n",
    "# \n",
    "# acompletion = patched_acompletion\n",
    "# achat_pause = AsyncChat('claude-sonnet-4-5', search='l')\n",
    "# \n",
    "# call_count = 0\n",
    "# res = await achat_pause(\"Search and tell me about Solveit\", stream=True)\n",
    "# fmt = await adisplay_stream(res)\n",
    "# print(f\"\\nTotal calls: {call_count}\")\n",
    "# \n",
    "# acompletion = orig_acompletion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4d05f9",
   "metadata": {},
   "source": [
    "### Tool Call Referencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e88c6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Perfect! I successfully completed both steps:\n",
       "\n",
       "1. **Retrieved person data**: I called `get_person` which returned information about Alice, who is 30 years old.\n",
       "\n",
       "2. **Greeted the person**: I then passed Alice's data to `greet_person`, which generated the greeting: \"Hello Alice, you are 30 years old!\"\n",
       "\n",
       "The task has been completed successfully. The person's data was retrieved and used to create a personalized greeting.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-xxx`\n",
       "- model: `claude-sonnet-4-5-20250929`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=103, prompt_tokens=1081, total_tokens=1184, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=103, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='not_available', speed=None)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-xxx', created=1000000000, model='claude-sonnet-4-5-20250929', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Perfect! I successfully completed both steps:\\n\\n1. **Retrieved person data**: I called `get_person` which returned information about Alice, who is 30 years old.\\n\\n2. **Greeted the person**: I then passed Alice\\'s data to `greet_person`, which generated the greeting: \"Hello Alice, you are 30 years old!\"\\n\\nThe task has been completed successfully. The person\\'s data was retrieved and used to create a personalized greeting.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=103, prompt_tokens=1081, total_tokens=1184, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=103, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0, inference_geo='not_available', speed=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "achat = AsyncChat('claude-sonnet-4-5', tools=[get_person, greet_person], tc_refs=True)\n",
    "await achat(\"First call get_person, then pass the result to greet_person\", max_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39edd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toolu_01RbzkhhezbZ4Ktd133xqJTc': {'name': 'Alice', 'age': 30},\n",
       " 'toolu_01WtKJw8rQ4KfAGR4hX3so9j': 'Hello Alice, you are 30 years old!'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "achat.tc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfd8af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[ChatCompletionMessageToolCall(index=1, caller={'type': 'direct'}, function=Function(arguments='{}', name='get_person'), id='toolu_01RbzkhhezbZ4Ktd133xqJTc', type='function')],\n",
       " [ChatCompletionMessageToolCall(index=1, caller={'type': 'direct'}, function=Function(arguments='{\"person\": \"$`toolu_01RbzkhhezbZ4Ktd133xqJTc`\"}', name='greet_person'), id='toolu_01WtKJw8rQ4KfAGR4hX3so9j', type='function')]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(L(achat.hist).attrgot('tool_calls').filter())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9764dc",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e677e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "learning",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
