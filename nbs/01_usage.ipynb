{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bd3dbfa",
   "metadata": {},
   "source": [
    "# Usage\n",
    "\n",
    "> Lisette usage and cost monitoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c9427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6856c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from litellm.integrations.custom_logger import CustomLogger\n",
    "from fastcore.utils import *\n",
    "import time\n",
    "try: from fastlite import *\n",
    "except ImportError: raise ImportError(\"Please install `fastlite` to use sqlite based lisette usage logging.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743eedcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm, importlib, httpx\n",
    "from lisette.core import Chat, AsyncChat, patch_litellm\n",
    "from cachy import enable_cachy, disable_cachy\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69144ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "enable_cachy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cff8990",
   "metadata": {},
   "source": [
    "## Lisette Usage Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9acabfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = importlib.reload(litellm) # to re-run the notebook without kernel restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85329c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# litellm._turn_on_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_litellm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed71558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Usage: id:int; timestamp:float; model:str; user_id:str; prompt_tokens:int; completion_tokens:int; total_tokens:int; cached_tokens:int; cache_creation_tokens:int; cache_read_tokens:int; web_search_requests:int; response_cost:int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4301de",
   "metadata": {},
   "source": [
    "Anthropic provides web search request counts directly via `usage.server_tool_use.web_search_requests`, billed at $10 per 1,000 searches ([pricing](https://docs.claude.com/en/docs/about-claude/pricing)). Gemini returns queries in `groundingMetadata.webSearchQueries`—each query counts as a separate billable use—with 5,000 free prompts per month, then $14 per 1,000 search queries (coming soon) ([pricing](https://ai.google.dev/gemini-api/docs/pricing), [grounding docs](https://ai.google.dev/gemini-api/docs/google-search))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4323da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def search_count(r):\n",
    "    if cnt := nested_idx(r.usage, 'server_tool_use', 'web_search_requests'): return cnt # Anthropic\n",
    "    if meta := getattr(r, 'vertex_ai_grounding_metadata', None): # Gemini\n",
    "        if meta and (queries := meta[0].get('webSearchQueries')): return len(queries)\n",
    "    if cnt := nested_idx(r.usage, 'prompt_tokens_details', 'web_search_requests'): return cnt # streaming with `include_usage`\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bf5fc1",
   "metadata": {},
   "source": [
    "The precomputed response cost provided is available in `kwargs['response_cost']` according to the [litellm docs](https://docs.litellm.ai/docs/observability/custom_callback#whats-available-in-kwargs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad2e088",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LisetteUsageLogger(CustomLogger):\n",
    "    def __init__(self, db_path): \n",
    "        self.db = Database(db_path)\n",
    "        self.usage = self.db.create(Usage)\n",
    "    \n",
    "    async def async_log_success_event(self, kwargs, response_obj, start_time, end_time): self._log_usage(response_obj, kwargs, start_time, end_time)\n",
    "    def log_success_event(self, kwargs, response_obj, start_time, end_time):             self._log_usage(response_obj, kwargs, start_time, end_time)\n",
    "    def _log_usage(self, response_obj, kwargs, start_time, end_time):\n",
    "        response_cost = kwargs.get('response_cost') or nested_idx(kwargs,'standard_logging_object','cost_breakdown','total_cost')\n",
    "        usage = response_obj.usage\n",
    "        ptd   = usage.prompt_tokens_details\n",
    "        self.usage.insert(Usage(timestamp=time.time(),\n",
    "                                model=response_obj.model,\n",
    "                                user_id=self.user_id_fn(),\n",
    "                                prompt_tokens=usage.prompt_tokens,\n",
    "                                completion_tokens=usage.completion_tokens,\n",
    "                                total_tokens=usage.total_tokens,\n",
    "                                cached_tokens=ptd.cached_tokens if ptd else 0, # used by gemini (read tokens)\n",
    "                                cache_creation_tokens=nested_idx(usage, 'cache_creation_input_tokens'),\n",
    "                                cache_read_tokens=nested_idx(usage, 'cache_read_input_tokens'), # used by anthropic\n",
    "                                web_search_requests=search_count(response_obj),\n",
    "                                response_cost=response_cost))\n",
    "                  \n",
    "    def user_id_fn(self): raise NotImplementedError('Please implement `LisetteUsageLogger.user_id_fn` before initializing, e.g using fastcore.patch.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdfd5ca",
   "metadata": {},
   "source": [
    "## Cost Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce652ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrefixDict(dict):\n",
    "    def __getitem__(self, key):\n",
    "        if key in self.keys(): return super().__getitem__(key)\n",
    "        for k in self.keys(): \n",
    "            if key.startswith(k): return super().__getitem__(k)\n",
    "        raise KeyError(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847758d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prices = PrefixDict({\n",
    "    'claude-sonnet-4-5': dict(input_prc = 3/1e6, cache_write_prc = 3.75/1e6, cache_read_prc = 0.3/1e6, output_prc = 15/1e6, web_search_prc = 10/1e3)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42be909f",
   "metadata": {},
   "source": [
    "Simplified cost utils to demonstrate total cost calculation (use `Usage.response_cost` in prod):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6624d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch(as_prop=True)\n",
    "def inp_cost(self:Usage):         return model_prices[self.model]['input_prc'] * (self.prompt_tokens - self.cache_read_tokens)\n",
    "@patch(as_prop=True)\n",
    "def cache_write_cost(self:Usage): return model_prices[self.model]['cache_write_prc'] * self.cache_creation_tokens\n",
    "@patch(as_prop=True)\n",
    "def cache_read_cost(self:Usage):  return model_prices[self.model]['cache_read_prc'] * self.cache_read_tokens\n",
    "@patch(as_prop=True)\n",
    "def out_cost(self:Usage):         return model_prices[self.model]['output_prc'] * self.completion_tokens\n",
    "@patch(as_prop=True)\n",
    "def web_cost(self:Usage):         return model_prices[self.model]['web_search_prc'] * ifnone(self.web_search_requests, 0)\n",
    "@patch(as_prop=True)\n",
    "def cost(self:Usage):             return self.inp_cost + self.cache_write_cost + self.cache_read_cost + self.out_cost + self.web_cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432ef6d0",
   "metadata": {},
   "source": [
    "A mapping of model pricing is also available in litellm, which is used to calculate the `response_cost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90af6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pricing = dict2obj(httpx.get(litellm.model_cost_map_url).json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc0ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pricing['claude-sonnet-4-5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ff68bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pricing['gemini-3-pro-preview']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd2987b",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a045f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import NamedTemporaryFile\n",
    "tf =NamedTemporaryFile(suffix='.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4a50ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def user_id_fn(self:LisetteUsageLogger): return 'user-123'\n",
    "tf=NamedTemporaryFile(suffix='.db')\n",
    "logger = LisetteUsageLogger(tf.name)\n",
    "litellm.callbacks = [logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5842bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "slc = ','.join('id model user_id prompt_tokens completion_tokens total_tokens cached_tokens cache_creation_tokens cache_read_tokens web_search_requests response_cost'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac32ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# litellm.set_verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0af81a",
   "metadata": {},
   "source": [
    "A simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9215558",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat('claude-sonnet-4-5-20250929')\n",
    "r = chat(\"What is 2+2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b82ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3) # wait for callback db write\n",
    "u = logger.usage(select=slc)[-1]; u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39087125",
   "metadata": {},
   "source": [
    "Our calculated cost matches litellm's `response_cost`. In some cases it might be better to use the custom calculation as we'll see in the remaining of this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367cb32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(u.cost, u.response_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55735017",
   "metadata": {},
   "source": [
    "Now, let's test with streaming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b8cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat('claude-sonnet-4-5')\n",
    "res = chat(\"Count from 1 to 5\", stream=True)\n",
    "for o in res: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e8eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "u = logger.usage(select=slc)[-1]; u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fadb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(u.cost, u.response_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab9bb4b",
   "metadata": {},
   "source": [
    "Streaming logged successfully. Let's also verify async chat calls are logged properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5270a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_async = AsyncChat('claude-sonnet-4-5-20250929')\n",
    "await chat_async(\"What is 3+3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a75d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "u = logger.usage(select=slc)[-1]; u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1916085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(u.cost, u.response_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f82d440",
   "metadata": {},
   "source": [
    "Finally, let's test async streaming to ensure all API patterns are covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7791bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await chat_async(\"Count from 10 to 15\", stream=True)\n",
    "async for o in res: pass\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd6b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "u = logger.usage(select=slc)[-1]; u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea9299",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(u.cost, u.response_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050cf3a5",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc60ec86",
   "metadata": {},
   "source": [
    "Now let's run a prompt with web search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79df374",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat('gemini/gemini-2.5-flash')\n",
    "chat(\"What is the weather like in NYC? Search web.\", search=\"m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "u = logger.usage(select=slc)[-1]; u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b597375",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(u.web_search_requests,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d3c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat('claude-sonnet-4-5-20250929')\n",
    "r = chat(\"What is the weather like in NYC? Search web.\", search=\"m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb86f247",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "u = logger.usage(select=slc)[-1]; u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50379ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(u.web_search_requests,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7d58e3",
   "metadata": {},
   "source": [
    "::: {.callout-important}\n",
    "Litellm's `response_cost` doesn't take web search request cost into account!\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a35480",
   "metadata": {},
   "source": [
    "Now, this is a case where using the custom calculations is better as it will also include the web search request cost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc09ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(u.cost, u.response_cost + u.web_search_requests * model_prices[u.model]['web_search_prc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e9b5a8",
   "metadata": {},
   "source": [
    "### Search with streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8929bae",
   "metadata": {},
   "source": [
    "Web search with streaming:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d1da0",
   "metadata": {},
   "source": [
    "::: {.callout-important}\n",
    "Gemini web search requests are part of `prompt_tokens_details` which is only included with `stream_options={\"include_usage\": True}` when `stream=True`. \n",
    "\n",
    "There is currently a bug with gemini web search request counts, [Issue](https://github.com/BerriAI/litellm/issues/17919) and [PR](https://github.com/BerriAI/litellm/pull/17921). Waiting for litellm 1.80.11 pypi release.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faec06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat('gemini/gemini-2.5-flash')\n",
    "res = chat(\"What is the weather like in NYC? Search web.\", search=\"m\", stream=True, stream_options={\"include_usage\": True})\n",
    "for o in res: pass\n",
    "# print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21056927",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "u = logger.usage(select=slc)[-1]; u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae560895",
   "metadata": {},
   "source": [
    "::: {.callout-important}\n",
    "Anthropic web search requests are available in `usage.server_tool_use`\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff66e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat('claude-sonnet-4-5')\n",
    "res = chat(\"What is the weather like in NYC now? Search web.\", search=\"m\", stream=True, stream_options={\"include_usage\": True})\n",
    "for o in res: pass\n",
    "# print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c9bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "u = logger.usage(select=slc)[-1]; u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f51ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(u.cost, u.response_cost + u.web_search_requests * model_prices[u.model]['web_search_prc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc36e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(logger.usage()), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef8ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def total_cost(self:Usage, sc=0.01): return self.response_cost + sc * ifnone(self.web_search_requests, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef5dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "L(logger.usage()).attrgot('response_cost').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_cachy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e57bed",
   "metadata": {},
   "source": [
    "A simple Gemini example (requires min tokens and running twice to see `cached_tokens`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad22437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| notest\n",
    "# chat = Chat('gemini/gemini-2.5-flash')\n",
    "# chat(\"What is 2+2?\"* 500)\n",
    "# time.sleep(5)\n",
    "# chat(\"What is 2+2?\"* 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0621b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| notest\n",
    "# time.sleep(3) # wait for callback db write\n",
    "# u = logger.usage(select=slc)[-1];u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6133e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| notest\n",
    "# test_eq(len(logger.usage()), 10)\n",
    "# test_eq(logger.usage()[-1].cached_tokens > 3000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3577f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e335da",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
